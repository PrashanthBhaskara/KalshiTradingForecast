{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cryptography in /opt/anaconda3/lib/python3.12/site-packages (43.0.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/anaconda3/lib/python3.12/site-packages (from cryptography) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.12/site-packages (from cffi>=1.12->cryptography) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip install cryptography\n",
    "from cryptography.hazmat.primitives import serialization\n",
    "from cryptography.hazmat.backends import default_backend\n",
    "import base64\n",
    "from cryptography.hazmat.primitives import hashes\n",
    "from cryptography.hazmat.primitives.asymmetric import padding, rsa\n",
    "from cryptography.exceptions import InvalidSignature\n",
    "from pathlib import Path\n",
    "import os\n",
    "from cryptography.hazmat.backends import default_backend\n",
    "import requests\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Kalshi keys ✅\n"
     ]
    }
   ],
   "source": [
    "# Cell 1 — load KALSHI keys from .env in the same directory as this notebook\n",
    "\n",
    "\n",
    "# --- Try to use python-dotenv if it's installed (recommended) ---\n",
    "try:\n",
    "    from dotenv import load_dotenv  # pip install python-dotenv\n",
    "    env_path = Path.cwd() / \".env\"   # assumes notebook is run from the same directory as .env\n",
    "    if not env_path.exists():\n",
    "        raise FileNotFoundError(f\".env not found at: {env_path}\")\n",
    "    load_dotenv(dotenv_path=env_path, override=False)\n",
    "except ImportError:\n",
    "    # --- Fallback: minimal .env parser (no extra install needed) ---\n",
    "    env_path = Path.cwd() / \".env\"\n",
    "    if not env_path.exists():\n",
    "        raise FileNotFoundError(f\".env not found at: {env_path}\")\n",
    "\n",
    "    for line in env_path.read_text().splitlines():\n",
    "        line = line.strip()\n",
    "        if not line or line.startswith(\"#\") or \"=\" not in line:\n",
    "            continue\n",
    "        k, v = line.split(\"=\", 1)\n",
    "        k = k.strip()\n",
    "        v = v.strip().strip('\"').strip(\"'\")\n",
    "        os.environ.setdefault(k, v)  # don't overwrite if already set\n",
    "\n",
    "# --- Read your keys into variables ---\n",
    "public_key = os.getenv(\"KALSHI-ACCESS-KEY-DEMO\")\n",
    "\n",
    "missing = [k for k, v in {\n",
    "    \"KALSHI-ACCESS-KEY\": public_key\n",
    "}.items() if not v]\n",
    "\n",
    "if missing:\n",
    "    raise KeyError(f\"Missing env var(s): {missing}. Check your .env formatting and key names.\")\n",
    "\n",
    "print(\"Loaded Kalshi keys ✅\")  # intentionally not printing the secret values\n",
    "\n",
    "\n",
    "def load_private_key_from_file(file_path):\n",
    "    with open(file_path, \"rb\") as key_file:\n",
    "        private_key = serialization.load_pem_private_key(\n",
    "            key_file.read(),\n",
    "            password=None,  # or provide a password if your key is encrypted\n",
    "            backend=default_backend()\n",
    "        )\n",
    "    return private_key\n",
    "\n",
    "\n",
    "def sign_pss_text(private_key: rsa.RSAPrivateKey, text: str) -> str:\n",
    "    message = text.encode('utf-8')\n",
    "    try:\n",
    "        signature = private_key.sign(\n",
    "            message,\n",
    "            padding.PSS(\n",
    "                mgf=padding.MGF1(hashes.SHA256()),\n",
    "                salt_length=padding.PSS.DIGEST_LENGTH\n",
    "            ),\n",
    "            hashes.SHA256()\n",
    "        )\n",
    "        return base64.b64encode(signature).decode('utf-8')\n",
    "    except InvalidSignature as e:\n",
    "        raise ValueError(\"RSA sign PSS failed\") from e\n",
    "    \n",
    "\n",
    "def make_authenticated_request(path, method='GET', params=None):\n",
    "    \"\"\"Make an authenticated request to Kalshi demo API.\"\"\"\n",
    "    current_time = datetime.datetime.now()\n",
    "    timestamp = current_time.timestamp()\n",
    "    current_time_milliseconds = int(timestamp * 1000)\n",
    "    timestamp_str = str(current_time_milliseconds)\n",
    "    \n",
    "    private_key = load_private_key_from_file('pbhaskarademo.txt')\n",
    "    \n",
    "    base_url = 'https://demo-api.kalshi.co'\n",
    "    \n",
    "    # Strip query parameters from path before signing\n",
    "    path_without_query = path.split('?')[0]\n",
    "    msg_string = timestamp_str + method + path_without_query\n",
    "    sig = sign_pss_text(private_key, msg_string)\n",
    "    \n",
    "    headers = {\n",
    "        'KALSHI-ACCESS-KEY': public_key,\n",
    "        'KALSHI-ACCESS-SIGNATURE': sig,\n",
    "        'KALSHI-ACCESS-TIMESTAMP': timestamp_str\n",
    "    }\n",
    "    \n",
    "    if method == 'GET':\n",
    "        response = requests.get(base_url + path, headers=headers, params=params)\n",
    "    else:\n",
    "        response = requests.post(base_url + path, headers=headers, json=params)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FETCHING HISTORICAL COMPANIES MARKETS\n",
      "================================================================================\n",
      "\n",
      "Time window:\n",
      "  From: 2025-02-01 08:26:59 UTC\n",
      "  To:   2026-02-01 08:26:59 UTC\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Fetching Companies category series...\n",
      "--------------------------------------------------------------------------------\n",
      "  ✓ Found 349 series in Companies category\n",
      "\n",
      "✓ Total unique companies series: 349\n",
      "\n",
      "Companies series found:\n",
      "  - KXDANGROSSMETA: Daniel Gross joining Meta\n",
      "    Category: Companies\n",
      "  - KXTESLAPROD: Tesla production\n",
      "    Category: Companies\n",
      "  - CBVOLUME: Coinbase volume\n",
      "    Category: Companies\n",
      "  - KXTIKTOKSELL: Congress passes law to force TikTok sale\n",
      "    Category: Companies\n",
      "  - KXTOPLLM: GPT no longer top ranked LLM\n",
      "    Category: Science and Technology\n",
      "  - KXANTITRUSTOAIMSFT: OpenAI Microsoft antitrust\n",
      "    Category: Companies\n",
      "  - KXGROKMACOS: Grok MacOS app\n",
      "    Category: Companies\n",
      "  - KXNEWPRODUCTFALLOUT3REM: “will Fallout 3 remastered be revealed on October 23rd?”\n",
      "    Category: Companies\n",
      "  - KXACQANNOUNEWARNER: Warner Bros\n",
      "    Category: Companies\n",
      "  - KXTESLAYL: Tesla to release model Y L\n",
      "    Category: Companies\n",
      "  ... and 339 more series\n",
      "\n",
      "✓ Will fetch markets for 349 companies series\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 1: Pull All Historical Companies Markets\n",
    "# ============================================================================\n",
    "\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "try:\n",
    "    from zoneinfo import ZoneInfo\n",
    "    ET_TZ = ZoneInfo('America/New_York')\n",
    "except ImportError:\n",
    "    ET_TZ = timezone(timedelta(hours=-5))\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FETCHING HISTORICAL COMPANIES MARKETS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate time window (past year)\n",
    "now_comp = datetime.now(timezone.utc)\n",
    "one_year_ago_comp = now_comp - timedelta(days=365)\n",
    "min_close_ts_comp = int(one_year_ago_comp.timestamp())\n",
    "max_close_ts_comp = int(now_comp.timestamp())\n",
    "\n",
    "print(f\"\\nTime window:\")\n",
    "print(f\"  From: {one_year_ago_comp.strftime('%Y-%m-%d %H:%M:%S UTC')}\")\n",
    "print(f\"  To:   {now_comp.strftime('%Y-%m-%d %H:%M:%S UTC')}\")\n",
    "\n",
    "# Search for Companies category series\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"Fetching Companies category series...\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "base_url_comp = \"https://api.elections.kalshi.com/trade-api/v2\"\n",
    "\n",
    "# Fetch series by category \"Companies\"\n",
    "companies_series = []\n",
    "\n",
    "try:\n",
    "    response = requests.get(f\"{base_url_comp}/series\", params={\"category\": \"Companies\", \"limit\": 200})\n",
    "    if response.status_code == 200:\n",
    "        series_data = response.json().get('series', [])\n",
    "        companies_series.extend(series_data)\n",
    "        print(f\"  ✓ Found {len(series_data)} series in Companies category\")\n",
    "    else:\n",
    "        print(f\"  ✗ Error: Status {response.status_code}\")\n",
    "    time.sleep(0.5)\n",
    "except Exception as e:\n",
    "    print(f\"  ✗ Error fetching Companies category: {e}\")\n",
    "\n",
    "# If category search fails, try keyword-based search\n",
    "if len(companies_series) == 0:\n",
    "    print(\"\\n  Category search returned no results. Trying keyword search...\")\n",
    "    \n",
    "    # Try different company-related keywords\n",
    "    search_keywords = [\"stock\", \"company\", \"earnings\", \"revenue\", \"nasdaq\", \"dow\", \"sp500\"]\n",
    "    \n",
    "    for keyword in search_keywords:\n",
    "        try:\n",
    "            response = requests.get(f\"{base_url_comp}/series\", params={\"limit\": 200})\n",
    "            if response.status_code == 200:\n",
    "                all_series = response.json().get('series', [])\n",
    "                # Filter by keyword\n",
    "                keyword_series = [\n",
    "                    s for s in all_series \n",
    "                    if keyword.lower() in s.get('title', '').lower() \n",
    "                    or keyword.lower() in s.get('category', '').lower()\n",
    "                    or any(keyword.lower() in tag.lower() for tag in s.get('tags', []))\n",
    "                ]\n",
    "                companies_series.extend(keyword_series)\n",
    "                if keyword_series:\n",
    "                    print(f\"    Found {len(keyword_series)} series matching '{keyword}'\")\n",
    "            time.sleep(0.5)\n",
    "        except Exception as e:\n",
    "            print(f\"    Error searching for '{keyword}': {e}\")\n",
    "\n",
    "# Deduplicate series\n",
    "unique_companies_series = {s['ticker']: s for s in companies_series}.values()\n",
    "print(f\"\\n✓ Total unique companies series: {len(unique_companies_series)}\")\n",
    "\n",
    "# Display found series\n",
    "if unique_companies_series:\n",
    "    print(\"\\nCompanies series found:\")\n",
    "    for s in list(unique_companies_series)[:10]:  # Show first 10\n",
    "        print(f\"  - {s['ticker']}: {s['title']}\")\n",
    "        print(f\"    Category: {s.get('category', 'N/A')}\")\n",
    "    if len(unique_companies_series) > 10:\n",
    "        print(f\"  ... and {len(unique_companies_series) - 10} more series\")\n",
    "\n",
    "# Store series tickers\n",
    "companies_series_tickers = [s['ticker'] for s in unique_companies_series]\n",
    "companies_series_list = list(unique_companies_series)\n",
    "\n",
    "print(f\"\\n✓ Will fetch markets for {len(companies_series_tickers)} companies series\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FETCHING MARKETS FOR COMPANIES SERIES\n",
      "================================================================================\n",
      "\n",
      "Fetching settled markets for 349 series...\n",
      "(This may take a few minutes...)\n",
      "\n",
      "  [1/349] KXDANGROSSMETA: 1 markets\n",
      "  [2/349] KXTESLAPROD: 31 markets\n",
      "  Progress: 5/349 series processed, 32 total markets\n",
      "  [6/349] KXANTITRUSTOAIMSFT: 1 markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [7/349] KXGROKMACOS: 1 markets\n",
      "  [8/349] KXNEWPRODUCTFALLOUT3REM: 1 markets\n",
      "  [9/349] KXACQANNOUNEWARNER: 5 markets\n",
      "  [10/349] KXTESLAYL: 1 markets\n",
      "  Progress: 10/349 series processed, 41 total markets\n",
      "  [11/349] KXWEWORKCEO: 1 markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  Progress: 15/349 series processed, 42 total markets\n",
      "  [16/349] KXCRYPTOPAY: 1 markets\n",
      "  [17/349] KXAAPLCEOCHANGE: 1 markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [18/349] KXROGANBOARD: 1 markets\n",
      "  [19/349] KXAPPLEFOLD: 1 markets\n",
      "  Progress: 20/349 series processed, 46 total markets\n",
      "  [22/349] KXJOINMETA: 8 markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  Progress: 25/349 series processed, 54 total markets\n",
      "  [26/349] KXRHGOLD: 24 markets\n",
      "  [27/349] KXSPIRITCEOCHANGE: 1 markets\n",
      "  [29/349] KXOAIBROWSER: 1 markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  Progress: 30/349 series processed, 80 total markets\n",
      "  [33/349] KXLLAMA5: 1 markets\n",
      "  [34/349] KXAPPLEPORT: 1 markets\n",
      "  Progress: 35/349 series processed, 82 total markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [36/349] KXROBINHOODCHAIN: 1 markets\n",
      "  [38/349] KXNEWAAPLVR: 1 markets\n",
      "  [40/349] KXMETAHEADCOUNT: 7 markets\n",
      "  Progress: 40/349 series processed, 91 total markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [42/349] KXNYTSUBS: 17 markets\n",
      "  [45/349] KXPAIDSUBAPPLEINTEL: 1 markets\n",
      "  Progress: 45/349 series processed, 109 total markets\n",
      "  [47/349] KXMUSKINJ: 1 markets\n",
      "  [48/349] KXAAPLRING: 1 markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  Progress: 50/349 series processed, 111 total markets\n",
      "  [54/349] KXMERCHLISTPALANTIR: 5 markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  Progress: 55/349 series processed, 116 total markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [60/349] KXTESLA: 39 markets\n",
      "  Progress: 60/349 series processed, 155 total markets\n",
      "  [63/349] KXCEOINTC: 1 markets\n",
      "  [64/349] KXRELOCATENYCFL: 5 markets\n",
      "  Progress: 65/349 series processed, 161 total markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [66/349] KXNEWROLEX: 11 markets\n",
      "  [67/349] KXCLAUDE4: 1 markets\n",
      "  Progress: 70/349 series processed, 173 total markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [72/349] KXBOEINGCEOCHANGE: 1 markets\n",
      "  [73/349] KXNYTVISITPALANTIR: 1 markets\n",
      "  Progress: 75/349 series processed, 175 total markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [80/349] KXAIRTAG2: 1 markets\n",
      "  Progress: 80/349 series processed, 176 total markets\n",
      "  [82/349] KXISMPMI: 49 markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [84/349] KXTESLAROADSTER: 1 markets\n",
      "  Progress: 85/349 series processed, 226 total markets\n",
      "  [88/349] KXNINTENDOZELDA: 1 markets\n",
      "  [89/349] KXLEAVEANTHROPIC: 8 markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [90/349] KXSWBAGS: 1 markets\n",
      "  Progress: 90/349 series processed, 236 total markets\n",
      "  [92/349] KXSUBWAY: 3 markets\n",
      "  [95/349] KXCANCELTHELINE: 1 markets\n",
      "  Progress: 95/349 series processed, 240 total markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [96/349] KXACQANNOUNCECHROME: 1 markets\n",
      "  [98/349] KXINDIAX: 1 markets\n",
      "  [99/349] KXCEOMETA: 1 markets\n",
      "  [100/349] KXPLANETFITNESSSUBS: 1 markets\n",
      "  Progress: 100/349 series processed, 244 total markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [101/349] KXSINNERSIMAX: 1 markets\n",
      "  [104/349] KXEXPORTTARIFF: 1 markets\n",
      "  [105/349] KXAPPRANKFREE2: 1105 markets\n",
      "  Progress: 105/349 series processed, 1351 total markets\n",
      "  [106/349] KXCEOGS: 1 markets\n",
      "  [107/349] KXSWHIRES: 7 markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [109/349] KXJOINOPENAI: 6 markets\n",
      "  [110/349] KXJOINXAI: 7 markets\n",
      "  Progress: 110/349 series processed, 1372 total markets\n",
      "  [111/349] KXGMECEOCHANGE: 1 markets\n",
      "  [112/349] KXMSFTCEO: 3 markets\n",
      "  [113/349] KXOAIPROFIT: 1 markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [114/349] KXCRACKERBARRELREBRANDREVERSE: 1 markets\n",
      "  Progress: 115/349 series processed, 1378 total markets\n",
      "  [118/349] KXMINWAGE: 1 markets\n",
      "  [119/349] KXPHANTOMREV: 1 markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  Progress: 120/349 series processed, 1380 total markets\n",
      "  [123/349] KXDISNEYSUBS: 6 markets\n",
      "  [124/349] KXGPT5: 1 markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  Progress: 125/349 series processed, 1387 total markets\n",
      "  [127/349] KXTESLAFACTORY: 1 markets\n",
      "  [128/349] KXCOMPANYBOARDOPENDOOR: 1 markets\n",
      "  [129/349] KXNPRCEOCHANGE: 1 markets\n",
      "  Progress: 130/349 series processed, 1390 total markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [131/349] KXRELEASEIPHONE: 1 markets\n",
      "  [134/349] KXIPO: 26 markets\n",
      "  Progress: 135/349 series processed, 1417 total markets\n",
      "  [136/349] KXLLM1: 86 markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [138/349] KXTECHLAYOFF: 11 markets\n",
      "  Progress: 140/349 series processed, 1514 total markets\n",
      "  [141/349] KXREVIEWRELEASEMKBHDFRIEND: 1 markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [143/349] KXAMCCEOCHANGE: 1 markets\n",
      "  Progress: 145/349 series processed, 1516 total markets\n",
      "  [146/349] KXPRIVACYUPDATENYT: 1 markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [149/349] KXCEOAMAZON: 1 markets\n",
      "  [150/349] KXNEXTYACCARINO: 4 markets\n",
      "  Progress: 150/349 series processed, 1522 total markets\n",
      "  [154/349] KXGOOGLECEOCHANGE: 1 markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [155/349] KXSPACEXSTARSHIP: 39 markets\n",
      "  Progress: 155/349 series processed, 1562 total markets\n",
      "  [156/349] KXLEAVESEANCOOK: 1 markets\n",
      "  [157/349] KXVINE: 1 markets\n",
      "  [158/349] KXMUSKCABLE: 1 markets\n",
      "  [159/349] KXMYSTERYSTOCKBUFFET: 5 markets\n",
      "  Progress: 160/349 series processed, 1570 total markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [162/349] KXCEOUSSTEEL: 1 markets\n",
      "  Progress: 165/349 series processed, 1571 total markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [167/349] KXCEOROBLOX: 1 markets\n",
      "  [168/349] KXAIRTAGS2PRICE: 1 markets\n",
      "  [170/349] KXLAYOFFSYINFO: 2 markets\n",
      "  Progress: 170/349 series processed, 1575 total markets\n",
      "  [172/349] KXWEALTHY: 7 markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [173/349] KXDEEPSEEKV4RELEASE: 1 markets\n",
      "  Progress: 175/349 series processed, 1583 total markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [179/349] KXJOINANTHROPIC: 4 markets\n",
      "  Progress: 180/349 series processed, 1587 total markets\n",
      "  [182/349] KXCORPTAXCUT: 1 markets\n",
      "  [183/349] KXCEOCLUELY: 1 markets\n",
      "  [184/349] KXDANAWHITEFB: 1 markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  Progress: 185/349 series processed, 1590 total markets\n",
      "  [188/349] KXCARDFEECHASESAPH: 1 markets\n",
      "  [189/349] KXROBOTAXIOUT: 1 markets\n",
      "  Progress: 190/349 series processed, 1592 total markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [191/349] KXAPPRANKFREE: 1430 markets\n",
      "  [194/349] KXTRUMPPHONE: 1 markets\n",
      "  Progress: 195/349 series processed, 3023 total markets\n",
      "  [196/349] KXNEWPRODUCTMICROSOFT: 1 markets\n",
      "  [197/349] KXCEOASTRONOMER: 1 markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  Progress: 200/349 series processed, 3025 total markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [204/349] KXGEMINI3: 3 markets\n",
      "  Progress: 205/349 series processed, 3028 total markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [210/349] KXLEAVEXAI: 12 markets\n",
      "  Progress: 210/349 series processed, 3040 total markets\n",
      "  [211/349] KXCBVOLUME: 34 markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  Progress: 215/349 series processed, 3074 total markets\n",
      "  [218/349] KXOPENDOORCEO: 5 markets\n",
      "  [219/349] KXSP500BTCPURCHASE: 1 markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  Progress: 220/349 series processed, 3080 total markets\n",
      "  [222/349] KXMETADAP: 13 markets\n",
      "  [224/349] KXDEEPSEEKR2RELEASE: 1 markets\n",
      "  [225/349] KXRENAMECOMMANDERS: 1 markets\n",
      "  Progress: 225/349 series processed, 3095 total markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [227/349] KXRENAMEGUARDIANS: 1 markets\n",
      "  [229/349] KXCEOTARGET: 1 markets\n",
      "  [230/349] KXJONYIVEMETA: 1 markets\n",
      "  Progress: 230/349 series processed, 3098 total markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [235/349] KXALTMANEQUITY: 1 markets\n",
      "  Progress: 235/349 series processed, 3099 total markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [239/349] KXJOINAPPLEJB: 1 markets\n",
      "  [240/349] KXCEOYCOMB: 1 markets\n",
      "  Progress: 240/349 series processed, 3101 total markets\n",
      "  [241/349] KXCLAUDE5: 1 markets\n",
      "  [242/349] KXLEAVEJONYIVEOAI: 1 markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [243/349] KXJOINSTEPHENCOLBERT: 8 markets\n",
      "  Progress: 245/349 series processed, 3111 total markets\n",
      "  [246/349] KXMUSKPACKAGEVOTE: 1 markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [250/349] KXSPOTIFYSUBS: 14 markets\n",
      "  Progress: 250/349 series processed, 3126 total markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  Progress: 255/349 series processed, 3126 total markets\n",
      "  [256/349] KXNEWROLEOPENDOOR: 1 markets\n",
      "  [258/349] KXPS6: 1 markets\n",
      "  [260/349] KXNEWMETAVR: 1 markets\n",
      "  Progress: 260/349 series processed, 3129 total markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [261/349] KXACQANNOUNCEMISTRAL: 4 markets\n",
      "  [265/349] KXJOINBARSTOOL: 1 markets\n",
      "  Progress: 265/349 series processed, 3134 total markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [266/349] KXFOXONE: 6 markets\n",
      "  [270/349] KXTESLACEOCHANGE: 1 markets\n",
      "  Progress: 270/349 series processed, 3141 total markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [273/349] KXCITITOKEN: 1 markets\n",
      "  Progress: 275/349 series processed, 3142 total markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [277/349] KXOPENAICEOCHANGE: 1 markets\n",
      "  [280/349] KXCEOMRNA: 1 markets\n",
      "  Progress: 280/349 series processed, 3144 total markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [283/349] KXXCEOCHANGE: 1 markets\n",
      "  [285/349] KXFSDMARKET: 1 markets\n",
      "  Progress: 285/349 series processed, 3146 total markets\n",
      "  [287/349] KXXAIREASON: 1 markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  Progress: 290/349 series processed, 3147 total markets\n",
      "  [291/349] KXLEAVEMAGUIRESEQUOIA: 1 markets\n",
      "  [293/349] KXLEAVEOPENAI: 8 markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [294/349] KXCEOTWITCH: 1 markets\n",
      "  Progress: 295/349 series processed, 3157 total markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  Progress: 300/349 series processed, 3157 total markets\n",
      "  [302/349] KXMEEKMILLAI: 1 markets\n",
      "  [303/349] KXWIKIMEDIA: 1 markets\n",
      "  [304/349] KXCEOPFE: 1 markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [305/349] KXGROK4: 1 markets\n",
      "  Progress: 305/349 series processed, 3161 total markets\n",
      "  [308/349] KXJPMCEOCHANGE: 1 markets\n",
      "  [309/349] KXUSCOMPANYSTAKE: 1 markets\n",
      "  Progress: 310/349 series processed, 3163 total markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [314/349] KXNONCOMPETEBAN: 1 markets\n",
      "  Progress: 315/349 series processed, 3164 total markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  Progress: 320/349 series processed, 3164 total markets\n",
      "  [321/349] KXO3RELEASE: 1 markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [325/349] KXJUULFLAVOR: 8 markets\n",
      "  Progress: 325/349 series processed, 3173 total markets\n",
      "  [326/349] KXGODOFWARXBOX: 1 markets\n",
      "  [327/349] KXNEXTCOMPANYSP500: 5 markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [328/349] KXDISCEOCHANGE: 1 markets\n",
      "  Progress: 330/349 series processed, 3180 total markets\n",
      "  [331/349] KXBOEING: 8 markets\n",
      "  [332/349] KXNATFRIEDMANMETA: 1 markets\n",
      "  [333/349] KXSBGUESTS: 8 markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [334/349] KXACQUANNOUNCETIKTOK: 1 markets\n",
      "  Progress: 335/349 series processed, 3198 total markets\n",
      "  [336/349] KXNEWROLEVOGUE: 9 markets\n",
      "  [337/349] KXLEAVEJANGS: 1 markets\n",
      "  [338/349] KXSOFIMEMBERS: 9 markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  Progress: 340/349 series processed, 3217 total markets\n",
      "  [341/349] KXSPACEXCOUNT: 24 markets\n",
      "  [342/349] KXJOINKARPATHY: 3 markets\n",
      "  [343/349] KXCOMPANYACTIONYOUTUBE: 6 markets\n",
      "  Progress: 345/349 series processed, 3250 total markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [346/349] KXLEAVEMETA: 4 markets\n",
      "  [349/349] KXOAIAGI: 1 markets\n",
      "\n",
      "================================================================================\n",
      "✓ TOTAL MARKETS FETCHED: 3255\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 2: Fetch All Markets for Companies Series\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FETCHING MARKETS FOR COMPANIES SERIES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Fetch all markets for companies series\n",
    "all_companies_markets = []\n",
    "\n",
    "print(f\"\\nFetching settled markets for {len(companies_series_tickers)} series...\")\n",
    "print(\"(This may take a few minutes...)\\n\")\n",
    "\n",
    "for i, series_ticker in enumerate(companies_series_tickers, 1):\n",
    "    cursor = None\n",
    "    series_markets = []\n",
    "    \n",
    "    while True:\n",
    "        params = {\n",
    "            \"series_ticker\": series_ticker,\n",
    "            \"status\": \"settled\",\n",
    "            \"min_close_ts\": min_close_ts_comp,\n",
    "            \"max_close_ts\": max_close_ts_comp,\n",
    "            \"limit\": 1000\n",
    "        }\n",
    "        \n",
    "        if cursor:\n",
    "            params[\"cursor\"] = cursor\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(f\"{base_url_comp}/markets\", params=params)\n",
    "            \n",
    "            if response.status_code == 429:\n",
    "                print(f\"  Rate limited, waiting 2 seconds...\")\n",
    "                time.sleep(2)\n",
    "                continue\n",
    "            \n",
    "            if response.status_code != 200:\n",
    "                print(f\"  ✗ Error for {series_ticker}: Status {response.status_code}\")\n",
    "                break\n",
    "            \n",
    "            data = response.json()\n",
    "            markets = data.get('markets', [])\n",
    "            series_markets.extend(markets)\n",
    "            \n",
    "            cursor = data.get('cursor')\n",
    "            if not cursor:\n",
    "                break\n",
    "            \n",
    "            time.sleep(0.3)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ Error fetching {series_ticker}: {e}\")\n",
    "            break\n",
    "    \n",
    "    if series_markets:\n",
    "        all_companies_markets.extend(series_markets)\n",
    "        print(f\"  [{i}/{len(companies_series_tickers)}] {series_ticker}: {len(series_markets)} markets\")\n",
    "    \n",
    "    if i % 5 == 0:\n",
    "        print(f\"  Progress: {i}/{len(companies_series_tickers)} series processed, {len(all_companies_markets)} total markets\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"✓ TOTAL MARKETS FETCHED: {len(all_companies_markets)}\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "companies_markets_raw = all_companies_markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "APPLYING FILTERS: DURATION 1 WEEK - 1 MONTH, LIQUIDITY >= $100,000\n",
      "================================================================================\n",
      "\n",
      "Filter Results:\n",
      "  Total markets:                3255\n",
      "  Duration filter (1w - 1m):    2668 passed\n",
      "    - Too short (< 1 week):     62\n",
      "    - Too long (> 1 month):     525\n",
      "  Liquidity filter (>=$100k):   121 passed\n",
      "  ✓ Both filters passed:        32 markets\n",
      "\n",
      "================================================================================\n",
      "✓ QUALIFIED MARKETS: 32\n",
      "================================================================================\n",
      "\n",
      "Sample qualified markets (first 5):\n",
      "\n",
      "  1. KXDANGROSSMETA-25SEP\n",
      "     Title: Will Daniel Gross join Meta before Sep 2025?\n",
      "     Duration: 9.73 days\n",
      "     Liquidity: $655.70\n",
      "     Result: yes\n",
      "\n",
      "  2. KXMERCHLISTPALANTIR-25JUL-PANTS\n",
      "     Title: What kind of new merch will Palantir drop this year?\n",
      "     Duration: 17.72 days\n",
      "     Liquidity: $175.13\n",
      "     Result: no\n",
      "\n",
      "  3. KXISMPMI-25AUG-52\n",
      "     Title: ISM Manufacturing PMI in Aug 2025?\n",
      "     Duration: 17.00 days\n",
      "     Liquidity: $1,142.88\n",
      "     Result: no\n",
      "\n",
      "  4. KXISMPMI-25AUG-51\n",
      "     Title: ISM Manufacturing PMI in Aug 2025?\n",
      "     Duration: 17.00 days\n",
      "     Liquidity: $1,695.42\n",
      "     Result: no\n",
      "\n",
      "  5. KXISMPMI-25AUG-50\n",
      "     Title: ISM Manufacturing PMI in Aug 2025?\n",
      "     Duration: 17.00 days\n",
      "     Liquidity: $1,536.57\n",
      "     Result: no\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 3: Filter by Duration (1 Week to 1 Month) and Liquidity\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"APPLYING FILTERS: DURATION 1 WEEK - 1 MONTH, LIQUIDITY >= $100,000\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "MIN_DURATION_HOURS_COMP = 24\n",
    "MAX_DURATION_HOURS_COMP = 30 * 24\n",
    "MIN_LIQUIDITY_DOLLARS_COMP = 100\n",
    "\n",
    "filtered_companies_markets = []\n",
    "filter_stats_comp = {\n",
    "    'total': len(companies_markets_raw),\n",
    "    'duration_pass': 0,\n",
    "    'liquidity_pass': 0,\n",
    "    'both_pass': 0,\n",
    "    'too_short': 0,\n",
    "    'too_long': 0,\n",
    "    'liquidity_fail': 0\n",
    "}\n",
    "\n",
    "for market in companies_markets_raw:\n",
    "    try:\n",
    "        open_time = datetime.fromisoformat(market['open_time'].replace('Z', '+00:00'))\n",
    "        close_time = datetime.fromisoformat(market['close_time'].replace('Z', '+00:00'))\n",
    "        duration_hours = (close_time - open_time).total_seconds() / 3600\n",
    "        liquidity_dollars = float(market.get('liquidity_dollars', '0'))\n",
    "        \n",
    "        duration_ok = MIN_DURATION_HOURS_COMP <= duration_hours <= MAX_DURATION_HOURS_COMP\n",
    "        liquidity_ok = liquidity_dollars >= MIN_LIQUIDITY_DOLLARS_COMP\n",
    "        \n",
    "        if duration_ok:\n",
    "            filter_stats_comp['duration_pass'] += 1\n",
    "        else:\n",
    "            if duration_hours < MIN_DURATION_HOURS_COMP:\n",
    "                filter_stats_comp['too_short'] += 1\n",
    "            else:\n",
    "                filter_stats_comp['too_long'] += 1\n",
    "        \n",
    "        if liquidity_ok:\n",
    "            filter_stats_comp['liquidity_pass'] += 1\n",
    "        else:\n",
    "            filter_stats_comp['liquidity_fail'] += 1\n",
    "        \n",
    "        if duration_ok and liquidity_ok:\n",
    "            market['duration_hours'] = duration_hours\n",
    "            market['liquidity_dollars_float'] = liquidity_dollars\n",
    "            filtered_companies_markets.append(market)\n",
    "            filter_stats_comp['both_pass'] += 1\n",
    "    except Exception as e:\n",
    "        continue\n",
    "\n",
    "print(f\"\\nFilter Results:\")\n",
    "print(f\"  Total markets:                {filter_stats_comp['total']}\")\n",
    "print(f\"  Duration filter (1w - 1m):    {filter_stats_comp['duration_pass']} passed\")\n",
    "print(f\"    - Too short (< 1 week):     {filter_stats_comp['too_short']}\")\n",
    "print(f\"    - Too long (> 1 month):     {filter_stats_comp['too_long']}\")\n",
    "print(f\"  Liquidity filter (>=$100k):   {filter_stats_comp['liquidity_pass']} passed\")\n",
    "print(f\"  ✓ Both filters passed:        {filter_stats_comp['both_pass']} markets\")\n",
    "\n",
    "if filter_stats_comp['both_pass'] == 0:\n",
    "    print(\"\\n\" + \"⚠\"*40)\n",
    "    print(\"⚠ NO MARKETS PASSED - LOWERING LIQUIDITY THRESHOLD\")\n",
    "    print(\"⚠\"*40)\n",
    "    \n",
    "    for min_liq in [50000, 25000, 10000, 5000, 0]:\n",
    "        filtered_companies_markets = []\n",
    "        for market in companies_markets_raw:\n",
    "            try:\n",
    "                open_time = datetime.fromisoformat(market['open_time'].replace('Z', '+00:00'))\n",
    "                close_time = datetime.fromisoformat(market['close_time'].replace('Z', '+00:00'))\n",
    "                duration_hours = (close_time - open_time).total_seconds() / 3600\n",
    "                liquidity_dollars = float(market.get('liquidity_dollars', '0'))\n",
    "                \n",
    "                if MIN_DURATION_HOURS_COMP <= duration_hours <= MAX_DURATION_HOURS_COMP and liquidity_dollars >= min_liq:\n",
    "                    market['duration_hours'] = duration_hours\n",
    "                    market['liquidity_dollars_float'] = liquidity_dollars\n",
    "                    filtered_companies_markets.append(market)\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        if len(filtered_companies_markets) > 0:\n",
    "            print(f\"\\n✓ Found {len(filtered_companies_markets)} markets with liquidity >= ${min_liq:,}\")\n",
    "            MIN_LIQUIDITY_DOLLARS_COMP = min_liq\n",
    "            break\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"✓ QUALIFIED MARKETS: {len(filtered_companies_markets)}\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "if filtered_companies_markets:\n",
    "    print(\"\\nSample qualified markets (first 5):\")\n",
    "    for i, m in enumerate(filtered_companies_markets[:5], 1):\n",
    "        print(f\"\\n  {i}. {m['ticker']}\")\n",
    "        print(f\"     Title: {m.get('title', 'N/A')}\")\n",
    "        print(f\"     Duration: {m['duration_hours']/24:.2f} days\")\n",
    "        print(f\"     Liquidity: ${m['liquidity_dollars_float']:,.2f}\")\n",
    "        print(f\"     Result: {m.get('result', 'N/A')}\")\n",
    "\n",
    "companies_markets_qualified = filtered_companies_markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 4: Group by Event & Calculate Entry Points (90% Time Elapsed)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GROUPING MARKETS BY EVENT & CALCULATING ENTRY POINTS (90% TIME ELAPSED)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "events_dict_comp = {}\n",
    "\n",
    "for market in companies_markets_qualified:\n",
    "    event_ticker = market.get('event_ticker', market['ticker'])\n",
    "    \n",
    "    if event_ticker not in events_dict_comp:\n",
    "        events_dict_comp[event_ticker] = []\n",
    "    \n",
    "    # Calculate entry at 90% of market duration elapsed\n",
    "    open_time = datetime.fromisoformat(market['open_time'].replace('Z', '+00:00'))\n",
    "    close_time = datetime.fromisoformat(market['close_time'].replace('Z', '+00:00'))\n",
    "    market_duration = close_time - open_time\n",
    "    entry_time = open_time + (market_duration * 0.9)  # 90% elapsed\n",
    "    \n",
    "    market['open_time_dt'] = open_time\n",
    "    market['entry_time'] = entry_time\n",
    "    market['close_time_dt'] = close_time\n",
    "    market['time_to_expiry_hours'] = (close_time - entry_time).total_seconds() / 3600\n",
    "    \n",
    "    events_dict_comp[event_ticker].append(market)\n",
    "\n",
    "print(f\"\\n✓ Found {len(events_dict_comp)} unique events\")\n",
    "\n",
    "# Show sample entry timing\n",
    "if companies_markets_qualified:\n",
    "    sample = companies_markets_qualified[0]\n",
    "    duration_days = sample['duration_hours'] / 24\n",
    "    time_to_expiry = sample['time_to_expiry_hours']\n",
    "    print(f\"\\nSample entry timing:\")\n",
    "    print(f\"  Market duration: {duration_days:.2f} days\")\n",
    "    print(f\"  Entry point: {duration_days * 0.9:.2f} days after open\")\n",
    "    print(f\"  Time remaining at entry: {time_to_expiry:.2f} hours ({time_to_expiry/24:.2f} days)\")\n",
    "\n",
    "event_classification_comp = {'single': [], 'multi': []}\n",
    "for event_ticker, markets in events_dict_comp.items():\n",
    "    if len(markets) == 1:\n",
    "        event_classification_comp['single'].append(event_ticker)\n",
    "    else:\n",
    "        event_classification_comp['multi'].append(event_ticker)\n",
    "\n",
    "print(f\"\\nEvent Classification:\")\n",
    "print(f\"  Single-outcome events: {len(event_classification_comp['single'])}\")\n",
    "print(f\"  Multi-outcome events:  {len(event_classification_comp['multi'])}\")\n",
    "\n",
    "multi_decision_events_comp = {k: v for k, v in events_dict_comp.items() if len(v) >= 2}\n",
    "print(f\"\\n✓ Multi-decision events: {len(multi_decision_events_comp)}\")\n",
    "\n",
    "if multi_decision_events_comp:\n",
    "    print(\"\\nSample multi-decision events (first 3):\")\n",
    "    for i, (event_ticker, markets) in enumerate(list(multi_decision_events_comp.items())[:3], 1):\n",
    "        print(f\"\\n  {i}. Event: {event_ticker} ({len(markets)} markets)\")\n",
    "        for m in markets[:2]:\n",
    "            print(f\"     - {m['ticker']}: ${m.get('yes_bid', 0)/100:.2f} (result: {m.get('result', 'N/A')})\")\n",
    "\n",
    "all_tradeable_events_comp = events_dict_comp.copy()\n",
    "print(f\"\\n✓ Total tradeable events: {len(all_tradeable_events_comp)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 5: Organize Events by Entry Date\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ORGANIZING EVENTS BY ENTRY DATE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "events_by_entry_date_comp = {}\n",
    "\n",
    "for event_ticker, markets in all_tradeable_events_comp.items():\n",
    "    entry_time = markets[0]['entry_time']\n",
    "    entry_date = entry_time.date()\n",
    "    \n",
    "    if entry_date not in events_by_entry_date_comp:\n",
    "        events_by_entry_date_comp[entry_date] = []\n",
    "    \n",
    "    events_by_entry_date_comp[entry_date].append({\n",
    "        'event_ticker': event_ticker,\n",
    "        'markets': markets,\n",
    "        'entry_time': entry_time,\n",
    "        'num_markets': len(markets)\n",
    "    })\n",
    "\n",
    "sorted_dates_comp = sorted(events_by_entry_date_comp.keys())\n",
    "\n",
    "print(f\"\\n✓ Trading spans {len(sorted_dates_comp)} unique dates\")\n",
    "if sorted_dates_comp:\n",
    "    print(f\"  First entry date: {sorted_dates_comp[0]}\")\n",
    "    print(f\"  Last entry date:  {sorted_dates_comp[-1]}\")\n",
    "\n",
    "events_per_day_comp = [len(events) for events in events_by_entry_date_comp.values()]\n",
    "if events_per_day_comp:\n",
    "    print(f\"\\nEvents per day:\")\n",
    "    print(f\"  Average: {np.mean(events_per_day_comp):.2f}\")\n",
    "    print(f\"  Max: {np.max(events_per_day_comp)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 6: Simulate Trading Strategy (10% Liquidity Position Sizing)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SIMULATING TRADING STRATEGY (10% LIQUIDITY POSITION SIZING)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "INITIAL_CAPITAL_COMP = 100000\n",
    "LIQUIDITY_PERCENTAGE = 0.10  # 10% of market liquidity\n",
    "YES_ALLOCATION_COMP = 0.70   # 70% of position on YES\n",
    "NO_ALLOCATION_COMP = 0.30    # 30% of position split across NOs\n",
    "\n",
    "all_trades_comp = []\n",
    "trade_id_comp = 0\n",
    "total_exposure_by_date_comp = {}\n",
    "\n",
    "print(f\"Position sizing: 10% of each market's liquidity\")\n",
    "print(f\"Multi-decision split: 70% YES favorite, 30% across NOs\\n\")\n",
    "\n",
    "for date in sorted_dates_comp:\n",
    "    events_today = events_by_entry_date_comp[date]\n",
    "    if len(events_today) == 0:\n",
    "        continue\n",
    "    \n",
    "    daily_exposure = 0\n",
    "    \n",
    "    for event in events_today:\n",
    "        markets = event['markets']\n",
    "        \n",
    "        if len(markets) >= 2:\n",
    "            # Multi-decision: YES on favorite, NO on others\n",
    "            favorite = max(markets, key=lambda m: m.get('yes_bid', 0))\n",
    "            others = [m for m in markets if m != favorite]\n",
    "            \n",
    "            # Position size = 10% of favorite's liquidity\n",
    "            base_position = favorite['liquidity_dollars_float'] * LIQUIDITY_PERCENTAGE\n",
    "            yes_size = base_position * YES_ALLOCATION_COMP\n",
    "            no_size = base_position * NO_ALLOCATION_COMP\n",
    "            no_per_market = no_size / len(others) if others else 0\n",
    "            \n",
    "            # YES on favorite\n",
    "            yes_price = favorite.get('yes_ask', favorite.get('yes_bid', 50))\n",
    "            yes_contracts = (yes_size * 100) / yes_price if yes_price > 0 else 0\n",
    "            yes_pnl = yes_contracts * (100 - yes_price) / 100 if favorite.get('result') == 'yes' else (-yes_size if favorite.get('result') == 'no' else 0)\n",
    "            \n",
    "            trade_id_comp += 1\n",
    "            all_trades_comp.append({\n",
    "                'trade_id': trade_id_comp, 'event_ticker': event['event_ticker'], 'ticker': favorite['ticker'],\n",
    "                'entry_date': date, 'close_time': favorite['close_time_dt'], 'side': 'YES',\n",
    "                'price': yes_price / 100, 'investment': yes_size, 'result': favorite.get('result', 'unknown'),\n",
    "                'pnl': yes_pnl, 'liquidity': favorite.get('liquidity_dollars_float', 0),\n",
    "                'duration_days': favorite.get('duration_hours', 0) / 24,\n",
    "                'time_to_expiry_days': favorite['time_to_expiry_hours'] / 24,\n",
    "                'entry_time': favorite['entry_time']\n",
    "            })\n",
    "            daily_exposure += yes_size\n",
    "            \n",
    "            # NO on others\n",
    "            for other in others:\n",
    "                no_price = other.get('no_ask', other.get('no_bid', 50))\n",
    "                no_contracts = (no_per_market * 100) / no_price if no_price > 0 else 0\n",
    "                no_pnl = no_contracts * (100 - no_price) / 100 if other.get('result') == 'no' else (-no_per_market if other.get('result') == 'yes' else 0)\n",
    "                \n",
    "                trade_id_comp += 1\n",
    "                all_trades_comp.append({\n",
    "                    'trade_id': trade_id_comp, 'event_ticker': event['event_ticker'], 'ticker': other['ticker'],\n",
    "                    'entry_date': date, 'close_time': other['close_time_dt'], 'side': 'NO',\n",
    "                    'price': no_price / 100, 'investment': no_per_market, 'result': other.get('result', 'unknown'),\n",
    "                    'pnl': no_pnl, 'liquidity': other.get('liquidity_dollars_float', 0),\n",
    "                    'duration_days': other.get('duration_hours', 0) / 24,\n",
    "                    'time_to_expiry_days': other['time_to_expiry_hours'] / 24,\n",
    "                    'entry_time': other['entry_time']\n",
    "                })\n",
    "                daily_exposure += no_per_market\n",
    "        else:\n",
    "            # Single binary market\n",
    "            market = markets[0]\n",
    "            position_size = market['liquidity_dollars_float'] * LIQUIDITY_PERCENTAGE\n",
    "            yes_bid = market.get('yes_bid', 50)\n",
    "            \n",
    "            if yes_bid >= 50:\n",
    "                # Buy YES\n",
    "                price = market.get('yes_ask', yes_bid)\n",
    "                contracts = (position_size * 100) / price if price > 0 else 0\n",
    "                pnl = contracts * (100 - price) / 100 if market.get('result') == 'yes' else (-position_size if market.get('result') == 'no' else 0)\n",
    "                side = 'YES'\n",
    "            else:\n",
    "                # Buy NO\n",
    "                price = market.get('no_ask', 100 - yes_bid)\n",
    "                contracts = (position_size * 100) / price if price > 0 else 0\n",
    "                pnl = contracts * (100 - price) / 100 if market.get('result') == 'no' else (-position_size if market.get('result') == 'yes' else 0)\n",
    "                side = 'NO'\n",
    "            \n",
    "            trade_id_comp += 1\n",
    "            all_trades_comp.append({\n",
    "                'trade_id': trade_id_comp, 'event_ticker': event['event_ticker'], 'ticker': market['ticker'],\n",
    "                'entry_date': date, 'close_time': market['close_time_dt'], 'side': side,\n",
    "                'price': price / 100, 'investment': position_size, 'result': market.get('result', 'unknown'),\n",
    "                'pnl': pnl, 'liquidity': market.get('liquidity_dollars_float', 0),\n",
    "                'duration_days': market.get('duration_hours', 0) / 24,\n",
    "                'time_to_expiry_days': market['time_to_expiry_hours'] / 24,\n",
    "                'entry_time': market['entry_time']\n",
    "            })\n",
    "            daily_exposure += position_size\n",
    "    \n",
    "    total_exposure_by_date_comp[date] = daily_exposure\n",
    "\n",
    "print(f\"✓ Simulation complete: {len(all_trades_comp)} trades\")\n",
    "\n",
    "# Calculate exposure statistics\n",
    "if total_exposure_by_date_comp:\n",
    "    exposures = list(total_exposure_by_date_comp.values())\n",
    "    total_capital_deployed = sum(t['investment'] for t in all_trades_comp)\n",
    "    \n",
    "    print(f\"\\nExposure Analysis:\")\n",
    "    print(f\"  Total capital deployed: ${total_capital_deployed:,.2f}\")\n",
    "    print(f\"  Avg daily exposure: ${np.mean(exposures):,.2f}\")\n",
    "    print(f\"  Max daily exposure: ${np.max(exposures):,.2f}\")\n",
    "    print(f\"  Min daily exposure: ${np.min(exposures):,.2f}\")\n",
    "\n",
    "trades_df_comp = pd.DataFrame(all_trades_comp)\n",
    "\n",
    "if not trades_df_comp.empty:\n",
    "    print(f\"\\nSample trades (first 5):\")\n",
    "    for i, row in trades_df_comp.head(5).iterrows():\n",
    "        print(f\"  {row['ticker'][:30]:<30} {row['side']:<4} ${row['investment']:>8,.0f} (liq: ${row['liquidity']:>8,.0f}) TTL: {row['time_to_expiry_days']:.1f}d\")\n",
    "\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 5: Organize Events by Entry Date\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ORGANIZING EVENTS BY ENTRY DATE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "events_by_entry_date_comp = {}\n",
    "\n",
    "for event_ticker, markets in all_tradeable_events_comp.items():\n",
    "    entry_time = markets[0]['entry_time']\n",
    "    entry_date = entry_time.date()\n",
    "    \n",
    "    if entry_date not in events_by_entry_date_comp:\n",
    "        events_by_entry_date_comp[entry_date] = []\n",
    "    \n",
    "    events_by_entry_date_comp[entry_date].append({\n",
    "        'event_ticker': event_ticker,\n",
    "        'markets': markets,\n",
    "        'entry_time': entry_time,\n",
    "        'num_markets': len(markets)\n",
    "    })\n",
    "\n",
    "sorted_dates_comp = sorted(events_by_entry_date_comp.keys())\n",
    "\n",
    "print(f\"\\n✓ Trading spans {len(sorted_dates_comp)} unique dates\")\n",
    "if sorted_dates_comp:\n",
    "    print(f\"  First entry date: {sorted_dates_comp[0]}\")\n",
    "    print(f\"  Last entry date:  {sorted_dates_comp[-1]}\")\n",
    "\n",
    "events_per_day_comp = [len(events) for events in events_by_entry_date_comp.values()]\n",
    "if events_per_day_comp:\n",
    "    print(f\"\\nEvents per day:\")\n",
    "    print(f\"  Average: {np.mean(events_per_day_comp):.2f}\")\n",
    "    print(f\"  Max: {np.max(events_per_day_comp)}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 6: Simulate Trading Strategy\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SIMULATING TRADING STRATEGY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "INITIAL_CAPITAL_COMP = 100000\n",
    "DAILY_BUDGET_COMP = 10000\n",
    "YES_ALLOCATION_COMP = 0.70\n",
    "NO_ALLOCATION_COMP = 0.30\n",
    "\n",
    "all_trades_comp = []\n",
    "trade_id_comp = 0\n",
    "\n",
    "print(f\"\\nStrategy: $100k capital, $10k daily, 70% YES / 30% NO split\")\n",
    "print(f\"\\nProcessing {len(sorted_dates_comp)} trading days...\")\n",
    "\n",
    "for date in sorted_dates_comp:\n",
    "    events_today = events_by_entry_date_comp[date]\n",
    "    if len(events_today) == 0:\n",
    "        continue\n",
    "    \n",
    "    budget_per_event = DAILY_BUDGET_COMP / len(events_today)\n",
    "    \n",
    "    for event in events_today:\n",
    "        markets = event['markets']\n",
    "        \n",
    "        if len(markets) >= 2:\n",
    "            # Multi-decision\n",
    "            favorite = max(markets, key=lambda m: m.get('yes_bid', 0))\n",
    "            others = [m for m in markets if m != favorite]\n",
    "            \n",
    "            yes_size = budget_per_event * YES_ALLOCATION_COMP\n",
    "            no_size = budget_per_event * NO_ALLOCATION_COMP\n",
    "            no_per_market = no_size / len(others) if others else 0\n",
    "            \n",
    "            # YES on favorite\n",
    "            yes_price = favorite.get('yes_ask', favorite.get('yes_bid', 50))\n",
    "            yes_contracts = (yes_size * 100) / yes_price if yes_price > 0 else 0\n",
    "            yes_pnl = yes_contracts * (100 - yes_price) / 100 if favorite.get('result') == 'yes' else (-yes_size if favorite.get('result') == 'no' else 0)\n",
    "            \n",
    "            trade_id_comp += 1\n",
    "            all_trades_comp.append({\n",
    "                'trade_id': trade_id_comp, 'event_ticker': event['event_ticker'], 'ticker': favorite['ticker'],\n",
    "                'entry_date': date, 'close_time': favorite['close_time_dt'], 'side': 'YES',\n",
    "                'price': yes_price / 100, 'investment': yes_size, 'result': favorite.get('result', 'unknown'),\n",
    "                'pnl': yes_pnl, 'liquidity': favorite.get('liquidity_dollars_float', 0),\n",
    "                'duration_days': favorite.get('duration_hours', 0) / 24\n",
    "            })\n",
    "            \n",
    "            # NO on others\n",
    "            for other in others:\n",
    "                no_price = other.get('no_ask', other.get('no_bid', 50))\n",
    "                no_contracts = (no_per_market * 100) / no_price if no_price > 0 else 0\n",
    "                no_pnl = no_contracts * (100 - no_price) / 100 if other.get('result') == 'no' else (-no_per_market if other.get('result') == 'yes' else 0)\n",
    "                \n",
    "                trade_id_comp += 1\n",
    "                all_trades_comp.append({\n",
    "                    'trade_id': trade_id_comp, 'event_ticker': event['event_ticker'], 'ticker': other['ticker'],\n",
    "                    'entry_date': date, 'close_time': other['close_time_dt'], 'side': 'NO',\n",
    "                    'price': no_price / 100, 'investment': no_per_market, 'result': other.get('result', 'unknown'),\n",
    "                    'pnl': no_pnl, 'liquidity': other.get('liquidity_dollars_float', 0),\n",
    "                    'duration_days': other.get('duration_hours', 0) / 24\n",
    "                })\n",
    "        else:\n",
    "            # Single binary\n",
    "            market = markets[0]\n",
    "            yes_bid = market.get('yes_bid', 50)\n",
    "            \n",
    "            if yes_bid >= 50:\n",
    "                price = market.get('yes_ask', yes_bid)\n",
    "                contracts = (budget_per_event * 100) / price if price > 0 else 0\n",
    "                pnl = contracts * (100 - price) / 100 if market.get('result') == 'yes' else (-budget_per_event if market.get('result') == 'no' else 0)\n",
    "                side = 'YES'\n",
    "            else:\n",
    "                price = market.get('no_ask', 100 - yes_bid)\n",
    "                contracts = (budget_per_event * 100) / price if price > 0 else 0\n",
    "                pnl = contracts * (100 - price) / 100 if market.get('result') == 'no' else (-budget_per_event if market.get('result') == 'yes' else 0)\n",
    "                side = 'NO'\n",
    "            \n",
    "            trade_id_comp += 1\n",
    "            all_trades_comp.append({\n",
    "                'trade_id': trade_id_comp, 'event_ticker': event['event_ticker'], 'ticker': market['ticker'],\n",
    "                'entry_date': date, 'close_time': market['close_time_dt'], 'side': side,\n",
    "                'price': price / 100, 'investment': budget_per_event, 'result': market.get('result', 'unknown'),\n",
    "                'pnl': pnl, 'liquidity': market.get('liquidity_dollars_float', 0),\n",
    "                'duration_days': market.get('duration_hours', 0) / 24\n",
    "            })\n",
    "\n",
    "print(f\"\\n✓ Simulation complete: {len(all_trades_comp)} trades\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "trades_df_comp = pd.DataFrame(all_trades_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 7: Build Equity Curve, Calculate Metrics, Analyze Top 5%, and Summary\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PERFORMANCE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if trades_df_comp.empty:\n",
    "    print(\"\\n⚠ WARNING: No trades to analyze!\")\n",
    "else:\n",
    "    # ========== BUILD EQUITY CURVE ==========\n",
    "    trades_df_comp['close_date'] = trades_df_comp['close_time'].dt.date\n",
    "    daily_pnl_comp = trades_df_comp.groupby('close_date')['pnl'].sum().sort_index()\n",
    "    \n",
    "    equity_curve_comp = pd.Series(dtype=float)\n",
    "    equity_curve_comp[daily_pnl_comp.index[0]] = INITIAL_CAPITAL_COMP\n",
    "    \n",
    "    for date in daily_pnl_comp.index:\n",
    "        prev_equity = equity_curve_comp.iloc[-1]\n",
    "        equity_curve_comp[date] = prev_equity + daily_pnl_comp[date]\n",
    "    \n",
    "    equity_df_comp = pd.DataFrame({\n",
    "        'date': equity_curve_comp.index,\n",
    "        'equity': equity_curve_comp.values,\n",
    "        'daily_pnl': [0] + list(daily_pnl_comp.values)\n",
    "    })\n",
    "    \n",
    "    equity_df_comp['daily_return'] = equity_df_comp['equity'].pct_change()\n",
    "    equity_df_comp['cumulative_return'] = (equity_df_comp['equity'] / INITIAL_CAPITAL_COMP - 1) * 100\n",
    "    equity_df_comp['running_max'] = equity_df_comp['equity'].cummax()\n",
    "    equity_df_comp['drawdown'] = (equity_df_comp['equity'] - equity_df_comp['running_max']) / equity_df_comp['running_max'] * 100\n",
    "    \n",
    "    # ========== CALCULATE METRICS ==========\n",
    "    total_return_pct_comp = (equity_df_comp['equity'].iloc[-1] / INITIAL_CAPITAL_COMP - 1) * 100\n",
    "    total_pnl_comp = equity_df_comp['equity'].iloc[-1] - INITIAL_CAPITAL_COMP\n",
    "    \n",
    "    days_trading_comp = (equity_df_comp['date'].iloc[-1] - equity_df_comp['date'].iloc[0]).days\n",
    "    years_trading_comp = days_trading_comp / 365.25\n",
    "    cagr_comp = ((equity_df_comp['equity'].iloc[-1] / INITIAL_CAPITAL_COMP) ** (1 / years_trading_comp) - 1) * 100 if years_trading_comp > 0 else 0\n",
    "    \n",
    "    daily_returns_comp = equity_df_comp['daily_return'].dropna()\n",
    "    if len(daily_returns_comp) > 1:\n",
    "        sharpe_ratio_comp = (daily_returns_comp.mean() / daily_returns_comp.std() * np.sqrt(252)) if daily_returns_comp.std() > 0 else 0\n",
    "        downside_std_comp = daily_returns_comp[daily_returns_comp < 0].std() if len(daily_returns_comp[daily_returns_comp < 0]) > 1 else 0\n",
    "        sortino_ratio_comp = (daily_returns_comp.mean() / downside_std_comp * np.sqrt(252)) if downside_std_comp > 0 else 0\n",
    "    else:\n",
    "        sharpe_ratio_comp = 0\n",
    "        sortino_ratio_comp = 0\n",
    "    \n",
    "    max_drawdown_comp = equity_df_comp['drawdown'].min()\n",
    "    avg_drawdown_comp = equity_df_comp['drawdown'][equity_df_comp['drawdown'] < 0].mean()\n",
    "    \n",
    "    total_trades_comp = len(trades_df_comp)\n",
    "    winning_trades_comp = len(trades_df_comp[trades_df_comp['pnl'] > 0])\n",
    "    losing_trades_comp = len(trades_df_comp[trades_df_comp['pnl'] < 0])\n",
    "    win_rate_comp = (winning_trades_comp / total_trades_comp * 100) if total_trades_comp > 0 else 0\n",
    "    \n",
    "    avg_win_comp = trades_df_comp[trades_df_comp['pnl'] > 0]['pnl'].mean() if winning_trades_comp > 0 else 0\n",
    "    avg_loss_comp = trades_df_comp[trades_df_comp['pnl'] < 0]['pnl'].mean() if losing_trades_comp > 0 else 0\n",
    "    \n",
    "    profit_factor_comp = (trades_df_comp[trades_df_comp['pnl'] > 0]['pnl'].sum() / \n",
    "                         abs(trades_df_comp[trades_df_comp['pnl'] < 0]['pnl'].sum())) if losing_trades_comp > 0 else float('inf')\n",
    "    expectancy_comp = trades_df_comp['pnl'].mean()\n",
    "    \n",
    "    # ========== TOP 5% LIQUIDITY ==========\n",
    "    liquidity_95th_percentile_comp = trades_df_comp['liquidity'].quantile(0.95)\n",
    "    top_5_pct_trades_comp = trades_df_comp[trades_df_comp['liquidity'] >= liquidity_95th_percentile_comp]\n",
    "    \n",
    "    if len(top_5_pct_trades_comp) > 0:\n",
    "        top_5_pnl_comp = top_5_pct_trades_comp['pnl'].sum()\n",
    "        top_5_win_rate_comp = (len(top_5_pct_trades_comp[top_5_pct_trades_comp['pnl'] > 0]) / len(top_5_pct_trades_comp) * 100)\n",
    "        \n",
    "        top_5_daily_pnl_comp = top_5_pct_trades_comp.groupby('close_date')['pnl'].sum().sort_index()\n",
    "        top_5_equity_comp = pd.Series(dtype=float)\n",
    "        top_5_equity_comp[top_5_daily_pnl_comp.index[0]] = INITIAL_CAPITAL_COMP\n",
    "        for date in top_5_daily_pnl_comp.index:\n",
    "            top_5_equity_comp[date] = top_5_equity_comp.iloc[-1] + top_5_daily_pnl_comp[date]\n",
    "        \n",
    "        top_5_returns_comp = top_5_equity_comp.pct_change().dropna()\n",
    "        top_5_sharpe_comp = (top_5_returns_comp.mean() / top_5_returns_comp.std() * np.sqrt(252)) if len(top_5_returns_comp) > 1 and top_5_returns_comp.std() > 0 else 0\n",
    "        top_5_total_return_comp = (top_5_equity_comp.iloc[-1] / INITIAL_CAPITAL_COMP - 1) * 100\n",
    "    else:\n",
    "        top_5_sharpe_comp = 0\n",
    "        top_5_win_rate_comp = 0\n",
    "        top_5_total_return_comp = 0\n",
    "    \n",
    "    # ========== DISPLAY RESULTS ==========\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"COMPANIES MARKETS - STRATEGY PERFORMANCE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"\\n📊 RETURNS:\")\n",
    "    print(f\"  Total Return:        {total_return_pct_comp:>10.2f}%\")\n",
    "    print(f\"  Total P&L:           ${total_pnl_comp:>10,.2f}\")\n",
    "    print(f\"  CAGR:                {cagr_comp:>10.2f}%\")\n",
    "    print(f\"  Trading Period:      {days_trading_comp} days ({years_trading_comp:.2f} years)\")\n",
    "    \n",
    "    print(f\"\\n📉 RISK METRICS:\")\n",
    "    print(f\"  Sharpe Ratio:        {sharpe_ratio_comp:>10.2f}\")\n",
    "    print(f\"  Sortino Ratio:       {sortino_ratio_comp:>10.2f}\")\n",
    "    print(f\"  Max Drawdown:        {max_drawdown_comp:>10.2f}%\")\n",
    "    print(f\"  Avg Drawdown:        {avg_drawdown_comp:>10.2f}%\")\n",
    "    \n",
    "    print(f\"\\n💰 TRADE STATISTICS:\")\n",
    "    print(f\"  Total Trades:        {total_trades_comp:>10,}\")\n",
    "    print(f\"  Winning Trades:      {winning_trades_comp:>10,}\")\n",
    "    print(f\"  Win Rate:            {win_rate_comp:>10.1f}%\")\n",
    "    print(f\"  Avg Win:             ${avg_win_comp:>10,.2f}\")\n",
    "    print(f\"  Avg Loss:            ${avg_loss_comp:>10,.2f}\")\n",
    "    print(f\"  Profit Factor:       {profit_factor_comp if profit_factor_comp != float('inf') else 'N/A':>10}\")\n",
    "    print(f\"  Expectancy/Trade:    ${expectancy_comp:>10,.2f}\")\n",
    "    \n",
    "    print(f\"\\n🔝 TOP 5% LIQUIDITY (>= ${liquidity_95th_percentile_comp:,.2f}):\")\n",
    "    print(f\"  Trades:              {len(top_5_pct_trades_comp):>10,}\")\n",
    "    print(f\"  Total Return:        {top_5_total_return_comp:>10.2f}%\")\n",
    "    print(f\"  Sharpe Ratio:        {top_5_sharpe_comp:>10.2f}\")\n",
    "    print(f\"  Win Rate:            {top_5_win_rate_comp:>10.1f}%\")\n",
    "    \n",
    "    print(f\"\\n📊 MONTHLY BREAKDOWN:\")\n",
    "    trades_df_comp['month'] = pd.to_datetime(trades_df_comp['close_date']).dt.to_period('M')\n",
    "    monthly_pnl = trades_df_comp.groupby('month')['pnl'].sum()\n",
    "    monthly_trades = trades_df_comp.groupby('month').size()\n",
    "    \n",
    "    print(f\"  {'Month':<12} {'Trades':>8} {'P&L':>12}\")\n",
    "    print(f\"  {'-'*35}\")\n",
    "    for month in monthly_pnl.index:\n",
    "        print(f\"  {str(month):<12} {monthly_trades[month]:>8,} ${monthly_pnl[month]:>11,.2f}\")\n",
    "    \n",
    "    print(f\"\\n💡 KEY INSIGHTS:\")\n",
    "    if total_return_pct_comp > 0:\n",
    "        print(f\"  ✓ Strategy profitable: {total_return_pct_comp:.2f}% return\")\n",
    "    else:\n",
    "        print(f\"  ✗ Strategy unprofitable: {total_return_pct_comp:.2f}% return\")\n",
    "    \n",
    "    if sharpe_ratio_comp > 1:\n",
    "        print(f\"  ✓ Excellent risk-adjusted returns (Sharpe {sharpe_ratio_comp:.2f})\")\n",
    "    elif sharpe_ratio_comp > 0.5:\n",
    "        print(f\"  ~ Moderate risk-adjusted returns (Sharpe {sharpe_ratio_comp:.2f})\")\n",
    "    else:\n",
    "        print(f\"  ✗ Poor risk-adjusted returns (Sharpe {sharpe_ratio_comp:.2f})\")\n",
    "    \n",
    "    if win_rate_comp > 55:\n",
    "        print(f\"  ✓ High win rate ({win_rate_comp:.1f}%)\")\n",
    "    elif win_rate_comp > 45:\n",
    "        print(f\"  ~ Moderate win rate ({win_rate_comp:.1f}%)\")\n",
    "    else:\n",
    "        print(f\"  ✗ Low win rate ({win_rate_comp:.1f}%)\")\n",
    "    \n",
    "    if abs(max_drawdown_comp) < 10:\n",
    "        print(f\"  ✓ Low max drawdown ({abs(max_drawdown_comp):.1f}%)\")\n",
    "    elif abs(max_drawdown_comp) < 20:\n",
    "        print(f\"  ~ Moderate max drawdown ({abs(max_drawdown_comp):.1f}%)\")\n",
    "    else:\n",
    "        print(f\"  ✗ High max drawdown ({abs(max_drawdown_comp):.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n💾 DATA EXPORTS:\")\n",
    "    print(f\"  trades_df_comp          - All {len(trades_df_comp)} trades\")\n",
    "    print(f\"  equity_df_comp          - Daily equity curve\")\n",
    "    print(f\"  top_5_pct_trades_comp   - Top 5% liquidity trades\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"BACKTEST COMPLETE!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
