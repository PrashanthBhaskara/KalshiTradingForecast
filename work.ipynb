{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f983111",
   "metadata": {},
   "source": [
    "## Kalshi Research - Paper Trading \n",
    "\n",
    "### Prashanth Bhaskara"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7fd1ab",
   "metadata": {},
   "source": [
    "## Loading Keys and Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a99feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cryptography\n",
    "from cryptography.hazmat.primitives import serialization\n",
    "from cryptography.hazmat.backends import default_backend\n",
    "import base64\n",
    "from cryptography.hazmat.primitives import hashes\n",
    "from cryptography.hazmat.primitives.asymmetric import padding, rsa\n",
    "from cryptography.exceptions import InvalidSignature\n",
    "from pathlib import Path\n",
    "import os\n",
    "from cryptography.hazmat.backends import default_backend\n",
    "import requests\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0c41f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Kalshi keys ✅\n"
     ]
    }
   ],
   "source": [
    "# Cell 1 — load KALSHI keys from .env in the same directory as this notebook\n",
    "\n",
    "\n",
    "# --- Try to use python-dotenv if it's installed (recommended) ---\n",
    "try:\n",
    "    from dotenv import load_dotenv  # pip install python-dotenv\n",
    "    env_path = Path.cwd() / \".env\"   # assumes notebook is run from the same directory as .env\n",
    "    if not env_path.exists():\n",
    "        raise FileNotFoundError(f\".env not found at: {env_path}\")\n",
    "    load_dotenv(dotenv_path=env_path, override=False)\n",
    "except ImportError:\n",
    "    # --- Fallback: minimal .env parser (no extra install needed) ---\n",
    "    env_path = Path.cwd() / \".env\"\n",
    "    if not env_path.exists():\n",
    "        raise FileNotFoundError(f\".env not found at: {env_path}\")\n",
    "\n",
    "    for line in env_path.read_text().splitlines():\n",
    "        line = line.strip()\n",
    "        if not line or line.startswith(\"#\") or \"=\" not in line:\n",
    "            continue\n",
    "        k, v = line.split(\"=\", 1)\n",
    "        k = k.strip()\n",
    "        v = v.strip().strip('\"').strip(\"'\")\n",
    "        os.environ.setdefault(k, v)  # don't overwrite if already set\n",
    "\n",
    "# --- Read your keys into variables ---\n",
    "public_key = os.getenv(\"KALSHI-ACCESS-KEY-DEMO\")\n",
    "\n",
    "missing = [k for k, v in {\n",
    "    \"KALSHI-ACCESS-KEY\": public_key\n",
    "}.items() if not v]\n",
    "\n",
    "if missing:\n",
    "    raise KeyError(f\"Missing env var(s): {missing}. Check your .env formatting and key names.\")\n",
    "\n",
    "print(\"Loaded Kalshi keys ✅\")  # intentionally not printing the secret values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d15df8",
   "metadata": {},
   "source": [
    "### Next, construct functions to be able to pull Kalshi data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c940115e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_private_key_from_file(file_path):\n",
    "    with open(file_path, \"rb\") as key_file:\n",
    "        private_key = serialization.load_pem_private_key(\n",
    "            key_file.read(),\n",
    "            password=None,  # or provide a password if your key is encrypted\n",
    "            backend=default_backend()\n",
    "        )\n",
    "    return private_key\n",
    "\n",
    "\n",
    "def sign_pss_text(private_key: rsa.RSAPrivateKey, text: str) -> str:\n",
    "    message = text.encode('utf-8')\n",
    "    try:\n",
    "        signature = private_key.sign(\n",
    "            message,\n",
    "            padding.PSS(\n",
    "                mgf=padding.MGF1(hashes.SHA256()),\n",
    "                salt_length=padding.PSS.DIGEST_LENGTH\n",
    "            ),\n",
    "            hashes.SHA256()\n",
    "        )\n",
    "        return base64.b64encode(signature).decode('utf-8')\n",
    "    except InvalidSignature as e:\n",
    "        raise ValueError(\"RSA sign PSS failed\") from e\n",
    "    \n",
    "\n",
    "def make_authenticated_request(path, method='GET', params=None):\n",
    "    \"\"\"Make an authenticated request to Kalshi demo API.\"\"\"\n",
    "    current_time = datetime.datetime.now()\n",
    "    timestamp = current_time.timestamp()\n",
    "    current_time_milliseconds = int(timestamp * 1000)\n",
    "    timestamp_str = str(current_time_milliseconds)\n",
    "    \n",
    "    private_key = load_private_key_from_file('pbhaskarademo.txt')\n",
    "    \n",
    "    base_url = 'https://demo-api.kalshi.co'\n",
    "    \n",
    "    # Strip query parameters from path before signing\n",
    "    path_without_query = path.split('?')[0]\n",
    "    msg_string = timestamp_str + method + path_without_query\n",
    "    sig = sign_pss_text(private_key, msg_string)\n",
    "    \n",
    "    headers = {\n",
    "        'KALSHI-ACCESS-KEY': public_key,\n",
    "        'KALSHI-ACCESS-SIGNATURE': sig,\n",
    "        'KALSHI-ACCESS-TIMESTAMP': timestamp_str\n",
    "    }\n",
    "    \n",
    "    if method == 'GET':\n",
    "        response = requests.get(base_url + path, headers=headers, params=params)\n",
    "    else:\n",
    "        response = requests.post(base_url + path, headers=headers, json=params)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbddb70d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32c4edb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0cbf3988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PORTFOLIO BALANCE\n",
      "======================================================================\n",
      "\n",
      "  Available Balance:    $4,950.00\n",
      "  Portfolio Value:      $0.00\n",
      "  Total Value:          $4,950.00\n",
      "  Last Updated:         2026-01-31 22:27:08 EST\n",
      "\n",
      "======================================================================\n",
      "ACTIVE ORDERS (Resting)\n",
      "======================================================================\n",
      "\n",
      "  Total Active Orders: 0\n",
      "\n",
      "  No active orders found.\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'balance': {'available_balance': 4950.0,\n",
       "  'portfolio_value': 0.0,\n",
       "  'total_value': 4950.0},\n",
       " 'active_orders': []}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# === 1. Get Portfolio Balance ===\n",
    "print(\"=\" * 70)\n",
    "print(\"PORTFOLIO BALANCE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "balance_response = make_authenticated_request('/trade-api/v2/portfolio/balance')\n",
    "\n",
    "if balance_response.status_code == 200:\n",
    "    balance_data = balance_response.json()\n",
    "    \n",
    "    available_balance = balance_data.get('balance', 0) / 100  # Convert cents to dollars\n",
    "    portfolio_value = balance_data.get('portfolio_value', 0) / 100\n",
    "    updated_ts = balance_data.get('updated_ts', 0)\n",
    "    \n",
    "    if updated_ts:\n",
    "        updated_time = datetime.datetime.fromtimestamp(updated_ts, tz=datetime.timezone.utc)\n",
    "        try:\n",
    "            from zoneinfo import ZoneInfo\n",
    "            ET_TZ = ZoneInfo('America/New_York')\n",
    "            updated_time_et = updated_time.astimezone(ET_TZ).strftime('%Y-%m-%d %H:%M:%S %Z')\n",
    "        except:\n",
    "            updated_time_et = updated_time.strftime('%Y-%m-%d %H:%M:%S UTC')\n",
    "    else:\n",
    "        updated_time_et = 'N/A'\n",
    "    \n",
    "    print(f\"\\n  Available Balance:    ${available_balance:,.2f}\")\n",
    "    print(f\"  Portfolio Value:      ${portfolio_value:,.2f}\")\n",
    "    print(f\"  Total Value:          ${available_balance + portfolio_value:,.2f}\")\n",
    "    print(f\"  Last Updated:         {updated_time_et}\")\n",
    "    \n",
    "    portfolio_summary = {\n",
    "        'available_balance': available_balance,\n",
    "        'portfolio_value': portfolio_value,\n",
    "        'total_value': available_balance + portfolio_value\n",
    "    }\n",
    "else:\n",
    "    print(f\"✗ Error: {balance_response.status_code}\")\n",
    "    print(f\"Response: {balance_response.text}\")\n",
    "    portfolio_summary = None\n",
    "\n",
    "# === 2. Get Active Orders ===\n",
    "print(f\"\\n{'=' * 70}\")\n",
    "print(\"ACTIVE ORDERS (Resting)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "orders_response = make_authenticated_request(\n",
    "    '/trade-api/v2/portfolio/orders',\n",
    "    params={'status': 'resting', 'limit': 100}\n",
    ")\n",
    "\n",
    "if orders_response.status_code == 200:\n",
    "    orders_data = orders_response.json()\n",
    "    active_orders = orders_data.get('orders', [])\n",
    "    \n",
    "    print(f\"\\n  Total Active Orders: {len(active_orders)}\\n\")\n",
    "    \n",
    "    if active_orders:\n",
    "        print(f\"  {'Order ID':<20} {'Market':<25} {'Side':<5} {'Action':<6} {'Qty':<6} {'Price':<7} {'Status':<10}\")\n",
    "        print(f\"  {'-' * 100}\")\n",
    "        \n",
    "        for order in active_orders:\n",
    "            order_id = order.get('order_id', 'N/A')[:18]\n",
    "            ticker = order.get('ticker', 'N/A')[:23]\n",
    "            side = order.get('side', 'N/A').upper()\n",
    "            action = order.get('action', 'N/A')\n",
    "            qty = order.get('remaining_count', order.get('yes_price', 0))\n",
    "            price = order.get('yes_price', 0) / 100 if side == 'YES' else order.get('no_price', 0) / 100\n",
    "            status = order.get('status', 'N/A')\n",
    "            \n",
    "            print(f\"  {order_id:<20} {ticker:<25} {side:<5} {action:<6} {qty:<6} ${price:<6.2f} {status:<10}\")\n",
    "        \n",
    "        # Calculate total exposure\n",
    "        total_yes_exposure = sum(\n",
    "            (o.get('remaining_count', 0) * o.get('yes_price', 0)) / 100 \n",
    "            for o in active_orders if o.get('side') == 'yes'\n",
    "        )\n",
    "        total_no_exposure = sum(\n",
    "            (o.get('remaining_count', 0) * o.get('no_price', 0)) / 100 \n",
    "            for o in active_orders if o.get('side') == 'no'\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n  Total YES exposure: ${total_yes_exposure:,.2f}\")\n",
    "        print(f\"  Total NO exposure:  ${total_no_exposure:,.2f}\")\n",
    "        print(f\"  Total exposure:     ${total_yes_exposure + total_no_exposure:,.2f}\")\n",
    "    else:\n",
    "        print(\"  No active orders found.\")\n",
    "    \n",
    "    active_orders_summary = active_orders\n",
    "else:\n",
    "    print(f\"✗ Error: {orders_response.status_code}\")\n",
    "    print(f\"Response: {orders_response.text}\")\n",
    "    active_orders_summary = []\n",
    "\n",
    "print(f\"\\n{'=' * 70}\\n\")\n",
    "\n",
    "# Store results for further analysis\n",
    "account_info = {\n",
    "    'balance': portfolio_summary,\n",
    "    'active_orders': active_orders_summary\n",
    "}\n",
    "\n",
    "account_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3587eb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 series with '15 min' tag\n",
      "  - KXETH15M: ETH 15M price up down\n",
      "  - KXBTC15M: Bitcoin price up down\n",
      "  - KXSOL15M: Solana 15 minutes\n",
      "\n",
      "Fetched 1 open markets for KXETH15M\n",
      "\n",
      "Fetched 1 open markets for KXBTC15M\n",
      "\n",
      "Fetched 1 open markets for KXSOL15M\n",
      "\n",
      "=== Total: 3 open crypto 15-minute markets ===\n",
      "\n",
      "Sample market:\n",
      "  Ticker: KXETH15M-26JAN311745-45\n",
      "  Title: ETH price up in next 15 mins?\n",
      "  Yes Price: $0.67\n",
      "  Volume: 1106\n",
      "  Close Time: 2026-01-31T22:45:00Z\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'can_close_early': True,\n",
       "  'close_time': '2026-01-31T22:45:00Z',\n",
       "  'created_time': '2026-01-31T01:01:39.986147Z',\n",
       "  'event_ticker': 'KXETH15M-26JAN311745',\n",
       "  'expected_expiration_time': '2026-01-31T22:50:00Z',\n",
       "  'expiration_time': '2026-02-07T22:45:00Z',\n",
       "  'expiration_value': '',\n",
       "  'floor_strike': 2414.15,\n",
       "  'last_price': 69,\n",
       "  'last_price_dollars': '0.6900',\n",
       "  'latest_expiration_time': '2026-02-07T22:45:00Z',\n",
       "  'liquidity': 4625693,\n",
       "  'liquidity_dollars': '46256.9300',\n",
       "  'market_type': 'binary',\n",
       "  'no_ask': 33,\n",
       "  'no_ask_dollars': '0.3300',\n",
       "  'no_bid': 29,\n",
       "  'no_bid_dollars': '0.2900',\n",
       "  'no_sub_title': 'Price to beat: TBD',\n",
       "  'notional_value': 100,\n",
       "  'notional_value_dollars': '1.0000',\n",
       "  'open_interest': 736,\n",
       "  'open_interest_fp': '736.00',\n",
       "  'open_time': '2026-01-31T22:30:00Z',\n",
       "  'previous_price': 0,\n",
       "  'previous_price_dollars': '0.0000',\n",
       "  'previous_yes_ask': 0,\n",
       "  'previous_yes_ask_dollars': '0.0000',\n",
       "  'previous_yes_bid': 0,\n",
       "  'previous_yes_bid_dollars': '0.0000',\n",
       "  'price_level_structure': 'linear_cent',\n",
       "  'price_ranges': [{'end': '1.0000', 'start': '0.0000', 'step': '0.0100'}],\n",
       "  'response_price_units': 'usd_cent',\n",
       "  'result': '',\n",
       "  'rules_primary': \"If the simple average of the sixty seconds of CF Benchmarks' ETHUSD_RTI before 5:45 PM EST on Jan 31, 2026 is at least the simple average of the sixty seconds of CF Benchmarks' ETHUSD_RTI before 5:30 PM EST on January 31, 2026, then the market resolves to Yes.\",\n",
       "  'rules_secondary': \"Not all cryptocurrency price data is the same. While checking a source like Google or Coinbase may help guide your decision, the price used to determine this market is based on CF Benchmarks' corresponding Real Time Index (RTI). At the last minute before expiration, 60 RTI prices are collected. The official and final value is the average of these prices.\",\n",
       "  'settlement_timer_seconds': 60,\n",
       "  'status': 'active',\n",
       "  'strike_type': 'greater_or_equal',\n",
       "  'subtitle': '',\n",
       "  'tick_size': 1,\n",
       "  'ticker': 'KXETH15M-26JAN311745-45',\n",
       "  'title': 'ETH price up in next 15 mins?',\n",
       "  'updated_time': '2026-01-31T22:35:19.106404Z',\n",
       "  'volume': 1106,\n",
       "  'volume_24h': 0,\n",
       "  'volume_24h_fp': '0.00',\n",
       "  'volume_fp': '1106.00',\n",
       "  'yes_ask': 71,\n",
       "  'yes_ask_dollars': '0.7100',\n",
       "  'yes_bid': 67,\n",
       "  'yes_bid_dollars': '0.6700',\n",
       "  'yes_sub_title': 'Price to beat: $2,414.14'},\n",
       " {'can_close_early': True,\n",
       "  'close_time': '2026-01-31T22:45:00Z',\n",
       "  'created_time': '2026-01-31T01:01:39.142492Z',\n",
       "  'event_ticker': 'KXBTC15M-26JAN311745',\n",
       "  'expected_expiration_time': '2026-01-31T22:50:00Z',\n",
       "  'expiration_time': '2026-02-07T22:45:00Z',\n",
       "  'expiration_value': '',\n",
       "  'floor_strike': 78225.33,\n",
       "  'last_price': 36,\n",
       "  'last_price_dollars': '0.3600',\n",
       "  'latest_expiration_time': '2026-02-07T22:45:00Z',\n",
       "  'liquidity': 5046661,\n",
       "  'liquidity_dollars': '50466.6100',\n",
       "  'market_type': 'binary',\n",
       "  'no_ask': 65,\n",
       "  'no_ask_dollars': '0.6500',\n",
       "  'no_bid': 64,\n",
       "  'no_bid_dollars': '0.6400',\n",
       "  'no_sub_title': 'Price to beat: TBD',\n",
       "  'notional_value': 100,\n",
       "  'notional_value_dollars': '1.0000',\n",
       "  'open_interest': 4463,\n",
       "  'open_interest_fp': '4463.00',\n",
       "  'open_time': '2026-01-31T22:30:00Z',\n",
       "  'previous_price': 0,\n",
       "  'previous_price_dollars': '0.0000',\n",
       "  'previous_yes_ask': 0,\n",
       "  'previous_yes_ask_dollars': '0.0000',\n",
       "  'previous_yes_bid': 0,\n",
       "  'previous_yes_bid_dollars': '0.0000',\n",
       "  'price_level_structure': 'linear_cent',\n",
       "  'price_ranges': [{'end': '1.0000', 'start': '0.0000', 'step': '0.0100'}],\n",
       "  'response_price_units': 'usd_cent',\n",
       "  'result': '',\n",
       "  'rules_primary': \"If the simple average of the sixty seconds of CF Benchmarks' BRTI before 5:45 PM EST on Jan 31, 2026 is at least the simple average of the sixty seconds of CF Benchmarks' BRTI before 5:30 PM EST on January 31, 2026, then the market resolves to Yes.\",\n",
       "  'rules_secondary': \"Not all cryptocurrency price data is the same. While checking a source like Google or Coinbase may help guide your decision, the price used to determine this market is based on CF Benchmarks' corresponding Real Time Index (RTI). At the last minute before expiration, 60 RTI prices are collected. The official and final value is the average of these prices.\",\n",
       "  'settlement_timer_seconds': 60,\n",
       "  'status': 'active',\n",
       "  'strike_type': 'greater_or_equal',\n",
       "  'subtitle': '',\n",
       "  'tick_size': 1,\n",
       "  'ticker': 'KXBTC15M-26JAN311745-45',\n",
       "  'title': 'BTC price up in next 15 mins?',\n",
       "  'updated_time': '2026-01-31T22:35:15.982704Z',\n",
       "  'volume': 8793,\n",
       "  'volume_24h': 0,\n",
       "  'volume_24h_fp': '0.00',\n",
       "  'volume_fp': '8793.00',\n",
       "  'yes_ask': 36,\n",
       "  'yes_ask_dollars': '0.3600',\n",
       "  'yes_bid': 35,\n",
       "  'yes_bid_dollars': '0.3500',\n",
       "  'yes_sub_title': 'Price to beat: $78,225.32'},\n",
       " {'can_close_early': True,\n",
       "  'close_time': '2026-01-31T22:45:00Z',\n",
       "  'created_time': '2026-01-31T01:01:38.854224Z',\n",
       "  'event_ticker': 'KXSOL15M-26JAN311745',\n",
       "  'expected_expiration_time': '2026-01-31T22:50:00Z',\n",
       "  'expiration_time': '2026-02-07T22:45:00Z',\n",
       "  'expiration_value': '',\n",
       "  'floor_strike': 103.84,\n",
       "  'last_price': 78,\n",
       "  'last_price_dollars': '0.7800',\n",
       "  'latest_expiration_time': '2026-02-07T22:45:00Z',\n",
       "  'liquidity': 811973,\n",
       "  'liquidity_dollars': '8119.7300',\n",
       "  'market_type': 'binary',\n",
       "  'no_ask': 28,\n",
       "  'no_ask_dollars': '0.2800',\n",
       "  'no_bid': 24,\n",
       "  'no_bid_dollars': '0.2400',\n",
       "  'no_sub_title': 'Price to beat: TBD',\n",
       "  'notional_value': 100,\n",
       "  'notional_value_dollars': '1.0000',\n",
       "  'open_interest': 210,\n",
       "  'open_interest_fp': '210.00',\n",
       "  'open_time': '2026-01-31T22:30:00Z',\n",
       "  'previous_price': 0,\n",
       "  'previous_price_dollars': '0.0000',\n",
       "  'previous_yes_ask': 0,\n",
       "  'previous_yes_ask_dollars': '0.0000',\n",
       "  'previous_yes_bid': 0,\n",
       "  'previous_yes_bid_dollars': '0.0000',\n",
       "  'price_level_structure': 'linear_cent',\n",
       "  'price_ranges': [{'end': '1.0000', 'start': '0.0000', 'step': '0.0100'}],\n",
       "  'response_price_units': 'usd_cent',\n",
       "  'result': '',\n",
       "  'rules_primary': \"If the simple average of the sixty seconds of CF Benchmarks' SOLUSD_RTI before 5:45 PM EST on Jan 31, 2026 is at least the simple average of the sixty seconds of CF Benchmarks' SOLUSD_RTI before 5:30 PM EST on January 31, 2026, then the market resolves to Yes.\",\n",
       "  'rules_secondary': \"Not all cryptocurrency price data is the same. While checking a source like Google or Coinbase may help guide your decision, the price used to determine this market is based on CF Benchmarks' corresponding Real Time Index (RTI). At the last minute before expiration, 60 RTI prices are collected. The official and final value is the average of these prices.\",\n",
       "  'settlement_timer_seconds': 60,\n",
       "  'status': 'active',\n",
       "  'strike_type': 'greater_or_equal',\n",
       "  'subtitle': '',\n",
       "  'tick_size': 1,\n",
       "  'ticker': 'KXSOL15M-26JAN311745-45',\n",
       "  'title': 'SOL price up in next 15 mins?',\n",
       "  'updated_time': '2026-01-31T22:35:34.781222Z',\n",
       "  'volume': 332,\n",
       "  'volume_24h': 0,\n",
       "  'volume_24h_fp': '0.00',\n",
       "  'volume_fp': '332.00',\n",
       "  'yes_ask': 76,\n",
       "  'yes_ask_dollars': '0.7600',\n",
       "  'yes_bid': 72,\n",
       "  'yes_bid_dollars': '0.7200',\n",
       "  'yes_sub_title': 'Price to beat: $103.8399'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Fetch all series with the \"15 min\" tag (crypto 15-minute markets)\n",
    "url = \"https://api.elections.kalshi.com/trade-api/v2/series\"\n",
    "params = {\n",
    "    \"tags\": \"15 min\",  # Filter for 15-minute markets\n",
    "    \"limit\": 200\n",
    "}\n",
    "\n",
    "response = requests.get(url, params=params)\n",
    "series_data = response.json()\n",
    "\n",
    "# Extract series tickers for 15-minute crypto markets\n",
    "crypto_15min_series = series_data.get('series', [])\n",
    "print(f\"Found {len(crypto_15min_series)} series with '15 min' tag\")\n",
    "\n",
    "# Display first few series to see what we have\n",
    "for series in crypto_15min_series[:5]:\n",
    "    print(f\"  - {series['ticker']}: {series['title']}\")\n",
    "\n",
    "# Now fetch all markets for these series\n",
    "all_markets = []\n",
    "for series in crypto_15min_series:\n",
    "    series_ticker = series['ticker']\n",
    "    \n",
    "    # Fetch markets for this series\n",
    "    markets_url = \"https://api.elections.kalshi.com/trade-api/v2/markets\"\n",
    "    market_params = {\n",
    "        \"series_ticker\": series_ticker,\n",
    "        \"status\": \"open\",  # Only get currently open markets\n",
    "        \"limit\": 1000\n",
    "    }\n",
    "    \n",
    "    markets_response = requests.get(markets_url, params=market_params)\n",
    "    markets_data = markets_response.json()\n",
    "    \n",
    "    markets = markets_data.get('markets', [])\n",
    "    all_markets.extend(markets)\n",
    "    \n",
    "    if markets:\n",
    "        print(f\"\\nFetched {len(markets)} open markets for {series_ticker}\")\n",
    "\n",
    "print(f\"\\n=== Total: {len(all_markets)} open crypto 15-minute markets ===\")\n",
    "\n",
    "# Store in a variable for further analysis\n",
    "crypto_15min_markets = all_markets\n",
    "\n",
    "# Display sample market data\n",
    "if crypto_15min_markets:\n",
    "    print(\"\\nSample market:\")\n",
    "    sample = crypto_15min_markets[0]\n",
    "    print(f\"  Ticker: {sample.get('ticker')}\")\n",
    "    print(f\"  Title: {sample.get('title')}\")\n",
    "    print(f\"  Yes Price: ${sample.get('yes_bid', 0)/100:.2f}\")\n",
    "    print(f\"  Volume: {sample.get('volume', 0)}\")\n",
    "    print(f\"  Close Time: {sample.get('close_time')}\")\n",
    "\n",
    "crypto_15min_markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f625b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Bitcoin 15-min settled markets from the past month:\n",
      "  Start: 2026-01-02 08:13:34 UTC\n",
      "  End:   2026-02-01 08:13:34 UTC\n",
      "Page 1: Fetched 1 markets (total: 1)\n",
      "\n",
      "=== Total: 1 settled BTC 15-min markets ===\n",
      "\n",
      "Market Statistics:\n",
      "  Total markets: 1\n",
      "  Total volume: 2,491\n",
      "  Average volume per market: 2491.00\n",
      "\n",
      "Outcomes:\n",
      "  Yes (price went up): 1 (100.0%)\n",
      "  No (price went down): 0 (0.0%)\n",
      "\n",
      "Sample markets (first 3) - showing both UTC and ET times:\n",
      "\n",
      "  1. KXNYCSNOWM-26JAN-0.1\n",
      "     Title: Snow in New York City in Jan 2026?\n",
      "     Close time (UTC): 2026-01-07T15:00:00Z\n",
      "     Close time (ET):  2026-01-07 10:00:00 EST\n",
      "     Volume: 2491\n",
      "     Result: yes\n",
      "     Final price: $0.99\n",
      "\n",
      "Note: All markets now have _et suffix fields in format 'YYYY-MM-DD HH:MM:SS EST/EDT'\n",
      "      (e.g., close_time_et, open_time_et, created_time_et, etc.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'can_close_early': True,\n",
       "  'close_time': '2026-01-07T15:00:00Z',\n",
       "  'created_time': '2025-12-31T21:43:22.690736Z',\n",
       "  'early_close_condition': 'This market will close and expire early if the event occurs.',\n",
       "  'event_ticker': 'KXNYCSNOWM-26JAN',\n",
       "  'expected_expiration_time': '2026-02-02T04:59:59Z',\n",
       "  'expiration_time': '2026-02-09T04:59:59Z',\n",
       "  'expiration_value': '',\n",
       "  'floor_strike': 0.1,\n",
       "  'last_price': 99,\n",
       "  'last_price_dollars': '0.9900',\n",
       "  'latest_expiration_time': '2026-02-09T04:59:59Z',\n",
       "  'liquidity': 0,\n",
       "  'liquidity_dollars': '0.0000',\n",
       "  'market_type': 'binary',\n",
       "  'no_ask': 100,\n",
       "  'no_ask_dollars': '1.0000',\n",
       "  'no_bid': 0,\n",
       "  'no_bid_dollars': '0.0000',\n",
       "  'no_sub_title': 'Above 0.1 inches',\n",
       "  'notional_value': 100,\n",
       "  'notional_value_dollars': '1.0000',\n",
       "  'open_interest': 2490,\n",
       "  'open_interest_fp': '2490.00',\n",
       "  'open_time': '2026-01-01T00:43:14Z',\n",
       "  'previous_price': 99,\n",
       "  'previous_price_dollars': '0.9900',\n",
       "  'previous_yes_ask': 100,\n",
       "  'previous_yes_ask_dollars': '1.0000',\n",
       "  'previous_yes_bid': 99,\n",
       "  'previous_yes_bid_dollars': '0.9900',\n",
       "  'price_level_structure': 'linear_cent',\n",
       "  'price_ranges': [{'end': '1.0000', 'start': '0.0000', 'step': '0.0100'}],\n",
       "  'response_price_units': 'usd_cent',\n",
       "  'result': 'yes',\n",
       "  'rules_primary': 'If the total snowfall in New York City in Jan 2026 is strictly greater than 0.1 inches, then the market resolves to Yes.',\n",
       "  'rules_secondary': 'Data for CLINYC can be found by clicking the following URL: https://www.weather.gov/wrh/Climate?wfo=okx, and clicking on \"Observed Weather\", with Daily Climate Report selected.',\n",
       "  'settlement_timer_seconds': 1800,\n",
       "  'settlement_ts': '2026-01-08T01:34:20.858772Z',\n",
       "  'settlement_value': 100,\n",
       "  'settlement_value_dollars': '1.0000',\n",
       "  'status': 'finalized',\n",
       "  'strike_type': 'greater',\n",
       "  'subtitle': '',\n",
       "  'tick_size': 1,\n",
       "  'ticker': 'KXNYCSNOWM-26JAN-0.1',\n",
       "  'title': 'Snow in New York City in Jan 2026?',\n",
       "  'updated_time': '2026-01-08T01:34:21.032059Z',\n",
       "  'volume': 2491,\n",
       "  'volume_24h': 0,\n",
       "  'volume_24h_fp': '0.00',\n",
       "  'volume_fp': '2491.00',\n",
       "  'yes_ask': 100,\n",
       "  'yes_ask_dollars': '1.0000',\n",
       "  'yes_bid': 0,\n",
       "  'yes_bid_dollars': '0.0000',\n",
       "  'yes_sub_title': 'Above 0.1 inches',\n",
       "  'close_time_et': '2026-01-07 10:00:00 EST',\n",
       "  'open_time_et': '2025-12-31 19:43:14 EST',\n",
       "  'created_time_et': '2025-12-31 16:43:22 EST',\n",
       "  'updated_time_et': '2026-01-07 20:34:21 EST',\n",
       "  'expiration_time_et': '2026-02-08 23:59:59 EST',\n",
       "  'expected_expiration_time_et': '2026-02-01 23:59:59 EST',\n",
       "  'latest_expiration_time_et': '2026-02-08 23:59:59 EST'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "from datetime import datetime, timedelta, timezone\n",
    "try:\n",
    "    from zoneinfo import ZoneInfo\n",
    "    ET_TZ = ZoneInfo('America/New_York')\n",
    "except ImportError:\n",
    "    # Fallback for older Python versions\n",
    "    from datetime import timezone as tz\n",
    "    ET_TZ = tz(timedelta(hours=-5))  # EST approximation\n",
    "\n",
    "def add_et_times(market):\n",
    "    \"\"\"Add Eastern Time versions of all time fields to a market dict.\"\"\"\n",
    "    time_fields = ['close_time', 'open_time', 'created_time', 'updated_time', \n",
    "                   'expiration_time', 'expected_expiration_time', 'latest_expiration_time']\n",
    "    \n",
    "    for field in time_fields:\n",
    "        if field in market and market[field]:\n",
    "            try:\n",
    "                # Parse UTC time\n",
    "                utc_time_str = market[field]\n",
    "                if isinstance(utc_time_str, str):\n",
    "                    dt_utc = datetime.fromisoformat(utc_time_str.replace('Z', '+00:00'))\n",
    "                    # Convert to Eastern Time\n",
    "                    dt_et = dt_utc.astimezone(ET_TZ)\n",
    "                    # Format as clean readable string\n",
    "                    market[f\"{field}_et\"] = dt_et.strftime('%Y-%m-%d %H:%M:%S %Z')\n",
    "            except Exception:\n",
    "                pass  # Skip if conversion fails\n",
    "    \n",
    "    return market\n",
    "\n",
    "# Calculate Unix timestamps for the past month\n",
    "now = datetime.now(timezone.utc)\n",
    "one_month_ago = now - timedelta(days=30)\n",
    "\n",
    "max_close_ts = int(now.timestamp())\n",
    "min_close_ts = int(one_month_ago.timestamp())\n",
    "\n",
    "print(f\"Fetching Bitcoin 15-min settled markets from the past month:\")\n",
    "print(f\"  Start: {one_month_ago.strftime('%Y-%m-%d %H:%M:%S UTC')}\")\n",
    "print(f\"  End:   {now.strftime('%Y-%m-%d %H:%M:%S UTC')}\")\n",
    "\n",
    "# The Bitcoin 15-minute series ticker\n",
    "btc_series_ticker = \"KXNYCSNOWM\" \n",
    "\n",
    "# Fetch all SETTLED markets for Bitcoin 15-minute series in the past month\n",
    "base_url = \"https://api.elections.kalshi.com/trade-api/v2/markets\"\n",
    "\n",
    "all_btc_markets = []\n",
    "cursor = None\n",
    "page = 0\n",
    "\n",
    "while True:\n",
    "    params = {\n",
    "        \"series_ticker\": btc_series_ticker,\n",
    "        \"status\": \"settled\",\n",
    "        \"min_close_ts\": min_close_ts,\n",
    "        \"max_close_ts\": max_close_ts,\n",
    "        \"limit\": 1000\n",
    "    }\n",
    "    \n",
    "    if cursor:\n",
    "        params[\"cursor\"] = cursor\n",
    "    \n",
    "    response = requests.get(base_url, params=params)\n",
    "    \n",
    "    if response.status_code == 429:\n",
    "        print(\"Rate limited, waiting 2 seconds...\")\n",
    "        time.sleep(2)\n",
    "        continue\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error: Status {response.status_code}\")\n",
    "        print(f\"Response: {response.text}\")\n",
    "        break\n",
    "    \n",
    "    data = response.json()\n",
    "    markets = data.get('markets', [])\n",
    "    \n",
    "    # Add Eastern Time fields to each market\n",
    "    markets_with_et = [add_et_times(m) for m in markets]\n",
    "    all_btc_markets.extend(markets_with_et)\n",
    "    \n",
    "    page += 1\n",
    "    if markets:\n",
    "        print(f\"Page {page}: Fetched {len(markets)} markets (total: {len(all_btc_markets)})\")\n",
    "    \n",
    "    cursor = data.get('cursor')\n",
    "    \n",
    "    if not cursor:\n",
    "        break\n",
    "\n",
    "print(f\"\\n=== Total: {len(all_btc_markets)} settled BTC 15-min markets ===\")\n",
    "\n",
    "# Store in variable for analysis\n",
    "btc_15min_historical = all_btc_markets\n",
    "\n",
    "if btc_15min_historical:\n",
    "    print(\"\\nMarket Statistics:\")\n",
    "    total_volume = sum(m.get('volume', 0) for m in btc_15min_historical)\n",
    "    avg_volume = total_volume / len(btc_15min_historical)\n",
    "    \n",
    "    print(f\"  Total markets: {len(btc_15min_historical)}\")\n",
    "    print(f\"  Total volume: {total_volume:,}\")\n",
    "    print(f\"  Average volume per market: {avg_volume:.2f}\")\n",
    "    \n",
    "    # Count results\n",
    "    yes_count = sum(1 for m in btc_15min_historical if m.get('result') == 'yes')\n",
    "    no_count = sum(1 for m in btc_15min_historical if m.get('result') == 'no')\n",
    "    \n",
    "    print(f\"\\nOutcomes:\")\n",
    "    print(f\"  Yes (price went up): {yes_count} ({yes_count/len(btc_15min_historical)*100:.1f}%)\")\n",
    "    print(f\"  No (price went down): {no_count} ({no_count/len(btc_15min_historical)*100:.1f}%)\")\n",
    "    \n",
    "    print(\"\\nSample markets (first 3) - showing both UTC and ET times:\")\n",
    "    for i, market in enumerate(btc_15min_historical[:3], 1):\n",
    "        print(f\"\\n  {i}. {market.get('ticker')}\")\n",
    "        print(f\"     Title: {market.get('title')}\")\n",
    "        print(f\"     Close time (UTC): {market.get('close_time')}\")\n",
    "        print(f\"     Close time (ET):  {market.get('close_time_et')}\")\n",
    "        print(f\"     Volume: {market.get('volume', 0)}\")\n",
    "        print(f\"     Result: {market.get('result')}\")\n",
    "        print(f\"     Final price: ${market.get('last_price', 0)/100:.2f}\")\n",
    "    \n",
    "    print(\"\\nNote: All markets now have _et suffix fields in format 'YYYY-MM-DD HH:MM:SS EST/EDT'\")\n",
    "    print(\"      (e.g., close_time_et, open_time_et, created_time_et, etc.)\")\n",
    "else:\n",
    "    print(\"\\n⚠ No settled markets found in the past 30 days.\")\n",
    "    print(\"The series might be very new. Try:\")\n",
    "    print(\"  - Increasing the time window (e.g., 60 or 90 days)\")\n",
    "    print(\"  - Checking when the series was created\")\n",
    "\n",
    "btc_15min_historical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7181cd2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'can_close_early': True,\n",
       " 'close_time': '2026-01-01T23:00:00Z',\n",
       " 'created_time': '2025-12-31T23:49:48.168266Z',\n",
       " 'event_ticker': 'KXBTC15M-26JAN011800',\n",
       " 'expected_expiration_time': '2026-01-01T23:05:00Z',\n",
       " 'expiration_time': '2026-01-08T23:00:00Z',\n",
       " 'expiration_value': '',\n",
       " 'floor_strike': 88456.49,\n",
       " 'last_price': 99,\n",
       " 'last_price_dollars': '0.9900',\n",
       " 'latest_expiration_time': '2026-01-08T23:00:00Z',\n",
       " 'liquidity': 0,\n",
       " 'liquidity_dollars': '0.0000',\n",
       " 'market_type': 'binary',\n",
       " 'no_ask': 100,\n",
       " 'no_ask_dollars': '1.0000',\n",
       " 'no_bid': 0,\n",
       " 'no_bid_dollars': '0.0000',\n",
       " 'no_sub_title': 'Price to beat: TBD',\n",
       " 'notional_value': 100,\n",
       " 'notional_value_dollars': '1.0000',\n",
       " 'open_interest': 4458,\n",
       " 'open_interest_fp': '4458.00',\n",
       " 'open_time': '2026-01-01T22:45:00Z',\n",
       " 'previous_price': 99,\n",
       " 'previous_price_dollars': '0.9900',\n",
       " 'previous_yes_ask': 100,\n",
       " 'previous_yes_ask_dollars': '1.0000',\n",
       " 'previous_yes_bid': 0,\n",
       " 'previous_yes_bid_dollars': '0.0000',\n",
       " 'price_level_structure': 'linear_cent',\n",
       " 'price_ranges': [{'end': '1.0000', 'start': '0.0000', 'step': '0.0100'}],\n",
       " 'response_price_units': 'usd_cent',\n",
       " 'result': 'yes',\n",
       " 'rules_primary': \"If the simple average of the sixty seconds of CF Benchmarks' BRTI before 6:00 PM EST is at least The price of Bitcoin at 5:45 PM ET on January 1st, 2026 according to CF Benchmarks at 6:00 PM EST on Jan 1, 2026, then the market resolves to Yes.\",\n",
       " 'rules_secondary': \"Not all cryptocurrency price data is the same. While checking a source like Google or Coinbase may help guide your decision, the price used to determine this market is based on CF Benchmarks' corresponding Real Time Index (RTI). At the last minute before expiration, 60 RTI prices are collected. The official and final value is the average of these prices.\",\n",
       " 'settlement_timer_seconds': 1800,\n",
       " 'settlement_ts': '2026-01-01T23:30:55.197063Z',\n",
       " 'settlement_value': 100,\n",
       " 'settlement_value_dollars': '1.0000',\n",
       " 'status': 'finalized',\n",
       " 'strike_type': 'greater_or_equal',\n",
       " 'subtitle': '',\n",
       " 'tick_size': 1,\n",
       " 'ticker': 'KXBTC15M-26JAN011800-00',\n",
       " 'title': 'BTC price up in next 15 mins?',\n",
       " 'updated_time': '2026-01-01T23:30:55.226644Z',\n",
       " 'volume': 7681,\n",
       " 'volume_24h': 0,\n",
       " 'volume_24h_fp': '0.00',\n",
       " 'volume_fp': '7681.00',\n",
       " 'yes_ask': 100,\n",
       " 'yes_ask_dollars': '1.0000',\n",
       " 'yes_bid': 0,\n",
       " 'yes_bid_dollars': '0.0000',\n",
       " 'yes_sub_title': 'Price to beat: $88,456.48',\n",
       " 'close_time_et': '2026-01-01 18:00:00 EST',\n",
       " 'open_time_et': '2026-01-01 17:45:00 EST',\n",
       " 'created_time_et': '2025-12-31 18:49:48 EST',\n",
       " 'updated_time_et': '2026-01-01 18:30:55 EST',\n",
       " 'expiration_time_et': '2026-01-08 18:00:00 EST',\n",
       " 'expected_expiration_time_et': '2026-01-01 18:05:00 EST',\n",
       " 'latest_expiration_time_et': '2026-01-08 18:00:00 EST'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btc_15min_historical[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4h97ugbkyze",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Analyzing Market: KXBTC15M-26JAN011800-00 ===\n",
      "Title: BTC price up in next 15 mins?\n",
      "Result: yes\n",
      "Close time: 2026-01-01 18:00:00 EST\n",
      "\n",
      "============================================================\n",
      "\n",
      "Market was active from:\n",
      "  Open:  2026-01-01 17:45:00 EST\n",
      "  Close: 2026-01-01 18:00:00 EST\n",
      "  Duration: 15.0 minutes\n",
      "\n",
      "============================================================\n",
      "FETCHING HISTORICAL PRICE DATA (Candlesticks)\n",
      "============================================================\n",
      "\n",
      "✓ Fetched 15 candlesticks (1-minute intervals)\n",
      "\n",
      "Price Evolution Summary:\n",
      "  First candlestick: 17:46:00 EST\n",
      "  Last candlestick:  18:00:00 EST\n",
      "\n",
      "YES Token Price Evolution (every 3 min):\n",
      "  Time (ET)    Yes Bid   Yes Ask   Last Trade  Volume  \n",
      "  ------------------------------------------------------------\n",
      "  17:46:00     $0.67     $0.72     $0.71       65      \n",
      "  17:49:00     $0.60     $0.65     $0.64       264     \n",
      "  17:52:00     $0.78     $0.79     $0.79       3488    \n",
      "  17:55:00     $0.95     $0.96     $0.96       576     \n",
      "  17:58:00     $0.98     $1.00     $0.99       533     \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 81\u001b[0m\n\u001b[1;32m     78\u001b[0m         last_price \u001b[38;5;241m=\u001b[39m candle\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m candle\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     79\u001b[0m         volume \u001b[38;5;241m=\u001b[39m candle\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime_str\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<12\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m $\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myes_bid\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<8.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m $\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myes_ask\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<8.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m $\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlast_price\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<10.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvolume\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<8\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mNO Token Price Evolution (every 3 min):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime (ET)\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<12\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo Bid\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<9\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo Ask\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<9\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImplied\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<11\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVolume\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<8\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "try:\n",
    "    from zoneinfo import ZoneInfo\n",
    "    ET_TZ = ZoneInfo('America/New_York')\n",
    "except ImportError:\n",
    "    # Fallback for older Python versions\n",
    "    ET_TZ = timezone(timedelta(hours=-5))\n",
    "\n",
    "# Get the last market from historical data\n",
    "last_market = btc_15min_historical[-1]\n",
    "ticker = last_market['ticker']\n",
    "series_ticker = \"KXBTC15M\"\n",
    "\n",
    "print(f\"=== Analyzing Market: {ticker} ===\")\n",
    "print(f\"Title: {last_market['title']}\")\n",
    "print(f\"Result: {last_market['result']}\")\n",
    "print(f\"Close time: {last_market.get('close_time_et', last_market['close_time'])}\")\n",
    "print(f\"\\n{'='*60}\\n\")\n",
    "\n",
    "# Parse timestamps for the market's lifetime\n",
    "open_time_str = last_market['open_time']\n",
    "close_time_str = last_market['close_time']\n",
    "\n",
    "open_dt = datetime.fromisoformat(open_time_str.replace('Z', '+00:00'))\n",
    "close_dt = datetime.fromisoformat(close_time_str.replace('Z', '+00:00'))\n",
    "\n",
    "start_ts = int(open_dt.timestamp())\n",
    "end_ts = int(close_dt.timestamp())\n",
    "\n",
    "print(f\"Market was active from:\")\n",
    "print(f\"  Open:  {open_dt.astimezone(ET_TZ).strftime('%Y-%m-%d %H:%M:%S %Z')}\")\n",
    "print(f\"  Close: {close_dt.astimezone(ET_TZ).strftime('%Y-%m-%d %H:%M:%S %Z')}\")\n",
    "print(f\"  Duration: {(end_ts - start_ts) / 60:.1f} minutes\")\n",
    "\n",
    "# === 1. Fetch Historical Candlestick Data (Price Evolution) ===\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"FETCHING HISTORICAL PRICE DATA (Candlesticks)\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "candlesticks_url = f\"https://api.elections.kalshi.com/trade-api/v2/series/{series_ticker}/markets/{ticker}/candlesticks\"\n",
    "params = {\n",
    "    \"start_ts\": start_ts,\n",
    "    \"end_ts\": end_ts,\n",
    "    \"period_interval\": 1,  # 1-minute intervals for detailed view\n",
    "    \"include_latest_before_start\": True\n",
    "}\n",
    "\n",
    "candlesticks_response = requests.get(candlesticks_url, params=params)\n",
    "\n",
    "if candlesticks_response.status_code == 200:\n",
    "    candlesticks_data = candlesticks_response.json()\n",
    "    candlesticks = candlesticks_data.get('candlesticks', [])\n",
    "    \n",
    "    print(f\"✓ Fetched {len(candlesticks)} candlesticks (1-minute intervals)\")\n",
    "    \n",
    "    if candlesticks:\n",
    "        first_ts = datetime.fromtimestamp(candlesticks[0]['end_period_ts'], tz=timezone.utc).astimezone(ET_TZ)\n",
    "        last_ts = datetime.fromtimestamp(candlesticks[-1]['end_period_ts'], tz=timezone.utc).astimezone(ET_TZ)\n",
    "        \n",
    "        print(\"\\nPrice Evolution Summary:\")\n",
    "        print(f\"  First candlestick: {first_ts.strftime('%H:%M:%S %Z')}\")\n",
    "        print(f\"  Last candlestick:  {last_ts.strftime('%H:%M:%S %Z')}\")\n",
    "        \n",
    "        # Show sample of price movement (every 3 minutes) - YES and NO prices\n",
    "        print(\"\\nYES Token Price Evolution (every 3 min):\")\n",
    "        print(f\"  {'Time (ET)':<12} {'Yes Bid':<9} {'Yes Ask':<9} {'Last Trade':<11} {'Volume':<8}\")\n",
    "        print(f\"  {'-'*60}\")\n",
    "        \n",
    "        for i, candle in enumerate(candlesticks):\n",
    "            if i % 3 == 0 or i == len(candlesticks) - 1:  # Every 3 minutes + last\n",
    "                ts = datetime.fromtimestamp(candle['end_period_ts'], tz=timezone.utc).astimezone(ET_TZ)\n",
    "                time_str = ts.strftime('%H:%M:%S')\n",
    "                \n",
    "                yes_bid = candle.get('yes_bid', {}).get('close', 0) if candle.get('yes_bid') else 0\n",
    "                yes_ask = candle.get('yes_ask', {}).get('close', 0) if candle.get('yes_ask') else 0\n",
    "                last_price = candle.get('price', {}).get('close', 0) if candle.get('price') else 0\n",
    "                volume = candle.get('volume', 0)\n",
    "                \n",
    "                print(f\"  {time_str:<12} ${yes_bid/100:<8.2f} ${yes_ask/100:<8.2f} ${last_price/100:<10.2f} {volume:<8}\")\n",
    "        \n",
    "        print(\"\\nNO Token Price Evolution (every 3 min):\")\n",
    "        print(f\"  {'Time (ET)':<12} {'No Bid':<9} {'No Ask':<9} {'Implied':<11} {'Volume':<8}\")\n",
    "        print(f\"  {'-'*60}\")\n",
    "        \n",
    "        for i, candle in enumerate(candlesticks):\n",
    "            if i % 3 == 0 or i == len(candlesticks) - 1:  # Every 3 minutes + last\n",
    "                ts = datetime.fromtimestamp(candle['end_period_ts'], tz=timezone.utc).astimezone(ET_TZ)\n",
    "                time_str = ts.strftime('%H:%M:%S')\n",
    "                \n",
    "                no_bid = candle.get('no_bid', {}).get('close', 0) if candle.get('no_bid') else 0\n",
    "                no_ask = candle.get('no_ask', {}).get('close', 0) if candle.get('no_ask') else 0\n",
    "                last_price = candle.get('price', {}).get('close', 0) if candle.get('price') else 0\n",
    "                # No implied price is 100 - Yes price\n",
    "                no_implied = 100 - last_price if last_price else 0\n",
    "                volume = candle.get('volume', 0)\n",
    "                \n",
    "                print(f\"  {time_str:<12} ${no_bid/100:<8.2f} ${no_ask/100:<8.2f} ${no_implied/100:<10.2f} {volume:<8}\")\n",
    "else:\n",
    "    print(f\"✗ Error fetching candlesticks: {candlesticks_response.status_code}\")\n",
    "    print(f\"Response: {candlesticks_response.text}\")\n",
    "    candlesticks = []\n",
    "\n",
    "# === 2. Fetch Historical Trades ===\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"FETCHING HISTORICAL TRADES\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "trades_url = \"https://api.elections.kalshi.com/trade-api/v2/markets/trades\"\n",
    "all_trades = []\n",
    "cursor = None\n",
    "\n",
    "while True:\n",
    "    trade_params = {\n",
    "        \"ticker\": ticker,\n",
    "        \"min_ts\": start_ts,\n",
    "        \"max_ts\": end_ts,\n",
    "        \"limit\": 1000\n",
    "    }\n",
    "    \n",
    "    if cursor:\n",
    "        trade_params[\"cursor\"] = cursor\n",
    "    \n",
    "    trades_response = requests.get(trades_url, params=trade_params)\n",
    "    \n",
    "    if trades_response.status_code != 200:\n",
    "        print(f\"✗ Error fetching trades: {trades_response.status_code}\")\n",
    "        break\n",
    "    \n",
    "    trades_data = trades_response.json()\n",
    "    trades = trades_data.get('trades', [])\n",
    "    all_trades.extend(trades)\n",
    "    \n",
    "    cursor = trades_data.get('cursor')\n",
    "    if not cursor:\n",
    "        break\n",
    "\n",
    "print(f\"✓ Fetched {len(all_trades)} historical trades\")\n",
    "\n",
    "if all_trades:\n",
    "    # Calculate trade statistics\n",
    "    total_volume = sum(t.get('count', 0) for t in all_trades)\n",
    "    yes_trades = [t for t in all_trades if t.get('taker_side') == 'yes']\n",
    "    no_trades = [t for t in all_trades if t.get('taker_side') == 'no']\n",
    "    \n",
    "    print(f\"\\nTrade Statistics:\")\n",
    "    print(f\"  Total volume: {total_volume:,} contracts\")\n",
    "    print(f\"  Yes-side trades: {len(yes_trades)} ({len(yes_trades)/len(all_trades)*100:.1f}%)\")\n",
    "    print(f\"  No-side trades:  {len(no_trades)} ({len(no_trades)/len(all_trades)*100:.1f}%)\")\n",
    "    \n",
    "    if yes_trades:\n",
    "        avg_yes_price = sum(t['yes_price'] for t in yes_trades) / len(yes_trades)\n",
    "        print(f\"  Avg Yes price: ${avg_yes_price/100:.2f}\")\n",
    "    \n",
    "    if no_trades:\n",
    "        avg_no_price = sum(t['no_price'] for t in no_trades) / len(no_trades)\n",
    "        print(f\"  Avg No price: ${avg_no_price/100:.2f}\")\n",
    "    \n",
    "    # Show first and last few trades\n",
    "    print(f\"\\nFirst 5 trades:\")\n",
    "    print(f\"  {'Time (ET)':<12} {'Side':<4} {'Yes $':<7} {'No $':<7} {'Contracts':<10}\")\n",
    "    print(f\"  {'-'*60}\")\n",
    "    \n",
    "    for trade in all_trades[:5]:\n",
    "        trade_time = datetime.fromisoformat(trade['created_time'].replace('Z', '+00:00')).astimezone(ET_TZ)\n",
    "        time_str = trade_time.strftime('%H:%M:%S')\n",
    "        side = trade['taker_side']\n",
    "        yes_price = trade['yes_price'] / 100\n",
    "        no_price = trade['no_price'] / 100\n",
    "        count = trade['count']\n",
    "        \n",
    "        print(f\"  {time_str:<12} {side:<4} ${yes_price:<6.2f} ${no_price:<6.2f} {count:<10}\")\n",
    "    \n",
    "    print(f\"\\nLast 5 trades:\")\n",
    "    print(f\"  {'Time (ET)':<12} {'Side':<4} {'Yes $':<7} {'No $':<7} {'Contracts':<10}\")\n",
    "    print(f\"  {'-'*60}\")\n",
    "    \n",
    "    for trade in all_trades[-5:]:\n",
    "        trade_time = datetime.fromisoformat(trade['created_time'].replace('Z', '+00:00')).astimezone(ET_TZ)\n",
    "        time_str = trade_time.strftime('%H:%M:%S')\n",
    "        side = trade['taker_side']\n",
    "        yes_price = trade['yes_price'] / 100\n",
    "        no_price = trade['no_price'] / 100\n",
    "        count = trade['count']\n",
    "        \n",
    "        print(f\"  {time_str:<12} {side:<4} ${yes_price:<6.2f} ${no_price:<6.2f} {count:<10}\")\n",
    "\n",
    "# Store data for further analysis\n",
    "market_historical_data = {\n",
    "    'market': last_market,\n",
    "    'candlesticks': candlesticks,\n",
    "    'trades': all_trades\n",
    "}\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"✓ Data stored in 'market_historical_data' variable\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "market_historical_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "v2u2a0vy9eo",
   "metadata": {},
   "source": [
    "# Climate Markets Backtesting Strategy\n",
    "\n",
    "## Strategy Overview\n",
    "- **Universe**: All climate-related markets from Kalshi\n",
    "- **Constraints**: \n",
    "  - Market duration >= 5 days (120 hours)\n",
    "  - Liquidity >= $100,000\n",
    "- **Entry**: 12 hours before market expiration\n",
    "- **Position Sizing**:\n",
    "  - Daily budget: $10,000 split across all qualifying events\n",
    "  - Per event: 70% on YES favorite, 30% split across NO positions\n",
    "- **Initial Capital**: $100,000\n",
    "- **Timeframe**: Past year\n",
    "\n",
    "## Performance Metrics\n",
    "- Day-by-day equity curve\n",
    "- Cumulative returns and Sharpe ratio\n",
    "- Maximum drawdown analysis\n",
    "- Separate analysis for top 5% liquidity markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ggx8j5s3pq",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FETCHING HISTORICAL CLIMATE MARKETS\n",
      "================================================================================\n",
      "\n",
      "Time window:\n",
      "  From: 2025-02-01 08:06:36 UTC\n",
      "  To:   2026-02-01 08:06:36 UTC\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Searching for climate series...\n",
      "--------------------------------------------------------------------------------\n",
      "  Error searching for 'climate': 'NoneType' object is not iterable\n",
      "  Error searching for 'weather': 'NoneType' object is not iterable\n",
      "  Error searching for 'temperature': 'NoneType' object is not iterable\n",
      "  Error searching for 'emissions': 'NoneType' object is not iterable\n",
      "  Error searching for 'carbon': 'NoneType' object is not iterable\n",
      "\n",
      "✓ Total unique climate-related series: 0\n",
      "\n",
      "⚠ WARNING: No climate series found with keyword search.\n",
      "Fetching ALL series to manually inspect...\n",
      "\n",
      "Total series available: 8216\n",
      "\n",
      "Sample series (first 20):\n",
      "  - KXUFAWEST: Ultimate Frisbee Association East Division Winner (Category: Sports)\n",
      "  - KXSTARTIND: iNDIANAPOLIS WEEK 1 QB (Category: Sports)\n",
      "  - DEBATES24: How many presidential debates in 2024? (Category: Politics)\n",
      "  - NEWOUTBREAKPMPOX: New monkeypox/mpox pandemic (Category: Health)\n",
      "  - KXVOTEGREER: Senators voting for JAMIESON GREER (Category: Politics)\n",
      "  - KXBETBFHHA: Best Female Hip Hop Artist (Category: Entertainment)\n",
      "  - KXOSCARNOMINTERFILM: INTERNATIONAL FEATURE FILM (Category: Entertainment)\n",
      "  - KXNATHANDOGS: Nathan's hot dogs (Category: Sports)\n",
      "  - KXDEBATEAOCGAINES: AOC debates Riley gaines (Category: World)\n",
      "  - KXGRAMBSSFVGAOIM: Best Score Soundtrack for Video Games and Other Interactive Media (Category: Entertainment)\n",
      "  - KXSOLMAXY: Solana Max Yearly (Category: Crypto)\n",
      "  - KXFRANCEAMB: France ambassador confirmation (Category: Politics)\n",
      "  - KXREGINAWASCANA: Regina-Wascana (Category: Politics)\n",
      "  - SENATEMN: Minnesota Senate race (Category: Politics)\n",
      "  - KXESPYCOLLEGEMEN: BEST COLLEGE ATHLETE – MEN’S SPORTS‬ (Category: Entertainment)\n",
      "  - KXACKMANLEAVE: Bill Ackman leave New York City (Category: Politics)\n",
      "  - KXHFINSERVICECHAIR: House Financial Services chair (Category: Politics)\n",
      "  - KXZAMBIAPRES: Zambia presidency (Category: Elections)\n",
      "  - KXSELZER: Selzer lawsuit (Category: Politics)\n",
      "  - KXNYGOVDP: NY Governor pardon (Category: Politics)\n",
      "\n",
      "✓ Will fetch markets for 0 climate series\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 1: Pull All Historical Climate Markets\n",
    "# ============================================================================\n",
    "\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "try:\n",
    "    from zoneinfo import ZoneInfo\n",
    "    ET_TZ = ZoneInfo('America/New_York')\n",
    "except ImportError:\n",
    "    ET_TZ = timezone(timedelta(hours=-5))\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FETCHING HISTORICAL CLIMATE MARKETS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate time window (past year)\n",
    "now = datetime.now(timezone.utc)\n",
    "one_year_ago = now - timedelta(days=365)\n",
    "min_close_ts = int(one_year_ago.timestamp())\n",
    "max_close_ts = int(now.timestamp())\n",
    "\n",
    "print(f\"\\nTime window:\")\n",
    "print(f\"  From: {one_year_ago.strftime('%Y-%m-%d %H:%M:%S UTC')}\")\n",
    "print(f\"  To:   {now.strftime('%Y-%m-%d %H:%M:%S UTC')}\")\n",
    "\n",
    "# First, search for climate-related series\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"Searching for climate series...\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "base_url = \"https://api.elections.kalshi.com/trade-api/v2\"\n",
    "\n",
    "# Try different search approaches for climate markets\n",
    "search_queries = [\"climate\", \"weather\", \"temperature\", \"emissions\", \"carbon\"]\n",
    "all_series = []\n",
    "\n",
    "for query in search_queries:\n",
    "    try:\n",
    "        response = requests.get(f\"{base_url}/series\", params={\"limit\": 200})\n",
    "        if response.status_code == 200:\n",
    "            series_data = response.json().get('series', [])\n",
    "            # Filter series that match climate-related keywords\n",
    "            climate_series = [\n",
    "                s for s in series_data \n",
    "                if query.lower() in s.get('title', '').lower() \n",
    "                or query.lower() in s.get('category', '').lower()\n",
    "                or any(query.lower() in tag.lower() for tag in s.get('tags', []))\n",
    "            ]\n",
    "            all_series.extend(climate_series)\n",
    "            if climate_series:\n",
    "                print(f\"  Found {len(climate_series)} series matching '{query}'\")\n",
    "        time.sleep(0.5)  # Rate limiting\n",
    "    except Exception as e:\n",
    "        print(f\"  Error searching for '{query}': {e}\")\n",
    "\n",
    "# Deduplicate series by ticker\n",
    "unique_series = {s['ticker']: s for s in all_series}.values()\n",
    "print(f\"\\n✓ Total unique climate-related series: {len(unique_series)}\")\n",
    "\n",
    "if len(unique_series) == 0:\n",
    "    print(\"\\n⚠ WARNING: No climate series found with keyword search.\")\n",
    "    print(\"Fetching ALL series to manually inspect...\")\n",
    "    \n",
    "    all_response = requests.get(f\"{base_url}/series\", params={\"limit\": 1000})\n",
    "    if all_response.status_code == 200:\n",
    "        all_series_data = all_response.json().get('series', [])\n",
    "        print(f\"\\nTotal series available: {len(all_series_data)}\")\n",
    "        print(\"\\nSample series (first 20):\")\n",
    "        for s in all_series_data[:20]:\n",
    "            print(f\"  - {s['ticker']}: {s['title']} (Category: {s.get('category', 'N/A')})\")\n",
    "\n",
    "# Display found series\n",
    "if unique_series:\n",
    "    print(\"\\nClimate series found:\")\n",
    "    for s in unique_series:\n",
    "        print(f\"  - {s['ticker']}: {s['title']}\")\n",
    "        print(f\"    Category: {s.get('category', 'N/A')}, Tags: {s.get('tags', [])}\")\n",
    "\n",
    "# Store series tickers for market fetching\n",
    "climate_series_tickers = [s['ticker'] for s in unique_series]\n",
    "print(f\"\\n✓ Will fetch markets for {len(climate_series_tickers)} climate series\")\n",
    "\n",
    "climate_series_list = list(unique_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a801e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "nastpjec8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FETCHING MARKETS FOR CLIMATE SERIES\n",
      "================================================================================\n",
      "\n",
      "⚠ No climate series found. Trying category-based search...\n",
      "  Error fetching category 'Science': object of type 'NoneType' has no len()\n",
      "  Error fetching category 'Environment': object of type 'NoneType' has no len()\n",
      "  Error fetching category 'Weather': object of type 'NoneType' has no len()\n",
      "\n",
      "Fetching settled markets for 0 series...\n",
      "(This may take a few minutes...)\n",
      "\n",
      "\n",
      "================================================================================\n",
      "✓ TOTAL MARKETS FETCHED: 0\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 2: Fetch All Markets for Climate Series\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FETCHING MARKETS FOR CLIMATE SERIES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# If no climate series found, fall back to manually specifying some categories\n",
    "if len(climate_series_tickers) == 0:\n",
    "    print(\"\\n⚠ No climate series found. Trying category-based search...\")\n",
    "    \n",
    "    # Try fetching by category\n",
    "    categories_to_try = [\"Science\", \"Environment\", \"Weather\"]\n",
    "    \n",
    "    for category in categories_to_try:\n",
    "        try:\n",
    "            response = requests.get(f\"{base_url}/series\", params={\"category\": category, \"limit\": 200})\n",
    "            if response.status_code == 200:\n",
    "                series = response.json().get('series', [])\n",
    "                print(f\"\\n  Category '{category}': Found {len(series)} series\")\n",
    "                if series:\n",
    "                    for s in series[:5]:\n",
    "                        print(f\"    - {s['ticker']}: {s['title']}\")\n",
    "                all_series.extend(series)\n",
    "            time.sleep(0.5)\n",
    "        except Exception as e:\n",
    "            print(f\"  Error fetching category '{category}': {e}\")\n",
    "    \n",
    "    unique_series = {s['ticker']: s for s in all_series}.values()\n",
    "    climate_series_tickers = [s['ticker'] for s in unique_series]\n",
    "    climate_series_list = list(unique_series)\n",
    "\n",
    "# Fetch all markets for these series\n",
    "all_markets = []\n",
    "\n",
    "print(f\"\\nFetching settled markets for {len(climate_series_tickers)} series...\")\n",
    "print(\"(This may take a few minutes...)\\n\")\n",
    "\n",
    "for i, series_ticker in enumerate(climate_series_tickers, 1):\n",
    "    cursor = None\n",
    "    series_markets = []\n",
    "    \n",
    "    while True:\n",
    "        params = {\n",
    "            \"series_ticker\": series_ticker,\n",
    "            \"status\": \"settled\",  # Only settled markets for backtesting\n",
    "            \"min_close_ts\": min_close_ts,\n",
    "            \"max_close_ts\": max_close_ts,\n",
    "            \"limit\": 1000\n",
    "        }\n",
    "        \n",
    "        if cursor:\n",
    "            params[\"cursor\"] = cursor\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(f\"{base_url}/markets\", params=params)\n",
    "            \n",
    "            if response.status_code == 429:\n",
    "                print(f\"  Rate limited, waiting 2 seconds...\")\n",
    "                time.sleep(2)\n",
    "                continue\n",
    "            \n",
    "            if response.status_code != 200:\n",
    "                print(f\"  ✗ Error for {series_ticker}: Status {response.status_code}\")\n",
    "                break\n",
    "            \n",
    "            data = response.json()\n",
    "            markets = data.get('markets', [])\n",
    "            series_markets.extend(markets)\n",
    "            \n",
    "            cursor = data.get('cursor')\n",
    "            if not cursor:\n",
    "                break\n",
    "            \n",
    "            time.sleep(0.3)  # Rate limiting\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ Error fetching {series_ticker}: {e}\")\n",
    "            break\n",
    "    \n",
    "    if series_markets:\n",
    "        all_markets.extend(series_markets)\n",
    "        print(f\"  [{i}/{len(climate_series_tickers)}] {series_ticker}: {len(series_markets)} markets\")\n",
    "    \n",
    "    # Progress update every 5 series\n",
    "    if i % 5 == 0:\n",
    "        print(f\"  Progress: {i}/{len(climate_series_tickers)} series processed, {len(all_markets)} total markets\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"✓ TOTAL MARKETS FETCHED: {len(all_markets)}\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Store raw markets\n",
    "climate_markets_raw = all_markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a91fb3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zxlihvk7elc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 3: Filter Markets by Duration and Liquidity Constraints\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"APPLYING FILTERS: DURATION >= 5 DAYS, LIQUIDITY >= $100,000\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Target thresholds\n",
    "MIN_DURATION_HOURS = 5 * 24  # 5 days = 120 hours\n",
    "MIN_LIQUIDITY_DOLLARS = 100000  # $100,000\n",
    "\n",
    "# Apply filters\n",
    "filtered_markets = []\n",
    "filter_stats = {\n",
    "    'total': len(climate_markets_raw),\n",
    "    'duration_pass': 0,\n",
    "    'liquidity_pass': 0,\n",
    "    'both_pass': 0,\n",
    "    'duration_fail': 0,\n",
    "    'liquidity_fail': 0\n",
    "}\n",
    "\n",
    "for market in climate_markets_raw:\n",
    "    # Parse timestamps\n",
    "    try:\n",
    "        open_time = datetime.fromisoformat(market['open_time'].replace('Z', '+00:00'))\n",
    "        close_time = datetime.fromisoformat(market['close_time'].replace('Z', '+00:00'))\n",
    "        duration_hours = (close_time - open_time).total_seconds() / 3600\n",
    "        \n",
    "        liquidity_dollars = float(market.get('liquidity_dollars', '0'))\n",
    "        \n",
    "        # Track filter pass rates\n",
    "        duration_ok = duration_hours >= MIN_DURATION_HOURS\n",
    "        liquidity_ok = liquidity_dollars >= MIN_LIQUIDITY_DOLLARS\n",
    "        \n",
    "        if duration_ok:\n",
    "            filter_stats['duration_pass'] += 1\n",
    "        else:\n",
    "            filter_stats['duration_fail'] += 1\n",
    "        \n",
    "        if liquidity_ok:\n",
    "            filter_stats['liquidity_pass'] += 1\n",
    "        else:\n",
    "            filter_stats['liquidity_fail'] += 1\n",
    "        \n",
    "        # Both filters must pass\n",
    "        if duration_ok and liquidity_ok:\n",
    "            market['duration_hours'] = duration_hours\n",
    "            market['liquidity_dollars_float'] = liquidity_dollars\n",
    "            filtered_markets.append(market)\n",
    "            filter_stats['both_pass'] += 1\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  Error processing market {market.get('ticker', 'unknown')}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\nFilter Results:\")\n",
    "print(f\"  Total markets:           {filter_stats['total']}\")\n",
    "print(f\"  Duration filter (>= 5d): {filter_stats['duration_pass']} passed, {filter_stats['duration_fail']} failed\")\n",
    "print(f\"  Liquidity filter (>=$100k): {filter_stats['liquidity_pass']} passed, {filter_stats['liquidity_fail']} failed\")\n",
    "print(f\"  ✓ Both filters passed:   {filter_stats['both_pass']} markets\")\n",
    "\n",
    "# If no markets pass strict filters, try lower thresholds\n",
    "if filter_stats['both_pass'] == 0:\n",
    "    print(\"\\n\" + \"⚠\"*40)\n",
    "    print(\"⚠ NO MARKETS PASSED STRICT FILTERS\")\n",
    "    print(\"⚠ Lowering thresholds to find available data...\")\n",
    "    print(\"⚠\"*40)\n",
    "    \n",
    "    # Try progressively lower thresholds\n",
    "    thresholds_to_try = [\n",
    "        (3 * 24, 50000),   # 3 days, $50k\n",
    "        (2 * 24, 25000),   # 2 days, $25k\n",
    "        (1 * 24, 10000),   # 1 day, $10k\n",
    "        (0, 0)             # No filters\n",
    "    ]\n",
    "    \n",
    "    for min_dur, min_liq in thresholds_to_try:\n",
    "        filtered_markets = []\n",
    "        for market in climate_markets_raw:\n",
    "            try:\n",
    "                open_time = datetime.fromisoformat(market['open_time'].replace('Z', '+00:00'))\n",
    "                close_time = datetime.fromisoformat(market['close_time'].replace('Z', '+00:00'))\n",
    "                duration_hours = (close_time - open_time).total_seconds() / 3600\n",
    "                liquidity_dollars = float(market.get('liquidity_dollars', '0'))\n",
    "                \n",
    "                if duration_hours >= min_dur and liquidity_dollars >= min_liq:\n",
    "                    market['duration_hours'] = duration_hours\n",
    "                    market['liquidity_dollars_float'] = liquidity_dollars\n",
    "                    filtered_markets.append(market)\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        if len(filtered_markets) > 0:\n",
    "            print(f\"\\n✓ Found {len(filtered_markets)} markets with:\")\n",
    "            print(f\"  - Duration >= {min_dur/24:.1f} days\")\n",
    "            print(f\"  - Liquidity >= ${min_liq:,}\")\n",
    "            MIN_DURATION_HOURS = min_dur\n",
    "            MIN_LIQUIDITY_DOLLARS = min_liq\n",
    "            break\n",
    "    \n",
    "    if len(filtered_markets) == 0:\n",
    "        print(\"\\n⚠ WARNING: No climate markets found even with lowered thresholds!\")\n",
    "        print(\"Showing sample of available markets:\\n\")\n",
    "        for i, m in enumerate(climate_markets_raw[:5], 1):\n",
    "            try:\n",
    "                open_time = datetime.fromisoformat(m['open_time'].replace('Z', '+00:00'))\n",
    "                close_time = datetime.fromisoformat(m['close_time'].replace('Z', '+00:00'))\n",
    "                duration = (close_time - open_time).total_seconds() / 3600\n",
    "                liq = float(m.get('liquidity_dollars', '0'))\n",
    "                print(f\"  {i}. {m['ticker']}\")\n",
    "                print(f\"     Duration: {duration/24:.2f} days, Liquidity: ${liq:,.2f}\")\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"✓ QUALIFIED MARKETS: {len(filtered_markets)}\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Show sample of qualified markets\n",
    "if filtered_markets:\n",
    "    print(\"\\nSample qualified markets (first 5):\")\n",
    "    for i, m in enumerate(filtered_markets[:5], 1):\n",
    "        print(f\"\\n  {i}. {m['ticker']}\")\n",
    "        print(f\"     Title: {m.get('title', 'N/A')}\")\n",
    "        print(f\"     Duration: {m['duration_hours']/24:.2f} days\")\n",
    "        print(f\"     Liquidity: ${m['liquidity_dollars_float']:,.2f}\")\n",
    "        print(f\"     Open: {m['open_time']}\")\n",
    "        print(f\"     Close: {m['close_time']}\")\n",
    "        print(f\"     Result: {m.get('result', 'N/A')}\")\n",
    "\n",
    "climate_markets_qualified = filtered_markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tctsx1pxt8p",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 4: Group by Event and Calculate Entry Points\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GROUPING MARKETS BY EVENT & CALCULATING ENTRY POINTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Group markets by event_ticker to identify multi-decision markets\n",
    "events_dict = {}\n",
    "\n",
    "for market in climate_markets_qualified:\n",
    "    event_ticker = market.get('event_ticker', market['ticker'])\n",
    "    \n",
    "    if event_ticker not in events_dict:\n",
    "        events_dict[event_ticker] = []\n",
    "    \n",
    "    # Calculate entry point (12 hours before close)\n",
    "    close_time = datetime.fromisoformat(market['close_time'].replace('Z', '+00:00'))\n",
    "    entry_time = close_time - timedelta(hours=12)\n",
    "    \n",
    "    # Add entry info to market\n",
    "    market['entry_time'] = entry_time\n",
    "    market['entry_time_str'] = entry_time.isoformat()\n",
    "    market['close_time_dt'] = close_time\n",
    "    \n",
    "    events_dict[event_ticker].append(market)\n",
    "\n",
    "print(f\"\\n✓ Found {len(events_dict)} unique events\")\n",
    "\n",
    "# Classify events by number of markets (outcomes)\n",
    "event_classification = {\n",
    "    'single': [],      # 1 market (binary event)\n",
    "    'multi': []        # 2+ markets (multi-decision event)\n",
    "}\n",
    "\n",
    "for event_ticker, markets in events_dict.items():\n",
    "    if len(markets) == 1:\n",
    "        event_classification['single'].append(event_ticker)\n",
    "    else:\n",
    "        event_classification['multi'].append(event_ticker)\n",
    "\n",
    "print(f\"\\nEvent Classification:\")\n",
    "print(f\"  Single-outcome events: {len(event_classification['single'])}\")\n",
    "print(f\"  Multi-outcome events:  {len(event_classification['multi'])}\")\n",
    "\n",
    "# Focus on multi-decision events for the strategy\n",
    "multi_decision_events = {k: v for k, v in events_dict.items() if len(v) >= 2}\n",
    "\n",
    "print(f\"\\n✓ Multi-decision events for strategy: {len(multi_decision_events)}\")\n",
    "\n",
    "# Show sample multi-decision events\n",
    "if multi_decision_events:\n",
    "    print(\"\\nSample multi-decision events (first 3):\")\n",
    "    for i, (event_ticker, markets) in enumerate(list(multi_decision_events.items())[:3], 1):\n",
    "        print(f\"\\n  {i}. Event: {event_ticker}\")\n",
    "        print(f\"     Number of markets: {len(markets)}\")\n",
    "        print(f\"     Entry time: {markets[0]['entry_time'].strftime('%Y-%m-%d %H:%M:%S UTC')}\")\n",
    "        print(f\"     Close time: {markets[0]['close_time_dt'].strftime('%Y-%m-%d %H:%M:%S UTC')}\")\n",
    "        print(f\"     Markets:\")\n",
    "        for m in markets:\n",
    "            print(f\"       - {m['ticker']}: {m.get('title', 'N/A')[:60]}...\")\n",
    "            print(f\"         Yes bid/ask: ${m.get('yes_bid', 0)/100:.2f}/${m.get('yes_ask', 0)/100:.2f}\")\n",
    "            print(f\"         Result: {m.get('result', 'N/A')}\")\n",
    "\n",
    "# Also include single binary events for completeness\n",
    "all_tradeable_events = events_dict.copy()\n",
    "\n",
    "print(f\"\\n✓ Total tradeable events (single + multi): {len(all_tradeable_events)}\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oxiz07cflq",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 5: Organize Events by Entry Date for Daily Trading\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ORGANIZING EVENTS BY ENTRY DATE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Organize events by entry date (just the date, not time)\n",
    "events_by_entry_date = {}\n",
    "\n",
    "for event_ticker, markets in all_tradeable_events.items():\n",
    "    # All markets in an event have the same entry time\n",
    "    entry_time = markets[0]['entry_time']\n",
    "    entry_date = entry_time.date()\n",
    "    \n",
    "    if entry_date not in events_by_entry_date:\n",
    "        events_by_entry_date[entry_date] = []\n",
    "    \n",
    "    events_by_entry_date[entry_date].append({\n",
    "        'event_ticker': event_ticker,\n",
    "        'markets': markets,\n",
    "        'entry_time': entry_time,\n",
    "        'num_markets': len(markets)\n",
    "    })\n",
    "\n",
    "# Sort dates\n",
    "sorted_dates = sorted(events_by_entry_date.keys())\n",
    "\n",
    "print(f\"\\n✓ Trading spans {len(sorted_dates)} unique dates\")\n",
    "print(f\"  First entry date: {sorted_dates[0] if sorted_dates else 'N/A'}\")\n",
    "print(f\"  Last entry date:  {sorted_dates[-1] if sorted_dates else 'N/A'}\")\n",
    "\n",
    "# Show distribution of events per day\n",
    "events_per_day = [len(events) for events in events_by_entry_date.values()]\n",
    "if events_per_day:\n",
    "    print(f\"\\nEvents per day statistics:\")\n",
    "    print(f\"  Average: {np.mean(events_per_day):.2f}\")\n",
    "    print(f\"  Median:  {np.median(events_per_day):.0f}\")\n",
    "    print(f\"  Max:     {np.max(events_per_day)}\")\n",
    "    print(f\"  Min:     {np.min(events_per_day)}\")\n",
    "\n",
    "# Show sample daily schedule\n",
    "print(f\"\\nSample daily schedule (first 5 days):\")\n",
    "for i, date in enumerate(sorted_dates[:5], 1):\n",
    "    events = events_by_entry_date[date]\n",
    "    print(f\"\\n  Day {i}: {date}\")\n",
    "    print(f\"  Events to trade: {len(events)}\")\n",
    "    for event in events[:3]:  # Show first 3 events\n",
    "        print(f\"    - {event['event_ticker']}: {event['num_markets']} markets\")\n",
    "    if len(events) > 3:\n",
    "        print(f\"    ... and {len(events) - 3} more events\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rqr01arqv4r",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 6: Simulate Trading Strategy\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SIMULATING TRADING STRATEGY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Strategy parameters\n",
    "INITIAL_CAPITAL = 100000  # $100,000\n",
    "DAILY_BUDGET = 10000      # $10,000 per day\n",
    "YES_ALLOCATION = 0.70     # 70% on YES favorite\n",
    "NO_ALLOCATION = 0.30      # 30% split across NOs\n",
    "\n",
    "# Track all trades\n",
    "all_trades = []\n",
    "trade_id = 0\n",
    "\n",
    "print(f\"\\nStrategy Parameters:\")\n",
    "print(f\"  Initial capital:  ${INITIAL_CAPITAL:,}\")\n",
    "print(f\"  Daily budget:     ${DAILY_BUDGET:,}\")\n",
    "print(f\"  YES allocation:   {YES_ALLOCATION*100:.0f}%\")\n",
    "print(f\"  NO allocation:    {NO_ALLOCATION*100:.0f}% (split across NOs)\")\n",
    "\n",
    "print(f\"\\n{'-'*80}\")\n",
    "print(\"Processing trades...\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Process each trading day\n",
    "for date in sorted_dates:\n",
    "    events_today = events_by_entry_date[date]\n",
    "    num_events = len(events_today)\n",
    "    \n",
    "    if num_events == 0:\n",
    "        continue\n",
    "    \n",
    "    # Allocate budget across events\n",
    "    budget_per_event = DAILY_BUDGET / num_events\n",
    "    \n",
    "    # Process each event\n",
    "    for event in events_today:\n",
    "        event_ticker = event['event_ticker']\n",
    "        markets = event['markets']\n",
    "        num_markets = len(markets)\n",
    "        \n",
    "        # For multi-decision events: YES on favorite, NO on others\n",
    "        # For single binary: YES if probability > 50%, else NO\n",
    "        \n",
    "        if num_markets >= 2:\n",
    "            # Multi-decision: identify favorite (highest yes_bid)\n",
    "            favorite = max(markets, key=lambda m: m.get('yes_bid', 0))\n",
    "            others = [m for m in markets if m != favorite]\n",
    "            \n",
    "            # Position sizing:\n",
    "            # 70% on YES favorite\n",
    "            # 30% split across NO on others\n",
    "            yes_size_dollars = budget_per_event * YES_ALLOCATION\n",
    "            no_size_dollars = budget_per_event * NO_ALLOCATION\n",
    "            no_size_per_market = no_size_dollars / len(others) if others else 0\n",
    "            \n",
    "            # Trade 1: Buy YES on favorite\n",
    "            yes_price = favorite.get('yes_ask', favorite.get('yes_bid', 50))  # Use ask price\n",
    "            yes_contracts = (yes_size_dollars * 100) / yes_price if yes_price > 0 else 0\n",
    "            \n",
    "            # Calculate P&L based on result\n",
    "            if favorite.get('result') == 'yes':\n",
    "                yes_pnl = yes_contracts * (100 - yes_price) / 100  # Win: get $1 per contract, paid yes_price\n",
    "            elif favorite.get('result') == 'no':\n",
    "                yes_pnl = -yes_size_dollars  # Loss: lose entire investment\n",
    "            elif favorite.get('result') == 'void':\n",
    "                yes_pnl = 0  # Refund\n",
    "            else:\n",
    "                yes_pnl = 0  # Unknown result\n",
    "            \n",
    "            trade_id += 1\n",
    "            all_trades.append({\n",
    "                'trade_id': trade_id,\n",
    "                'event_ticker': event_ticker,\n",
    "                'ticker': favorite['ticker'],\n",
    "                'entry_date': date,\n",
    "                'entry_time': event['entry_time'],\n",
    "                'close_time': favorite['close_time_dt'],\n",
    "                'side': 'YES',\n",
    "                'price': yes_price / 100,\n",
    "                'contracts': yes_contracts,\n",
    "                'investment': yes_size_dollars,\n",
    "                'result': favorite.get('result', 'unknown'),\n",
    "                'pnl': yes_pnl,\n",
    "                'market_type': 'multi_favorite',\n",
    "                'liquidity': favorite.get('liquidity_dollars_float', 0),\n",
    "                'duration_days': favorite.get('duration_hours', 0) / 24\n",
    "            })\n",
    "            \n",
    "            # Trades 2+: Buy NO on all others\n",
    "            for other in others:\n",
    "                no_price = other.get('no_ask', other.get('no_bid', 50))\n",
    "                no_contracts = (no_size_per_market * 100) / no_price if no_price > 0 else 0\n",
    "                \n",
    "                # Calculate P&L\n",
    "                if other.get('result') == 'no':\n",
    "                    no_pnl = no_contracts * (100 - no_price) / 100  # Win\n",
    "                elif other.get('result') == 'yes':\n",
    "                    no_pnl = -no_size_per_market  # Loss\n",
    "                elif other.get('result') == 'void':\n",
    "                    no_pnl = 0  # Refund\n",
    "                else:\n",
    "                    no_pnl = 0\n",
    "                \n",
    "                trade_id += 1\n",
    "                all_trades.append({\n",
    "                    'trade_id': trade_id,\n",
    "                    'event_ticker': event_ticker,\n",
    "                    'ticker': other['ticker'],\n",
    "                    'entry_date': date,\n",
    "                    'entry_time': event['entry_time'],\n",
    "                    'close_time': other['close_time_dt'],\n",
    "                    'side': 'NO',\n",
    "                    'price': no_price / 100,\n",
    "                    'contracts': no_contracts,\n",
    "                    'investment': no_size_per_market,\n",
    "                    'result': other.get('result', 'unknown'),\n",
    "                    'pnl': no_pnl,\n",
    "                    'market_type': 'multi_other',\n",
    "                    'liquidity': other.get('liquidity_dollars_float', 0),\n",
    "                    'duration_days': other.get('duration_hours', 0) / 24\n",
    "                })\n",
    "        \n",
    "        else:\n",
    "            # Single binary market: buy YES if implied prob > 50%, else NO\n",
    "            market = markets[0]\n",
    "            yes_bid = market.get('yes_bid', 50)\n",
    "            \n",
    "            if yes_bid >= 50:\n",
    "                # Buy YES\n",
    "                yes_price = market.get('yes_ask', yes_bid)\n",
    "                contracts = (budget_per_event * 100) / yes_price if yes_price > 0 else 0\n",
    "                \n",
    "                if market.get('result') == 'yes':\n",
    "                    pnl = contracts * (100 - yes_price) / 100\n",
    "                elif market.get('result') == 'no':\n",
    "                    pnl = -budget_per_event\n",
    "                elif market.get('result') == 'void':\n",
    "                    pnl = 0\n",
    "                else:\n",
    "                    pnl = 0\n",
    "                \n",
    "                side = 'YES'\n",
    "                price = yes_price\n",
    "            else:\n",
    "                # Buy NO\n",
    "                no_price = market.get('no_ask', 100 - yes_bid)\n",
    "                contracts = (budget_per_event * 100) / no_price if no_price > 0 else 0\n",
    "                \n",
    "                if market.get('result') == 'no':\n",
    "                    pnl = contracts * (100 - no_price) / 100\n",
    "                elif market.get('result') == 'yes':\n",
    "                    pnl = -budget_per_event\n",
    "                elif market.get('result') == 'void':\n",
    "                    pnl = 0\n",
    "                else:\n",
    "                    pnl = 0\n",
    "                \n",
    "                side = 'NO'\n",
    "                price = no_price\n",
    "            \n",
    "            trade_id += 1\n",
    "            all_trades.append({\n",
    "                'trade_id': trade_id,\n",
    "                'event_ticker': event_ticker,\n",
    "                'ticker': market['ticker'],\n",
    "                'entry_date': date,\n",
    "                'entry_time': event['entry_time'],\n",
    "                'close_time': market['close_time_dt'],\n",
    "                'side': side,\n",
    "                'price': price / 100,\n",
    "                'contracts': contracts,\n",
    "                'investment': budget_per_event,\n",
    "                'result': market.get('result', 'unknown'),\n",
    "                'pnl': pnl,\n",
    "                'market_type': 'binary',\n",
    "                'liquidity': market.get('liquidity_dollars_float', 0),\n",
    "                'duration_days': market.get('duration_hours', 0) / 24\n",
    "            })\n",
    "\n",
    "print(f\"\\n✓ Simulation complete!\")\n",
    "print(f\"  Total trades executed: {len(all_trades)}\")\n",
    "print(f\"  Trading days: {len(sorted_dates)}\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Convert to DataFrame for easier analysis\n",
    "trades_df = pd.DataFrame(all_trades)\n",
    "\n",
    "# Show sample trades\n",
    "print(f\"\\nSample trades (first 10):\")\n",
    "if not trades_df.empty:\n",
    "    print(trades_df[['trade_id', 'ticker', 'side', 'price', 'investment', 'result', 'pnl']].head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nwdod1w1yy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 7: Build Day-by-Day Equity Curve\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BUILDING DAILY EQUITY CURVE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if trades_df.empty:\n",
    "    print(\"\\n⚠ WARNING: No trades to analyze!\")\n",
    "else:\n",
    "    # Build daily P&L by settlement date (close_time)\n",
    "    # Group trades by the date they close (when P&L is realized)\n",
    "    trades_df['close_date'] = trades_df['close_time'].dt.date\n",
    "    \n",
    "    # Calculate daily P&L\n",
    "    daily_pnl = trades_df.groupby('close_date')['pnl'].sum().sort_index()\n",
    "    \n",
    "    # Build equity curve\n",
    "    equity_curve = pd.Series(dtype=float)\n",
    "    equity_curve[daily_pnl.index[0]] = INITIAL_CAPITAL  # Starting capital\n",
    "    \n",
    "    # Accumulate daily P&L\n",
    "    for date in daily_pnl.index:\n",
    "        prev_date = equity_curve.index[-1]\n",
    "        prev_equity = equity_curve.iloc[-1]\n",
    "        \n",
    "        # Add daily P&L to equity\n",
    "        new_equity = prev_equity + daily_pnl[date]\n",
    "        equity_curve[date] = new_equity\n",
    "    \n",
    "    # Create DataFrame for easier analysis\n",
    "    equity_df = pd.DataFrame({\n",
    "        'date': equity_curve.index,\n",
    "        'equity': equity_curve.values,\n",
    "        'daily_pnl': [0] + list(daily_pnl.values)\n",
    "    })\n",
    "    \n",
    "    # Calculate daily returns\n",
    "    equity_df['daily_return'] = equity_df['equity'].pct_change()\n",
    "    equity_df['cumulative_return'] = (equity_df['equity'] / INITIAL_CAPITAL - 1) * 100\n",
    "    \n",
    "    # Calculate running drawdown\n",
    "    equity_df['running_max'] = equity_df['equity'].cummax()\n",
    "    equity_df['drawdown'] = (equity_df['equity'] - equity_df['running_max']) / equity_df['running_max'] * 100\n",
    "    \n",
    "    print(f\"\\n✓ Equity curve built!\")\n",
    "    print(f\"  Trading days: {len(equity_df)}\")\n",
    "    print(f\"  Start date: {equity_df['date'].iloc[0]}\")\n",
    "    print(f\"  End date: {equity_df['date'].iloc[-1]}\")\n",
    "    \n",
    "    print(f\"\\nEquity Summary:\")\n",
    "    print(f\"  Starting capital: ${INITIAL_CAPITAL:,.2f}\")\n",
    "    print(f\"  Ending equity:    ${equity_df['equity'].iloc[-1]:,.2f}\")\n",
    "    print(f\"  Total P&L:        ${equity_df['equity'].iloc[-1] - INITIAL_CAPITAL:,.2f}\")\n",
    "    print(f\"  Total return:     {equity_df['cumulative_return'].iloc[-1]:.2f}%\")\n",
    "    \n",
    "    # Show daily equity progression (sample)\n",
    "    print(f\"\\nDaily equity (first 10 days):\")\n",
    "    print(equity_df[['date', 'equity', 'daily_pnl', 'cumulative_return', 'drawdown']].head(10).to_string(index=False))\n",
    "    \n",
    "    print(f\"\\nDaily equity (last 10 days):\")\n",
    "    print(equity_df[['date', 'equity', 'daily_pnl', 'cumulative_return', 'drawdown']].tail(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9uuy8xug2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 8: Calculate Comprehensive Performance Metrics\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CALCULATING PERFORMANCE METRICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if not trades_df.empty and len(equity_df) > 1:\n",
    "    # ========== Returns Analysis ==========\n",
    "    total_return_pct = (equity_df['equity'].iloc[-1] / INITIAL_CAPITAL - 1) * 100\n",
    "    total_pnl = equity_df['equity'].iloc[-1] - INITIAL_CAPITAL\n",
    "    \n",
    "    # Calculate annualized return\n",
    "    days_trading = (equity_df['date'].iloc[-1] - equity_df['date'].iloc[0]).days\n",
    "    years_trading = days_trading / 365.25\n",
    "    cagr = ((equity_df['equity'].iloc[-1] / INITIAL_CAPITAL) ** (1 / years_trading) - 1) * 100 if years_trading > 0 else 0\n",
    "    \n",
    "    # ========== Risk Metrics ==========\n",
    "    # Daily returns for Sharpe calculation (exclude first day with 0 return)\n",
    "    daily_returns = equity_df['daily_return'].dropna()\n",
    "    \n",
    "    if len(daily_returns) > 1:\n",
    "        avg_daily_return = daily_returns.mean()\n",
    "        std_daily_return = daily_returns.std()\n",
    "        \n",
    "        # Sharpe ratio (annualized, assuming 252 trading days, risk-free rate = 0)\n",
    "        sharpe_ratio = (avg_daily_return / std_daily_return * np.sqrt(252)) if std_daily_return > 0 else 0\n",
    "        \n",
    "        # Sortino ratio (downside deviation)\n",
    "        downside_returns = daily_returns[daily_returns < 0]\n",
    "        downside_std = downside_returns.std() if len(downside_returns) > 1 else 0\n",
    "        sortino_ratio = (avg_daily_return / downside_std * np.sqrt(252)) if downside_std > 0 else 0\n",
    "    else:\n",
    "        sharpe_ratio = 0\n",
    "        sortino_ratio = 0\n",
    "        std_daily_return = 0\n",
    "    \n",
    "    # ========== Drawdown Analysis ==========\n",
    "    max_drawdown = equity_df['drawdown'].min()  # Most negative value\n",
    "    max_drawdown_idx = equity_df['drawdown'].idxmin()\n",
    "    max_drawdown_date = equity_df.loc[max_drawdown_idx, 'date']\n",
    "    \n",
    "    # Average drawdown\n",
    "    avg_drawdown = equity_df['drawdown'][equity_df['drawdown'] < 0].mean()\n",
    "    \n",
    "    # Drawdown duration (consecutive days in drawdown)\n",
    "    in_drawdown = equity_df['drawdown'] < -0.01  # More than 0.01% drawdown\n",
    "    drawdown_periods = in_drawdown.astype(int).diff().fillna(0)\n",
    "    \n",
    "    # ========== Trade Statistics ==========\n",
    "    total_trades = len(trades_df)\n",
    "    winning_trades = len(trades_df[trades_df['pnl'] > 0])\n",
    "    losing_trades = len(trades_df[trades_df['pnl'] < 0])\n",
    "    breakeven_trades = len(trades_df[trades_df['pnl'] == 0])\n",
    "    \n",
    "    win_rate = (winning_trades / total_trades * 100) if total_trades > 0 else 0\n",
    "    \n",
    "    avg_win = trades_df[trades_df['pnl'] > 0]['pnl'].mean() if winning_trades > 0 else 0\n",
    "    avg_loss = trades_df[trades_df['pnl'] < 0]['pnl'].mean() if losing_trades > 0 else 0\n",
    "    \n",
    "    profit_factor = (trades_df[trades_df['pnl'] > 0]['pnl'].sum() / \n",
    "                     abs(trades_df[trades_df['pnl'] < 0]['pnl'].sum())) if losing_trades > 0 else float('inf')\n",
    "    \n",
    "    # Expectancy per trade\n",
    "    expectancy = trades_df['pnl'].mean()\n",
    "    \n",
    "    # ========== Display Results ==========\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"OVERALL STRATEGY PERFORMANCE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"\\n📊 RETURNS:\")\n",
    "    print(f\"  Total Return:        {total_return_pct:>10.2f}%\")\n",
    "    print(f\"  Total P&L:           ${total_pnl:>10,.2f}\")\n",
    "    print(f\"  CAGR:                {cagr:>10.2f}%\")\n",
    "    print(f\"  Trading Period:      {days_trading} days ({years_trading:.2f} years)\")\n",
    "    \n",
    "    print(f\"\\n📉 RISK METRICS:\")\n",
    "    print(f\"  Sharpe Ratio:        {sharpe_ratio:>10.2f}\")\n",
    "    print(f\"  Sortino Ratio:       {sortino_ratio:>10.2f}\")\n",
    "    print(f\"  Daily Volatility:    {std_daily_return*100:>10.2f}%\")\n",
    "    print(f\"  Max Drawdown:        {max_drawdown:>10.2f}% (on {max_drawdown_date})\")\n",
    "    print(f\"  Avg Drawdown:        {avg_drawdown:>10.2f}%\")\n",
    "    \n",
    "    print(f\"\\n💰 TRADE STATISTICS:\")\n",
    "    print(f\"  Total Trades:        {total_trades:>10,}\")\n",
    "    print(f\"  Winning Trades:      {winning_trades:>10,} ({win_rate:.1f}%)\")\n",
    "    print(f\"  Losing Trades:       {losing_trades:>10,}\")\n",
    "    print(f\"  Breakeven Trades:    {breakeven_trades:>10,}\")\n",
    "    print(f\"  Win Rate:            {win_rate:>10.1f}%\")\n",
    "    print(f\"  Avg Win:             ${avg_win:>10,.2f}\")\n",
    "    print(f\"  Avg Loss:            ${avg_loss:>10,.2f}\")\n",
    "    print(f\"  Profit Factor:       {profit_factor if profit_factor != float('inf') else 'N/A':>10}\")\n",
    "    print(f\"  Expectancy/Trade:    ${expectancy:>10,.2f}\")\n",
    "    \n",
    "    print(f\"\\n💵 CAPITAL EFFICIENCY:\")\n",
    "    total_invested = trades_df['investment'].sum()\n",
    "    print(f\"  Total Invested:      ${total_invested:>10,.2f}\")\n",
    "    print(f\"  ROI on Invested:     {(total_pnl / total_invested * 100) if total_invested > 0 else 0:>10.2f}%\")\n",
    "    \n",
    "    # Store metrics for later use\n",
    "    performance_metrics = {\n",
    "        'total_return_pct': total_return_pct,\n",
    "        'total_pnl': total_pnl,\n",
    "        'cagr': cagr,\n",
    "        'sharpe_ratio': sharpe_ratio,\n",
    "        'sortino_ratio': sortino_ratio,\n",
    "        'max_drawdown': max_drawdown,\n",
    "        'avg_drawdown': avg_drawdown,\n",
    "        'win_rate': win_rate,\n",
    "        'profit_factor': profit_factor,\n",
    "        'expectancy': expectancy,\n",
    "        'total_trades': total_trades,\n",
    "        'winning_trades': winning_trades,\n",
    "        'losing_trades': losing_trades\n",
    "    }\n",
    "\n",
    "else:\n",
    "    print(\"\\n⚠ WARNING: Insufficient data for metrics calculation!\")\n",
    "    performance_metrics = {}\n",
    "\n",
    "print(f\"\\n{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbu76v3878o",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 9: Analyze Top 5% Liquidity Markets Separately\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYZING TOP 5% LIQUIDITY MARKETS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if not trades_df.empty:\n",
    "    # Calculate 95th percentile of liquidity\n",
    "    liquidity_95th_percentile = trades_df['liquidity'].quantile(0.95)\n",
    "    \n",
    "    print(f\"\\nLiquidity threshold (top 5%):\")\n",
    "    print(f\"  95th percentile: ${liquidity_95th_percentile:,.2f}\")\n",
    "    \n",
    "    # Filter to top 5% liquidity trades\n",
    "    top_5_pct_trades = trades_df[trades_df['liquidity'] >= liquidity_95th_percentile].copy()\n",
    "    \n",
    "    print(f\"\\n✓ Found {len(top_5_pct_trades)} trades in top 5% liquidity\")\n",
    "    print(f\"  ({len(top_5_pct_trades) / len(trades_df) * 100:.1f}% of all trades)\")\n",
    "    \n",
    "    if len(top_5_pct_trades) > 0:\n",
    "        # Calculate metrics for top 5% markets\n",
    "        top_5_total_pnl = top_5_pct_trades['pnl'].sum()\n",
    "        top_5_winning = len(top_5_pct_trades[top_5_pct_trades['pnl'] > 0])\n",
    "        top_5_losing = len(top_5_pct_trades[top_5_pct_trades['pnl'] < 0])\n",
    "        top_5_win_rate = (top_5_winning / len(top_5_pct_trades) * 100) if len(top_5_pct_trades) > 0 else 0\n",
    "        \n",
    "        top_5_avg_win = top_5_pct_trades[top_5_pct_trades['pnl'] > 0]['pnl'].mean() if top_5_winning > 0 else 0\n",
    "        top_5_avg_loss = top_5_pct_trades[top_5_pct_trades['pnl'] < 0]['pnl'].mean() if top_5_losing > 0 else 0\n",
    "        \n",
    "        top_5_profit_factor = (top_5_pct_trades[top_5_pct_trades['pnl'] > 0]['pnl'].sum() / \n",
    "                               abs(top_5_pct_trades[top_5_pct_trades['pnl'] < 0]['pnl'].sum())) if top_5_losing > 0 else float('inf')\n",
    "        \n",
    "        # Build equity curve for top 5% markets only\n",
    "        top_5_daily_pnl = top_5_pct_trades.groupby('close_date')['pnl'].sum().sort_index()\n",
    "        \n",
    "        # Construct top 5% equity curve\n",
    "        top_5_equity_curve = pd.Series(dtype=float)\n",
    "        top_5_equity_curve[top_5_daily_pnl.index[0]] = INITIAL_CAPITAL\n",
    "        \n",
    "        for date in top_5_daily_pnl.index:\n",
    "            prev_equity = top_5_equity_curve.iloc[-1]\n",
    "            new_equity = prev_equity + top_5_daily_pnl[date]\n",
    "            top_5_equity_curve[date] = new_equity\n",
    "        \n",
    "        top_5_equity_df = pd.DataFrame({\n",
    "            'date': top_5_equity_curve.index,\n",
    "            'equity': top_5_equity_curve.values,\n",
    "            'daily_pnl': [0] + list(top_5_daily_pnl.values)\n",
    "        })\n",
    "        \n",
    "        top_5_equity_df['daily_return'] = top_5_equity_df['equity'].pct_change()\n",
    "        top_5_equity_df['running_max'] = top_5_equity_df['equity'].cummax()\n",
    "        top_5_equity_df['drawdown'] = (top_5_equity_df['equity'] - top_5_equity_df['running_max']) / top_5_equity_df['running_max'] * 100\n",
    "        \n",
    "        # Calculate Sharpe ratio for top 5%\n",
    "        top_5_daily_returns = top_5_equity_df['daily_return'].dropna()\n",
    "        if len(top_5_daily_returns) > 1:\n",
    "            top_5_avg_return = top_5_daily_returns.mean()\n",
    "            top_5_std_return = top_5_daily_returns.std()\n",
    "            top_5_sharpe = (top_5_avg_return / top_5_std_return * np.sqrt(252)) if top_5_std_return > 0 else 0\n",
    "        else:\n",
    "            top_5_sharpe = 0\n",
    "        \n",
    "        top_5_max_dd = top_5_equity_df['drawdown'].min()\n",
    "        top_5_total_return = (top_5_equity_df['equity'].iloc[-1] / INITIAL_CAPITAL - 1) * 100\n",
    "        \n",
    "        # Display results\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"TOP 5% LIQUIDITY MARKETS PERFORMANCE\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        print(f\"\\n📊 RETURNS:\")\n",
    "        print(f\"  Total P&L:           ${top_5_total_pnl:>10,.2f}\")\n",
    "        print(f\"  Total Return:        {top_5_total_return:>10.2f}%\")\n",
    "        print(f\"  Contribution to Total: {(top_5_total_pnl / total_pnl * 100) if total_pnl != 0 else 0:>8.1f}%\")\n",
    "        \n",
    "        print(f\"\\n📉 RISK METRICS:\")\n",
    "        print(f\"  Sharpe Ratio:        {top_5_sharpe:>10.2f}\")\n",
    "        print(f\"  Max Drawdown:        {top_5_max_dd:>10.2f}%\")\n",
    "        \n",
    "        print(f\"\\n💰 TRADE STATISTICS:\")\n",
    "        print(f\"  Total Trades:        {len(top_5_pct_trades):>10,}\")\n",
    "        print(f\"  Win Rate:            {top_5_win_rate:>10.1f}%\")\n",
    "        print(f\"  Avg Win:             ${top_5_avg_win:>10,.2f}\")\n",
    "        print(f\"  Avg Loss:            ${top_5_avg_loss:>10,.2f}\")\n",
    "        print(f\"  Profit Factor:       {top_5_profit_factor if top_5_profit_factor != float('inf') else 'N/A':>10}\")\n",
    "        \n",
    "        # Comparison with overall strategy\n",
    "        print(f\"\\n📈 COMPARISON VS OVERALL:\")\n",
    "        print(f\"  Win Rate Diff:       {top_5_win_rate - win_rate:>+10.1f} pp\")\n",
    "        print(f\"  Sharpe Diff:         {top_5_sharpe - sharpe_ratio:>+10.2f}\")\n",
    "        print(f\"  Max DD Diff:         {top_5_max_dd - max_drawdown:>+10.2f} pp\")\n",
    "        \n",
    "        # Store top 5% metrics\n",
    "        top_5_metrics = {\n",
    "            'total_pnl': top_5_total_pnl,\n",
    "            'total_return': top_5_total_return,\n",
    "            'sharpe_ratio': top_5_sharpe,\n",
    "            'max_drawdown': top_5_max_dd,\n",
    "            'win_rate': top_5_win_rate,\n",
    "            'profit_factor': top_5_profit_factor,\n",
    "            'num_trades': len(top_5_pct_trades)\n",
    "        }\n",
    "        \n",
    "    else:\n",
    "        print(\"\\n⚠ No trades found in top 5% liquidity\")\n",
    "        top_5_metrics = {}\n",
    "        top_5_equity_df = pd.DataFrame()\n",
    "else:\n",
    "    print(\"\\n⚠ No trades data available\")\n",
    "    top_5_metrics = {}\n",
    "    top_5_equity_df = pd.DataFrame()\n",
    "\n",
    "print(f\"\\n{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hubiyi99l9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 10: Summary & Key Visualizations\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BACKTEST SUMMARY & KEY INSIGHTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if not trades_df.empty and len(equity_df) > 0:\n",
    "    print(f\"\\n📋 STRATEGY CONFIGURATION:\")\n",
    "    print(f\"  Market Universe:     Climate markets\")\n",
    "    print(f\"  Time Period:         {equity_df['date'].iloc[0]} to {equity_df['date'].iloc[-1]}\")\n",
    "    print(f\"  Filters Applied:     Duration >= {MIN_DURATION_HOURS/24:.1f} days, Liquidity >= ${MIN_LIQUIDITY_DOLLARS:,}\")\n",
    "    print(f\"  Entry Timing:        12 hours before market close\")\n",
    "    print(f\"  Position Sizing:     70% YES on favorite, 30% NO on others\")\n",
    "    print(f\"  Daily Budget:        ${DAILY_BUDGET:,}\")\n",
    "    print(f\"  Initial Capital:     ${INITIAL_CAPITAL:,}\")\n",
    "    \n",
    "    print(f\"\\n🎯 KEY RESULTS:\")\n",
    "    print(f\"  Final Equity:        ${equity_df['equity'].iloc[-1]:>12,.2f}\")\n",
    "    print(f\"  Total Return:        {performance_metrics.get('total_return_pct', 0):>12.2f}%\")\n",
    "    print(f\"  CAGR:                {performance_metrics.get('cagr', 0):>12.2f}%\")\n",
    "    print(f\"  Sharpe Ratio:        {performance_metrics.get('sharpe_ratio', 0):>12.2f}\")\n",
    "    print(f\"  Max Drawdown:        {performance_metrics.get('max_drawdown', 0):>12.2f}%\")\n",
    "    print(f\"  Win Rate:            {performance_metrics.get('win_rate', 0):>12.1f}%\")\n",
    "    print(f\"  Total Trades:        {performance_metrics.get('total_trades', 0):>12,}\")\n",
    "    \n",
    "    print(f\"\\n📊 MONTHLY BREAKDOWN:\")\n",
    "    # Add month/year to trades\n",
    "    trades_df['month'] = pd.to_datetime(trades_df['close_date']).dt.to_period('M')\n",
    "    monthly_pnl = trades_df.groupby('month')['pnl'].sum()\n",
    "    monthly_trades = trades_df.groupby('month').size()\n",
    "    \n",
    "    print(f\"  {'Month':<12} {'Trades':>8} {'P&L':>12} {'Cum. Return':>12}\")\n",
    "    print(f\"  {'-'*50}\")\n",
    "    \n",
    "    cumulative_pnl = 0\n",
    "    for month in monthly_pnl.index:\n",
    "        cumulative_pnl += monthly_pnl[month]\n",
    "        cum_return_pct = (cumulative_pnl / INITIAL_CAPITAL) * 100\n",
    "        print(f\"  {str(month):<12} {monthly_trades[month]:>8,} ${monthly_pnl[month]:>11,.2f} {cum_return_pct:>11.2f}%\")\n",
    "    \n",
    "    print(f\"\\n📈 BEST & WORST DAYS:\")\n",
    "    best_days = equity_df.nlargest(5, 'daily_pnl')[['date', 'daily_pnl', 'equity']]\n",
    "    worst_days = equity_df.nsmallest(5, 'daily_pnl')[['date', 'daily_pnl', 'equity']]\n",
    "    \n",
    "    print(f\"\\n  Best 5 Days:\")\n",
    "    print(f\"  {'Date':<12} {'Daily P&L':>12} {'Equity':>14}\")\n",
    "    print(f\"  {'-'*40}\")\n",
    "    for _, row in best_days.iterrows():\n",
    "        print(f\"  {str(row['date']):<12} ${row['daily_pnl']:>11,.2f} ${row['equity']:>13,.2f}\")\n",
    "    \n",
    "    print(f\"\\n  Worst 5 Days:\")\n",
    "    print(f\"  {'Date':<12} {'Daily P&L':>12} {'Equity':>14}\")\n",
    "    print(f\"  {'-'*40}\")\n",
    "    for _, row in worst_days.iterrows():\n",
    "        print(f\"  {str(row['date']):<12} ${row['daily_pnl']:>11,.2f} ${row['equity']:>13,.2f}\")\n",
    "    \n",
    "    print(f\"\\n💡 KEY INSIGHTS:\")\n",
    "    \n",
    "    # Insight 1: Overall profitability\n",
    "    if performance_metrics.get('total_return_pct', 0) > 0:\n",
    "        print(f\"  ✓ Strategy is profitable with {performance_metrics.get('total_return_pct', 0):.2f}% total return\")\n",
    "    else:\n",
    "        print(f\"  ✗ Strategy is unprofitable with {performance_metrics.get('total_return_pct', 0):.2f}% total return\")\n",
    "    \n",
    "    # Insight 2: Risk-adjusted returns\n",
    "    sharpe = performance_metrics.get('sharpe_ratio', 0)\n",
    "    if sharpe > 1:\n",
    "        print(f\"  ✓ Excellent risk-adjusted returns (Sharpe = {sharpe:.2f})\")\n",
    "    elif sharpe > 0.5:\n",
    "        print(f\"  ~ Moderate risk-adjusted returns (Sharpe = {sharpe:.2f})\")\n",
    "    else:\n",
    "        print(f\"  ✗ Poor risk-adjusted returns (Sharpe = {sharpe:.2f})\")\n",
    "    \n",
    "    # Insight 3: Win rate vs expectancy\n",
    "    win_rate = performance_metrics.get('win_rate', 0)\n",
    "    if win_rate > 55:\n",
    "        print(f\"  ✓ High win rate ({win_rate:.1f}%) indicates good market selection\")\n",
    "    elif win_rate > 45:\n",
    "        print(f\"  ~ Moderate win rate ({win_rate:.1f}%)\")\n",
    "    else:\n",
    "        print(f\"  ✗ Low win rate ({win_rate:.1f}%) - strategy struggles to predict outcomes\")\n",
    "    \n",
    "    # Insight 4: Top 5% liquidity comparison\n",
    "    if top_5_metrics:\n",
    "        top_5_sharpe = top_5_metrics.get('sharpe_ratio', 0)\n",
    "        overall_sharpe = performance_metrics.get('sharpe_ratio', 0)\n",
    "        if top_5_sharpe > overall_sharpe:\n",
    "            diff = top_5_sharpe - overall_sharpe\n",
    "            print(f\"  ✓ Top 5% liquidity markets outperform (Sharpe +{diff:.2f})\")\n",
    "        else:\n",
    "            diff = overall_sharpe - top_5_sharpe\n",
    "            print(f\"  ~ Lower liquidity markets perform better (Sharpe +{diff:.2f})\")\n",
    "    \n",
    "    # Insight 5: Max drawdown analysis\n",
    "    max_dd = abs(performance_metrics.get('max_drawdown', 0))\n",
    "    if max_dd < 10:\n",
    "        print(f\"  ✓ Low max drawdown ({max_dd:.1f}%) - capital is well protected\")\n",
    "    elif max_dd < 20:\n",
    "        print(f\"  ~ Moderate max drawdown ({max_dd:.1f}%)\")\n",
    "    else:\n",
    "        print(f\"  ✗ High max drawdown ({max_dd:.1f}%) - significant volatility\")\n",
    "    \n",
    "    print(f\"\\n💾 DATA EXPORTS:\")\n",
    "    print(f\"  trades_df          - All {len(trades_df)} trades with details\")\n",
    "    print(f\"  equity_df          - Daily equity curve\")\n",
    "    print(f\"  performance_metrics - Overall strategy metrics\")\n",
    "    print(f\"  top_5_metrics      - Top 5% liquidity markets metrics\")\n",
    "    print(f\"  top_5_equity_df    - Top 5% equity curve\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n⚠ WARNING: No backtest data available!\")\n",
    "    print(\"  This likely means no climate markets met the filtering criteria.\")\n",
    "    print(\"  Consider:\")\n",
    "    print(\"    - Lowering liquidity threshold (currently ${MIN_LIQUIDITY_DOLLARS:,})\")\n",
    "    print(\"    - Shortening duration requirement (currently {MIN_DURATION_HOURS/24:.1f} days)\")\n",
    "    print(\"    - Broadening market universe beyond climate\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"BACKTEST COMPLETE!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "p0aicirf1s",
   "metadata": {},
   "source": [
    "# Companies Markets Backtesting Strategy\n",
    "\n",
    "## Strategy Overview\n",
    "- **Universe**: All companies-related markets from Kalshi ([Companies Category](https://kalshi.com/category/companies))\n",
    "- **Constraints**: \n",
    "  - Market duration: MIN 1 week (7 days), MAX 1 month (30 days)\n",
    "  - Liquidity: Adaptive threshold (starting at $100k, lowering if needed)\n",
    "- **Entry**: 12 hours before market expiration\n",
    "- **Position Sizing**:\n",
    "  - Daily budget: $10,000 split across all qualifying events\n",
    "  - Per event: 70% on YES favorite, 30% split across NO positions\n",
    "- **Initial Capital**: $100,000\n",
    "- **Timeframe**: Past year\n",
    "\n",
    "## Performance Metrics\n",
    "- Day-by-day equity curve\n",
    "- Cumulative returns and Sharpe ratio\n",
    "- Maximum drawdown analysis\n",
    "- Separate analysis for top 5% liquidity markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "lpj1cxudgk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FETCHING HISTORICAL COMPANIES MARKETS\n",
      "================================================================================\n",
      "\n",
      "Time window:\n",
      "  From: 2025-02-01 08:22:01 UTC\n",
      "  To:   2026-02-01 08:22:01 UTC\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Fetching Companies category series...\n",
      "--------------------------------------------------------------------------------\n",
      "  ✓ Found 349 series in Companies category\n",
      "\n",
      "✓ Total unique companies series: 349\n",
      "\n",
      "Companies series found:\n",
      "  - KXLEAVEJANGS: Jan GS\n",
      "    Category: Companies\n",
      "  - KXUNSEC: UN seceretary\n",
      "    Category: Companies\n",
      "  - KXAPPRANKPAID: Paid app ranking\n",
      "    Category: Entertainment\n",
      "  - KXAAPLRING: Apple Ring\n",
      "    Category: Companies\n",
      "  - KXIRSHEAD: New Head of IRS\n",
      "    Category: Companies\n",
      "  - KXWHOACQTIKTOK: Who will Acquire Tiktok\n",
      "    Category: Companies\n",
      "  - KXOPENAICEOCHANGE: OpenAI hires another CEO\n",
      "    Category: Companies\n",
      "  - KXMINWAGE: Minimum wage hike\n",
      "    Category: Politics\n",
      "  - KXPALANTIR: Palantir\n",
      "    Category: Companies\n",
      "  - KXREVIEWRELEASEMKBHDFRIEND: MKBHD Friend\n",
      "    Category: Companies\n",
      "  ... and 339 more series\n",
      "\n",
      "✓ Will fetch markets for 349 companies series\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# COMPANIES BACKTEST - STEP 1: Pull All Historical Companies Markets\n",
    "# ============================================================================\n",
    "\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "try:\n",
    "    from zoneinfo import ZoneInfo\n",
    "    ET_TZ = ZoneInfo('America/New_York')\n",
    "except ImportError:\n",
    "    ET_TZ = timezone(timedelta(hours=-5))\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FETCHING HISTORICAL COMPANIES MARKETS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate time window (past year)\n",
    "now_comp = datetime.now(timezone.utc)\n",
    "one_year_ago_comp = now_comp - timedelta(days=365)\n",
    "min_close_ts_comp = int(one_year_ago_comp.timestamp())\n",
    "max_close_ts_comp = int(now_comp.timestamp())\n",
    "\n",
    "print(f\"\\nTime window:\")\n",
    "print(f\"  From: {one_year_ago_comp.strftime('%Y-%m-%d %H:%M:%S UTC')}\")\n",
    "print(f\"  To:   {now_comp.strftime('%Y-%m-%d %H:%M:%S UTC')}\")\n",
    "\n",
    "# Search for Companies category series\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"Fetching Companies category series...\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "base_url_comp = \"https://api.elections.kalshi.com/trade-api/v2\"\n",
    "\n",
    "# Fetch series by category \"Companies\"\n",
    "companies_series = []\n",
    "\n",
    "try:\n",
    "    response = requests.get(f\"{base_url_comp}/series\", params={\"category\": \"Companies\", \"limit\": 200})\n",
    "    if response.status_code == 200:\n",
    "        series_data = response.json().get('series', [])\n",
    "        companies_series.extend(series_data)\n",
    "        print(f\"  ✓ Found {len(series_data)} series in Companies category\")\n",
    "    else:\n",
    "        print(f\"  ✗ Error: Status {response.status_code}\")\n",
    "    time.sleep(0.5)\n",
    "except Exception as e:\n",
    "    print(f\"  ✗ Error fetching Companies category: {e}\")\n",
    "\n",
    "# If category search fails, try keyword-based search\n",
    "if len(companies_series) == 0:\n",
    "    print(\"\\n  Category search returned no results. Trying keyword search...\")\n",
    "    \n",
    "    # Try different company-related keywords\n",
    "    search_keywords = [\"stock\", \"company\", \"earnings\", \"revenue\", \"nasdaq\", \"dow\", \"sp500\"]\n",
    "    \n",
    "    for keyword in search_keywords:\n",
    "        try:\n",
    "            response = requests.get(f\"{base_url_comp}/series\", params={\"limit\": 200})\n",
    "            if response.status_code == 200:\n",
    "                all_series = response.json().get('series', [])\n",
    "                # Filter by keyword\n",
    "                keyword_series = [\n",
    "                    s for s in all_series \n",
    "                    if keyword.lower() in s.get('title', '').lower() \n",
    "                    or keyword.lower() in s.get('category', '').lower()\n",
    "                    or any(keyword.lower() in tag.lower() for tag in s.get('tags', []))\n",
    "                ]\n",
    "                companies_series.extend(keyword_series)\n",
    "                if keyword_series:\n",
    "                    print(f\"    Found {len(keyword_series)} series matching '{keyword}'\")\n",
    "            time.sleep(0.5)\n",
    "        except Exception as e:\n",
    "            print(f\"    Error searching for '{keyword}': {e}\")\n",
    "\n",
    "# Deduplicate series\n",
    "unique_companies_series = {s['ticker']: s for s in companies_series}.values()\n",
    "print(f\"\\n✓ Total unique companies series: {len(unique_companies_series)}\")\n",
    "\n",
    "# Display found series\n",
    "if unique_companies_series:\n",
    "    print(\"\\nCompanies series found:\")\n",
    "    for s in list(unique_companies_series)[:10]:  # Show first 10\n",
    "        print(f\"  - {s['ticker']}: {s['title']}\")\n",
    "        print(f\"    Category: {s.get('category', 'N/A')}\")\n",
    "    if len(unique_companies_series) > 10:\n",
    "        print(f\"  ... and {len(unique_companies_series) - 10} more series\")\n",
    "\n",
    "# Store series tickers\n",
    "companies_series_tickers = [s['ticker'] for s in unique_companies_series]\n",
    "companies_series_list = list(unique_companies_series)\n",
    "\n",
    "print(f\"\\n✓ Will fetch markets for {len(companies_series_tickers)} companies series\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2rt5534oa9t",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FETCHING MARKETS FOR COMPANIES SERIES\n",
      "================================================================================\n",
      "\n",
      "Fetching settled markets for 349 series...\n",
      "(This may take a few minutes...)\n",
      "\n",
      "  [1/349] KXLEAVEJANGS: 1 markets\n",
      "  [4/349] KXAAPLRING: 1 markets\n",
      "  Progress: 5/349 series processed, 2 total markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [7/349] KXOPENAICEOCHANGE: 1 markets\n",
      "  [8/349] KXMINWAGE: 1 markets\n",
      "  [10/349] KXREVIEWRELEASEMKBHDFRIEND: 1 markets\n",
      "  Progress: 10/349 series processed, 5 total markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [12/349] KXINDIAX: 1 markets\n",
      "  [15/349] KXTESLAYL: 1 markets\n",
      "  Progress: 15/349 series processed, 7 total markets\n",
      "  [17/349] KXGMECEOCHANGE: 1 markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [19/349] KXCOMPANYACTIONYOUTUBE: 6 markets\n",
      "  Progress: 20/349 series processed, 14 total markets\n",
      "  [22/349] KXWIKIMEDIA: 1 markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  Progress: 25/349 series processed, 15 total markets\n",
      "  [26/349] KXRELOCATENYCFL: 5 markets\n",
      "  [27/349] KXALTMANEQUITY: 1 markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [29/349] KXROBOTAXIOUT: 1 markets\n",
      "  [30/349] KXLEAVEANTHROPIC: 8 markets\n",
      "  Progress: 30/349 series processed, 30 total markets\n",
      "  [32/349] KXWEALTHY: 7 markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [33/349] KXLEAVEJONYIVEOAI: 1 markets\n",
      "  [34/349] KXIPO: 26 markets\n",
      "  Progress: 35/349 series processed, 64 total markets\n",
      "  [38/349] KXNEWPRODUCTMICROSOFT: 1 markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  Progress: 40/349 series processed, 65 total markets\n",
      "  [42/349] KXNEWROLEVOGUE: 9 markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  Progress: 45/349 series processed, 74 total markets\n",
      "  [47/349] KXAAPLCEOCHANGE: 1 markets\n",
      "  [50/349] KXCEOINTC: 1 markets\n",
      "  Progress: 50/349 series processed, 76 total markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [52/349] KXEXPORTTARIFF: 1 markets\n",
      "  Progress: 55/349 series processed, 77 total markets\n",
      "  [56/349] KXBOEINGCEOCHANGE: 1 markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  [60/349] KXOPENDOORCEO: 5 markets\n",
      "  Progress: 60/349 series processed, 83 total markets\n",
      "  [62/349] KXJOINSTEPHENCOLBERT: 8 markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  Progress: 65/349 series processed, 91 total markets\n",
      "  [66/349] KXISMPMI: 49 markets\n",
      "  [67/349] KXSPIRITCEOCHANGE: 1 markets\n",
      "  Rate limited, waiting 2 seconds...\n",
      "  Progress: 70/349 series processed, 141 total markets\n",
      "  [71/349] KXLEAVEOPENAI: 8 markets\n",
      "  [73/349] KXROGANBOARD: 1 markets\n",
      "  [74/349] KXCBVOLUME: 34 markets\n",
      "  Progress: 75/349 series processed, 184 total markets\n",
      "  Rate limited, waiting 2 seconds...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m429\u001b[39m:\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Rate limited, waiting 2 seconds...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 36\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# COMPANIES BACKTEST - STEP 2: Fetch All Markets for Companies Series\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FETCHING MARKETS FOR COMPANIES SERIES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Fetch all markets for companies series\n",
    "all_companies_markets = []\n",
    "\n",
    "print(f\"\\nFetching settled markets for {len(companies_series_tickers)} series...\")\n",
    "print(\"(This may take a few minutes...)\\n\")\n",
    "\n",
    "for i, series_ticker in enumerate(companies_series_tickers, 1):\n",
    "    cursor = None\n",
    "    series_markets = []\n",
    "    \n",
    "    while True:\n",
    "        params = {\n",
    "            \"series_ticker\": series_ticker,\n",
    "            \"status\": \"settled\",  # Only settled markets for backtesting\n",
    "            \"min_close_ts\": min_close_ts_comp,\n",
    "            \"max_close_ts\": max_close_ts_comp,\n",
    "            \"limit\": 1000\n",
    "        }\n",
    "        \n",
    "        if cursor:\n",
    "            params[\"cursor\"] = cursor\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(f\"{base_url_comp}/markets\", params=params)\n",
    "            \n",
    "            if response.status_code == 429:\n",
    "                print(f\"  Rate limited, waiting 2 seconds...\")\n",
    "                time.sleep(2)\n",
    "                continue\n",
    "            \n",
    "            if response.status_code != 200:\n",
    "                print(f\"  ✗ Error for {series_ticker}: Status {response.status_code}\")\n",
    "                break\n",
    "            \n",
    "            data = response.json()\n",
    "            markets = data.get('markets', [])\n",
    "            series_markets.extend(markets)\n",
    "            \n",
    "            cursor = data.get('cursor')\n",
    "            if not cursor:\n",
    "                break\n",
    "            \n",
    "            time.sleep(0.3)  # Rate limiting\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ Error fetching {series_ticker}: {e}\")\n",
    "            break\n",
    "    \n",
    "    if series_markets:\n",
    "        all_companies_markets.extend(series_markets)\n",
    "        print(f\"  [{i}/{len(companies_series_tickers)}] {series_ticker}: {len(series_markets)} markets\")\n",
    "    \n",
    "    # Progress update every 5 series\n",
    "    if i % 5 == 0:\n",
    "        print(f\"  Progress: {i}/{len(companies_series_tickers)} series processed, {len(all_companies_markets)} total markets\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"✓ TOTAL MARKETS FETCHED: {len(all_companies_markets)}\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Store raw markets\n",
    "companies_markets_raw = all_companies_markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98bqpx57cl",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# COMPANIES BACKTEST - STEP 3: Filter by Duration (1 Week to 1 Month) and Liquidity\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"APPLYING FILTERS: DURATION 1 WEEK - 1 MONTH, LIQUIDITY >= $100,000\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Target thresholds\n",
    "MIN_DURATION_HOURS_COMP = 7 * 24    # 1 week = 168 hours\n",
    "MAX_DURATION_HOURS_COMP = 30 * 24   # 1 month = 720 hours\n",
    "MIN_LIQUIDITY_DOLLARS_COMP = 100000  # $100,000\n",
    "\n",
    "# Apply filters\n",
    "filtered_companies_markets = []\n",
    "filter_stats_comp = {\n",
    "    'total': len(companies_markets_raw),\n",
    "    'duration_pass': 0,\n",
    "    'liquidity_pass': 0,\n",
    "    'both_pass': 0,\n",
    "    'too_short': 0,\n",
    "    'too_long': 0,\n",
    "    'liquidity_fail': 0\n",
    "}\n",
    "\n",
    "for market in companies_markets_raw:\n",
    "    # Parse timestamps\n",
    "    try:\n",
    "        open_time = datetime.fromisoformat(market['open_time'].replace('Z', '+00:00'))\n",
    "        close_time = datetime.fromisoformat(market['close_time'].replace('Z', '+00:00'))\n",
    "        duration_hours = (close_time - open_time).total_seconds() / 3600\n",
    "        \n",
    "        liquidity_dollars = float(market.get('liquidity_dollars', '0'))\n",
    "        \n",
    "        # Track filter pass rates\n",
    "        duration_ok = MIN_DURATION_HOURS_COMP <= duration_hours <= MAX_DURATION_HOURS_COMP\n",
    "        liquidity_ok = liquidity_dollars >= MIN_LIQUIDITY_DOLLARS_COMP\n",
    "        \n",
    "        if duration_ok:\n",
    "            filter_stats_comp['duration_pass'] += 1\n",
    "        else:\n",
    "            if duration_hours < MIN_DURATION_HOURS_COMP:\n",
    "                filter_stats_comp['too_short'] += 1\n",
    "            else:\n",
    "                filter_stats_comp['too_long'] += 1\n",
    "        \n",
    "        if liquidity_ok:\n",
    "            filter_stats_comp['liquidity_pass'] += 1\n",
    "        else:\n",
    "            filter_stats_comp['liquidity_fail'] += 1\n",
    "        \n",
    "        # Both filters must pass\n",
    "        if duration_ok and liquidity_ok:\n",
    "            market['duration_hours'] = duration_hours\n",
    "            market['liquidity_dollars_float'] = liquidity_dollars\n",
    "            filtered_companies_markets.append(market)\n",
    "            filter_stats_comp['both_pass'] += 1\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  Error processing market {market.get('ticker', 'unknown')}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\nFilter Results:\")\n",
    "print(f\"  Total markets:                {filter_stats_comp['total']}\")\n",
    "print(f\"  Duration filter (1w - 1m):    {filter_stats_comp['duration_pass']} passed\")\n",
    "print(f\"    - Too short (< 1 week):     {filter_stats_comp['too_short']}\")\n",
    "print(f\"    - Too long (> 1 month):     {filter_stats_comp['too_long']}\")\n",
    "print(f\"  Liquidity filter (>=$100k):   {filter_stats_comp['liquidity_pass']} passed, {filter_stats_comp['liquidity_fail']} failed\")\n",
    "print(f\"  ✓ Both filters passed:        {filter_stats_comp['both_pass']} markets\")\n",
    "\n",
    "# If no markets pass strict filters, try lower liquidity thresholds\n",
    "if filter_stats_comp['both_pass'] == 0:\n",
    "    print(\"\\n\" + \"⚠\"*40)\n",
    "    print(\"⚠ NO MARKETS PASSED STRICT FILTERS\")\n",
    "    print(\"⚠ Lowering liquidity threshold to find available data...\")\n",
    "    print(\"⚠\"*40)\n",
    "    \n",
    "    # Try progressively lower liquidity thresholds (keep duration constant)\n",
    "    liquidity_thresholds_to_try = [50000, 25000, 10000, 5000, 0]\n",
    "    \n",
    "    for min_liq in liquidity_thresholds_to_try:\n",
    "        filtered_companies_markets = []\n",
    "        for market in companies_markets_raw:\n",
    "            try:\n",
    "                open_time = datetime.fromisoformat(market['open_time'].replace('Z', '+00:00'))\n",
    "                close_time = datetime.fromisoformat(market['close_time'].replace('Z', '+00:00'))\n",
    "                duration_hours = (close_time - open_time).total_seconds() / 3600\n",
    "                liquidity_dollars = float(market.get('liquidity_dollars', '0'))\n",
    "                \n",
    "                # Keep duration constraint, lower liquidity\n",
    "                if MIN_DURATION_HOURS_COMP <= duration_hours <= MAX_DURATION_HOURS_COMP and liquidity_dollars >= min_liq:\n",
    "                    market['duration_hours'] = duration_hours\n",
    "                    market['liquidity_dollars_float'] = liquidity_dollars\n",
    "                    filtered_companies_markets.append(market)\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        if len(filtered_companies_markets) > 0:\n",
    "            print(f\"\\n✓ Found {len(filtered_companies_markets)} markets with:\")\n",
    "            print(f\"  - Duration: 1 week - 1 month\")\n",
    "            print(f\"  - Liquidity >= ${min_liq:,}\")\n",
    "            MIN_LIQUIDITY_DOLLARS_COMP = min_liq\n",
    "            break\n",
    "    \n",
    "    if len(filtered_companies_markets) == 0:\n",
    "        print(\"\\n⚠ WARNING: No companies markets found even with lowered thresholds!\")\n",
    "        print(\"Showing sample of available markets:\\n\")\n",
    "        for i, m in enumerate(companies_markets_raw[:5], 1):\n",
    "            try:\n",
    "                open_time = datetime.fromisoformat(m['open_time'].replace('Z', '+00:00'))\n",
    "                close_time = datetime.fromisoformat(m['close_time'].replace('Z', '+00:00'))\n",
    "                duration = (close_time - open_time).total_seconds() / 3600\n",
    "                liq = float(m.get('liquidity_dollars', '0'))\n",
    "                print(f\"  {i}. {m['ticker']}\")\n",
    "                print(f\"     Duration: {duration/24:.2f} days, Liquidity: ${liq:,.2f}\")\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"✓ QUALIFIED MARKETS: {len(filtered_companies_markets)}\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Show sample of qualified markets\n",
    "if filtered_companies_markets:\n",
    "    print(\"\\nSample qualified markets (first 5):\")\n",
    "    for i, m in enumerate(filtered_companies_markets[:5], 1):\n",
    "        print(f\"\\n  {i}. {m['ticker']}\")\n",
    "        print(f\"     Title: {m.get('title', 'N/A')}\")\n",
    "        print(f\"     Duration: {m['duration_hours']/24:.2f} days ({m['duration_hours']/24/7:.2f} weeks)\")\n",
    "        print(f\"     Liquidity: ${m['liquidity_dollars_float']:,.2f}\")\n",
    "        print(f\"     Open: {m['open_time']}\")\n",
    "        print(f\"     Close: {m['close_time']}\")\n",
    "        print(f\"     Result: {m.get('result', 'N/A')}\")\n",
    "\n",
    "companies_markets_qualified = filtered_companies_markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apjjrb7hjuv",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# COMPANIES BACKTEST - STEP 4: Group by Event & Calculate Entry Points\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GROUPING MARKETS BY EVENT & CALCULATING ENTRY POINTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Group markets by event_ticker to identify multi-decision markets\n",
    "events_dict_comp = {}\n",
    "\n",
    "for market in companies_markets_qualified:\n",
    "    event_ticker = market.get('event_ticker', market['ticker'])\n",
    "    \n",
    "    if event_ticker not in events_dict_comp:\n",
    "        events_dict_comp[event_ticker] = []\n",
    "    \n",
    "    # Calculate entry point (12 hours before close)\n",
    "    close_time = datetime.fromisoformat(market['close_time'].replace('Z', '+00:00'))\n",
    "    entry_time = close_time - timedelta(hours=12)\n",
    "    \n",
    "    # Add entry info to market\n",
    "    market['entry_time'] = entry_time\n",
    "    market['entry_time_str'] = entry_time.isoformat()\n",
    "    market['close_time_dt'] = close_time\n",
    "    \n",
    "    events_dict_comp[event_ticker].append(market)\n",
    "\n",
    "print(f\"\\n✓ Found {len(events_dict_comp)} unique events\")\n",
    "\n",
    "# Classify events\n",
    "event_classification_comp = {\n",
    "    'single': [],\n",
    "    'multi': []\n",
    "}\n",
    "\n",
    "for event_ticker, markets in events_dict_comp.items():\n",
    "    if len(markets) == 1:\n",
    "        event_classification_comp['single'].append(event_ticker)\n",
    "    else:\n",
    "        event_classification_comp['multi'].append(event_ticker)\n",
    "\n",
    "print(f\"\\nEvent Classification:\")\n",
    "print(f\"  Single-outcome events: {len(event_classification_comp['single'])}\")\n",
    "print(f\"  Multi-outcome events:  {len(event_classification_comp['multi'])}\")\n",
    "\n",
    "# Multi-decision events for strategy\n",
    "multi_decision_events_comp = {k: v for k, v in events_dict_comp.items() if len(v) >= 2}\n",
    "\n",
    "print(f\"\\n✓ Multi-decision events for strategy: {len(multi_decision_events_comp)}\")\n",
    "\n",
    "# Show sample multi-decision events\n",
    "if multi_decision_events_comp:\n",
    "    print(\"\\nSample multi-decision events (first 3):\")\n",
    "    for i, (event_ticker, markets) in enumerate(list(multi_decision_events_comp.items())[:3], 1):\n",
    "        print(f\"\\n  {i}. Event: {event_ticker}\")\n",
    "        print(f\"     Number of markets: {len(markets)}\")\n",
    "        print(f\"     Entry time: {markets[0]['entry_time'].strftime('%Y-%m-%d %H:%M:%S UTC')}\")\n",
    "        print(f\"     Close time: {markets[0]['close_time_dt'].strftime('%Y-%m-%d %H:%M:%S UTC')}\")\n",
    "        print(f\"     Markets:\")\n",
    "        for m in markets[:3]:  # Show first 3 markets\n",
    "            print(f\"       - {m['ticker']}: {m.get('title', 'N/A')[:50]}...\")\n",
    "            print(f\"         Yes bid/ask: ${m.get('yes_bid', 0)/100:.2f}/${m.get('yes_ask', 0)/100:.2f}\")\n",
    "            print(f\"         Result: {m.get('result', 'N/A')}\")\n",
    "        if len(markets) > 3:\n",
    "            print(f\"       ... and {len(markets) - 3} more markets\")\n",
    "\n",
    "# All tradeable events\n",
    "all_tradeable_events_comp = events_dict_comp.copy()\n",
    "\n",
    "print(f\"\\n✓ Total tradeable events (single + multi): {len(all_tradeable_events_comp)}\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf70c34fv1u",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# COMPANIES BACKTEST - STEP 5: Organize Events by Entry Date\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ORGANIZING EVENTS BY ENTRY DATE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Organize events by entry date\n",
    "events_by_entry_date_comp = {}\n",
    "\n",
    "for event_ticker, markets in all_tradeable_events_comp.items():\n",
    "    entry_time = markets[0]['entry_time']\n",
    "    entry_date = entry_time.date()\n",
    "    \n",
    "    if entry_date not in events_by_entry_date_comp:\n",
    "        events_by_entry_date_comp[entry_date] = []\n",
    "    \n",
    "    events_by_entry_date_comp[entry_date].append({\n",
    "        'event_ticker': event_ticker,\n",
    "        'markets': markets,\n",
    "        'entry_time': entry_time,\n",
    "        'num_markets': len(markets)\n",
    "    })\n",
    "\n",
    "# Sort dates\n",
    "sorted_dates_comp = sorted(events_by_entry_date_comp.keys())\n",
    "\n",
    "print(f\"\\n✓ Trading spans {len(sorted_dates_comp)} unique dates\")\n",
    "if sorted_dates_comp:\n",
    "    print(f\"  First entry date: {sorted_dates_comp[0]}\")\n",
    "    print(f\"  Last entry date:  {sorted_dates_comp[-1]}\")\n",
    "\n",
    "# Events per day statistics\n",
    "events_per_day_comp = [len(events) for events in events_by_entry_date_comp.values()]\n",
    "if events_per_day_comp:\n",
    "    print(f\"\\nEvents per day statistics:\")\n",
    "    print(f\"  Average: {np.mean(events_per_day_comp):.2f}\")\n",
    "    print(f\"  Median:  {np.median(events_per_day_comp):.0f}\")\n",
    "    print(f\"  Max:     {np.max(events_per_day_comp)}\")\n",
    "    print(f\"  Min:     {np.min(events_per_day_comp)}\")\n",
    "\n",
    "# Sample daily schedule\n",
    "if sorted_dates_comp:\n",
    "    print(f\"\\nSample daily schedule (first 5 days):\")\n",
    "    for i, date in enumerate(sorted_dates_comp[:5], 1):\n",
    "        events = events_by_entry_date_comp[date]\n",
    "        print(f\"\\n  Day {i}: {date}\")\n",
    "        print(f\"  Events to trade: {len(events)}\")\n",
    "        for event in events[:3]:\n",
    "            print(f\"    - {event['event_ticker']}: {event['num_markets']} markets\")\n",
    "        if len(events) > 3:\n",
    "            print(f\"    ... and {len(events) - 3} more events\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ynxfk8d3nqr",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# COMPANIES BACKTEST - STEP 6: Simulate Trading Strategy\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SIMULATING TRADING STRATEGY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Strategy parameters (same as climate backtest)\n",
    "INITIAL_CAPITAL_COMP = 100000\n",
    "DAILY_BUDGET_COMP = 10000\n",
    "YES_ALLOCATION_COMP = 0.70\n",
    "NO_ALLOCATION_COMP = 0.30\n",
    "\n",
    "all_trades_comp = []\n",
    "trade_id_comp = 0\n",
    "\n",
    "print(f\"\\nStrategy Parameters:\")\n",
    "print(f\"  Initial capital:  ${INITIAL_CAPITAL_COMP:,}\")\n",
    "print(f\"  Daily budget:     ${DAILY_BUDGET_COMP:,}\")\n",
    "print(f\"  YES allocation:   {YES_ALLOCATION_COMP*100:.0f}%\")\n",
    "print(f\"  NO allocation:    {NO_ALLOCATION_COMP*100:.0f}% (split across NOs)\")\n",
    "\n",
    "print(f\"\\n{'-'*80}\")\n",
    "print(\"Processing trades...\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Process each trading day\n",
    "for date in sorted_dates_comp:\n",
    "    events_today = events_by_entry_date_comp[date]\n",
    "    num_events = len(events_today)\n",
    "    \n",
    "    if num_events == 0:\n",
    "        continue\n",
    "    \n",
    "    budget_per_event = DAILY_BUDGET_COMP / num_events\n",
    "    \n",
    "    for event in events_today:\n",
    "        event_ticker = event['event_ticker']\n",
    "        markets = event['markets']\n",
    "        num_markets = len(markets)\n",
    "        \n",
    "        if num_markets >= 2:\n",
    "            # Multi-decision: YES on favorite, NO on others\n",
    "            favorite = max(markets, key=lambda m: m.get('yes_bid', 0))\n",
    "            others = [m for m in markets if m != favorite]\n",
    "            \n",
    "            yes_size_dollars = budget_per_event * YES_ALLOCATION_COMP\n",
    "            no_size_dollars = budget_per_event * NO_ALLOCATION_COMP\n",
    "            no_size_per_market = no_size_dollars / len(others) if others else 0\n",
    "            \n",
    "            # YES on favorite\n",
    "            yes_price = favorite.get('yes_ask', favorite.get('yes_bid', 50))\n",
    "            yes_contracts = (yes_size_dollars * 100) / yes_price if yes_price > 0 else 0\n",
    "            \n",
    "            if favorite.get('result') == 'yes':\n",
    "                yes_pnl = yes_contracts * (100 - yes_price) / 100\n",
    "            elif favorite.get('result') == 'no':\n",
    "                yes_pnl = -yes_size_dollars\n",
    "            elif favorite.get('result') == 'void':\n",
    "                yes_pnl = 0\n",
    "            else:\n",
    "                yes_pnl = 0\n",
    "            \n",
    "            trade_id_comp += 1\n",
    "            all_trades_comp.append({\n",
    "                'trade_id': trade_id_comp,\n",
    "                'event_ticker': event_ticker,\n",
    "                'ticker': favorite['ticker'],\n",
    "                'entry_date': date,\n",
    "                'entry_time': event['entry_time'],\n",
    "                'close_time': favorite['close_time_dt'],\n",
    "                'side': 'YES',\n",
    "                'price': yes_price / 100,\n",
    "                'contracts': yes_contracts,\n",
    "                'investment': yes_size_dollars,\n",
    "                'result': favorite.get('result', 'unknown'),\n",
    "                'pnl': yes_pnl,\n",
    "                'market_type': 'multi_favorite',\n",
    "                'liquidity': favorite.get('liquidity_dollars_float', 0),\n",
    "                'duration_days': favorite.get('duration_hours', 0) / 24\n",
    "            })\n",
    "            \n",
    "            # NO on others\n",
    "            for other in others:\n",
    "                no_price = other.get('no_ask', other.get('no_bid', 50))\n",
    "                no_contracts = (no_size_per_market * 100) / no_price if no_price > 0 else 0\n",
    "                \n",
    "                if other.get('result') == 'no':\n",
    "                    no_pnl = no_contracts * (100 - no_price) / 100\n",
    "                elif other.get('result') == 'yes':\n",
    "                    no_pnl = -no_size_per_market\n",
    "                elif other.get('result') == 'void':\n",
    "                    no_pnl = 0\n",
    "                else:\n",
    "                    no_pnl = 0\n",
    "                \n",
    "                trade_id_comp += 1\n",
    "                all_trades_comp.append({\n",
    "                    'trade_id': trade_id_comp,\n",
    "                    'event_ticker': event_ticker,\n",
    "                    'ticker': other['ticker'],\n",
    "                    'entry_date': date,\n",
    "                    'entry_time': event['entry_time'],\n",
    "                    'close_time': other['close_time_dt'],\n",
    "                    'side': 'NO',\n",
    "                    'price': no_price / 100,\n",
    "                    'contracts': no_contracts,\n",
    "                    'investment': no_size_per_market,\n",
    "                    'result': other.get('result', 'unknown'),\n",
    "                    'pnl': no_pnl,\n",
    "                    'market_type': 'multi_other',\n",
    "                    'liquidity': other.get('liquidity_dollars_float', 0),\n",
    "                    'duration_days': other.get('duration_hours', 0) / 24\n",
    "                })\n",
    "        \n",
    "        else:\n",
    "            # Single binary market\n",
    "            market = markets[0]\n",
    "            yes_bid = market.get('yes_bid', 50)\n",
    "            \n",
    "            if yes_bid >= 50:\n",
    "                yes_price = market.get('yes_ask', yes_bid)\n",
    "                contracts = (budget_per_event * 100) / yes_price if yes_price > 0 else 0\n",
    "                \n",
    "                if market.get('result') == 'yes':\n",
    "                    pnl = contracts * (100 - yes_price) / 100\n",
    "                elif market.get('result') == 'no':\n",
    "                    pnl = -budget_per_event\n",
    "                elif market.get('result') == 'void':\n",
    "                    pnl = 0\n",
    "                else:\n",
    "                    pnl = 0\n",
    "                \n",
    "                side = 'YES'\n",
    "                price = yes_price\n",
    "            else:\n",
    "                no_price = market.get('no_ask', 100 - yes_bid)\n",
    "                contracts = (budget_per_event * 100) / no_price if no_price > 0 else 0\n",
    "                \n",
    "                if market.get('result') == 'no':\n",
    "                    pnl = contracts * (100 - no_price) / 100\n",
    "                elif market.get('result') == 'yes':\n",
    "                    pnl = -budget_per_event\n",
    "                elif market.get('result') == 'void':\n",
    "                    pnl = 0\n",
    "                else:\n",
    "                    pnl = 0\n",
    "                \n",
    "                side = 'NO'\n",
    "                price = no_price\n",
    "            \n",
    "            trade_id_comp += 1\n",
    "            all_trades_comp.append({\n",
    "                'trade_id': trade_id_comp,\n",
    "                'event_ticker': event_ticker,\n",
    "                'ticker': market['ticker'],\n",
    "                'entry_date': date,\n",
    "                'entry_time': event['entry_time'],\n",
    "                'close_time': market['close_time_dt'],\n",
    "                'side': side,\n",
    "                'price': price / 100,\n",
    "                'contracts': contracts,\n",
    "                'investment': budget_per_event,\n",
    "                'result': market.get('result', 'unknown'),\n",
    "                'pnl': pnl,\n",
    "                'market_type': 'binary',\n",
    "                'liquidity': market.get('liquidity_dollars_float', 0),\n",
    "                'duration_days': market.get('duration_hours', 0) / 24\n",
    "            })\n",
    "\n",
    "print(f\"\\n✓ Simulation complete!\")\n",
    "print(f\"  Total trades executed: {len(all_trades_comp)}\")\n",
    "print(f\"  Trading days: {len(sorted_dates_comp)}\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "trades_df_comp = pd.DataFrame(all_trades_comp)\n",
    "\n",
    "if not trades_df_comp.empty:\n",
    "    print(f\"\\nSample trades (first 10):\")\n",
    "    print(trades_df_comp[['trade_id', 'ticker', 'side', 'price', 'investment', 'result', 'pnl']].head(10).to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
